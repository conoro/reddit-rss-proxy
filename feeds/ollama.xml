<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/ollama/.rss</id>
  <title>ollama</title>
  <updated>2025-11-25T20:38:14+00:00</updated>
  <link href="https://old.reddit.com/r/ollama/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Atom feed for r/ollama</subtitle>
  <entry>
    <id>t3_1p4lxnr</id>
    <title>Best Local Coding Agent Model for 64GB RAM and 12GB VRAM?</title>
    <updated>2025-11-23T12:49:55+00:00</updated>
    <author>
      <name>/u/fallen0523</name>
      <uri>https://old.reddit.com/user/fallen0523</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/fallen0523"&gt; /u/fallen0523 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/LocalLLaMA/comments/1p4lwyc/best_local_coding_agent_model_for_64gb_ram_and/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4lxnr/best_local_coding_agent_model_for_64gb_ram_and/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p4lxnr/best_local_coding_agent_model_for_64gb_ram_and/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-23T12:49:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1p4od24</id>
    <title>Summarize and manage local files?</title>
    <updated>2025-11-23T14:42:32+00:00</updated>
    <author>
      <name>/u/cl326</name>
      <uri>https://old.reddit.com/user/cl326</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have a huge number of files on my laptop. They are not well organized or named. I‚Äôve removed all duplicates that I can by comparing hashes and names. Now I‚Äôd like to use Ollama to summarize each file in a folder so ai can get an idea of what the file is about if I can‚Äôt tell by the name. The files are mostly MS Office documents, PDFs, and images. Is there a model that you‚Äôd suggest? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cl326"&gt; /u/cl326 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4od24/summarize_and_manage_local_files/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4od24/summarize_and_manage_local_files/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p4od24/summarize_and_manage_local_files/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-23T14:42:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1p3vpni</id>
    <title>Your local Ollama agents can be just as good as closed-source models - I open-sourced Stanford's ACE framework that makes agents learn from mistakes</title>
    <updated>2025-11-22T15:17:51+00:00</updated>
    <author>
      <name>/u/cheetguy</name>
      <uri>https://old.reddit.com/user/cheetguy</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I implemented Stanford's &lt;a href="https://arxiv.org/abs/2510.04618"&gt;Agentic Context Engineering paper&lt;/a&gt; for Ollama. The framework makes agents learn from their own execution feedback through in-context learning instead of fine-tuning.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt; Agent runs task ‚Üí reflects on what worked/failed ‚Üí curates strategies into playbook ‚Üí uses playbook on next run&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Improvement:&lt;/strong&gt; Paper shows +17.1pp accuracy improvement vs base LLM (‚âà+40% relative improvement) on agent benchmarks (DeepSeek-V3.1 non-thinking mode), helping close the gap with closed-source models. All through in-context learning (no fine-tuning needed).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;My Open-Source Implementation:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Drop into existing agents in ~10 lines of code&lt;/li&gt; &lt;li&gt;Works with any Ollama model (Llama, Qwen, Mistral, DeepSeek, etc.)&lt;/li&gt; &lt;li&gt;Real-world test on browser automation agent: &lt;ul&gt; &lt;li&gt;30% ‚Üí 100% success rate&lt;/li&gt; &lt;li&gt;82% fewer steps&lt;/li&gt; &lt;li&gt;65% decrease in token cost&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Get started:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;GitHub: &lt;a href="https://github.com/kayba-ai/agentic-context-engine"&gt;https://github.com/kayba-ai/agentic-context-engine&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Ollama Starter Template: &lt;a href="https://github.com/kayba-ai/agentic-context-engine/blob/main/examples/ollama/ollama_starter_template.py"&gt;https://github.com/kayba-ai/agentic-context-engine/blob/main/examples/ollama/ollama_starter_template.py&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Would love to hear if anyone tries this with Ollama! Especially curious how it performs with different Ollama models.&lt;/p&gt; &lt;p&gt;I'm currently actively improving this based on feedback - &lt;a href="https://github.com/kayba-ai/agentic-context-engine"&gt;‚≠ê the repo&lt;/a&gt; so you can stay updated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cheetguy"&gt; /u/cheetguy &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p3vpni/your_local_ollama_agents_can_be_just_as_good_as/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p3vpni/your_local_ollama_agents_can_be_just_as_good_as/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p3vpni/your_local_ollama_agents_can_be_just_as_good_as/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-22T15:17:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1p52b8z</id>
    <title>RAG follow-ups not working ‚Äî Qwen2.5 ignores previous context and gives unrelated answers</title>
    <updated>2025-11-24T00:10:24+00:00</updated>
    <author>
      <name>/u/NoBlackberry3264</name>
      <uri>https://old.reddit.com/user/NoBlackberry3264</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt; &lt;p&gt;I‚Äôm building a &lt;strong&gt;RAG-based chat system&lt;/strong&gt; using FastAPI + &lt;strong&gt;Qwen/Qwen2.5-7B-Instruct&lt;/strong&gt;, and I‚Äôm running into an issue with follow-up queries.&lt;/p&gt; &lt;p&gt;The first query works fine, retrieving relevant documents from my knowledge base. But when the user asks a follow-up question, the model completely ignores previous context and fetches unrelated information.&lt;/p&gt; &lt;h1&gt;Example Payload (Client Request)&lt;/h1&gt; &lt;p&gt;Here‚Äôs the structure of the payload my client sends:&lt;br /&gt; {&lt;/p&gt; &lt;p&gt;&amp;quot;system_persona&amp;quot;: &amp;quot;KB&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;system_prompt&amp;quot;: { ... }, &lt;/p&gt; &lt;p&gt;&amp;quot;context&amp;quot;: [&lt;/p&gt; &lt;p&gt;{&lt;/p&gt; &lt;p&gt;&amp;quot;content&amp;quot;: &amp;quot;...&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;pageUrl&amp;quot;: &amp;quot;...&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;sourceUrl&amp;quot;: &amp;quot;...&amp;quot;&lt;/p&gt; &lt;p&gt;},&lt;/p&gt; &lt;p&gt;{&lt;/p&gt; &lt;p&gt;&amp;quot;content&amp;quot;: &amp;quot;...&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;pageUrl&amp;quot;: &amp;quot;...&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;sourceUrl&amp;quot;: &amp;quot;...&amp;quot;&lt;/p&gt; &lt;p&gt;}&lt;/p&gt; &lt;p&gt;],&lt;/p&gt; &lt;p&gt;&amp;quot;chat_history&amp;quot;: [&lt;/p&gt; &lt;p&gt;{&lt;/p&gt; &lt;p&gt;&amp;quot;query&amp;quot;: &amp;quot;...&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;response&amp;quot;: &amp;quot;...&amp;quot;&lt;/p&gt; &lt;p&gt;},&lt;/p&gt; &lt;p&gt;{&lt;/p&gt; &lt;p&gt;&amp;quot;query&amp;quot;: &amp;quot;...&amp;quot;,&lt;/p&gt; &lt;p&gt;&amp;quot;response&amp;quot;: &amp;quot;...&amp;quot;&lt;/p&gt; &lt;p&gt;}&lt;/p&gt; &lt;p&gt;],&lt;/p&gt; &lt;p&gt;&amp;quot;query&amp;quot;: &amp;quot;nabil bank ko baryama bhana?&amp;quot;&lt;/p&gt; &lt;p&gt;}&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Issue:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Follow-ups are not linked to previous conversation.&lt;/li&gt; &lt;li&gt;Chat history is sent but not effectively used.&lt;/li&gt; &lt;li&gt;Retrieval is based only on the latest query.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/NoBlackberry3264"&gt; /u/NoBlackberry3264 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p52b8z/rag_followups_not_working_qwen25_ignores_previous/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p52b8z/rag_followups_not_working_qwen25_ignores_previous/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p52b8z/rag_followups_not_working_qwen25_ignores_previous/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T00:10:24+00:00</published>
  </entry>
  <entry>
    <id>t3_1p4wq3l</id>
    <title>ollama troubles</title>
    <updated>2025-11-23T20:15:31+00:00</updated>
    <author>
      <name>/u/Remote-Ad8602</name>
      <uri>https://old.reddit.com/user/Remote-Ad8602</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi people&lt;br /&gt; I recently heard about ollama and tought of giving it a try after installing the app i tried to download some existing models like gpt and qwen when try to give a prompt for the model the screen keeps loading for long time and so on, one time i had to wait 44 mins just to see an error message so i tried removing the app and reinstall again even after multiple tries I still couldn't figure out what's wrong is it my computer or some problems with the app, I use a Macbook Air M4 chip &lt;/p&gt; &lt;p&gt;has anyone faced the same issue, please let me know is there any remedy to get it working normally let me know guys....&lt;/p&gt; &lt;p&gt;cheers&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Remote-Ad8602"&gt; /u/Remote-Ad8602 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4wq3l/ollama_troubles/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4wq3l/ollama_troubles/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p4wq3l/ollama_troubles/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-23T20:15:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1p4z140</id>
    <title>Need some honest opinions on GPU Ai in a box</title>
    <updated>2025-11-23T21:49:26+00:00</updated>
    <author>
      <name>/u/Whyme-__-</name>
      <uri>https://old.reddit.com/user/Whyme-__-</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;This is related to Nvidia Spark and its competitors. I have a use case where I have to deliver my Ai software to deploy on customer infrastructure. I have 3 8b models fine tuned for each use case. I want to know if using a Nvidia spark or similar GPU in a box is worth the investment for privacy, speed and economics. &lt;/p&gt; &lt;p&gt;For my use case my models and software burn about $2000 per month if I rent a pod using runpod and I have to be extra careful due to rate limits. I want to consider running my models using llamacpp or ollama or offering direct inference for customer using their own on prem machine shipped by me. &lt;/p&gt; &lt;p&gt;Here are my 2 concern:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;p&gt;Are these machines stable enough to deploy in production environments? I know they run Linux and my software stack is dockerized so won‚Äôt affect much. &lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Cost: I know as we enter the new year GPU cost might go down but should that be something to wait it out or get 1 DGX spark box and test things out to see the functionality and ease of deployment? I can always repurpose the box for my startup instead of relying on Runpod GPU. &lt;/p&gt;&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This community has helped me a lot in the past, I‚Äôm hoping to get some answers from the community regarding these issues. &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Whyme-__-"&gt; /u/Whyme-__- &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4z140/need_some_honest_opinions_on_gpu_ai_in_a_box/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4z140/need_some_honest_opinions_on_gpu_ai_in_a_box/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p4z140/need_some_honest_opinions_on_gpu_ai_in_a_box/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-23T21:49:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1p4o31k</id>
    <title>Nanocoder VS Code Plugin is Coming Along!</title>
    <updated>2025-11-23T14:30:09+00:00</updated>
    <author>
      <name>/u/willlamerton</name>
      <uri>https://old.reddit.com/user/willlamerton</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p4o31k/nanocoder_vs_code_plugin_is_coming_along/"&gt; &lt;img alt="Nanocoder VS Code Plugin is Coming Along!" src="https://preview.redd.it/0bdpxyrvm03g1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5a452110a43bda75376e5ffac7e29e49df77ae63" title="Nanocoder VS Code Plugin is Coming Along!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/willlamerton"&gt; /u/willlamerton &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/0bdpxyrvm03g1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p4o31k/nanocoder_vs_code_plugin_is_coming_along/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p4o31k/nanocoder_vs_code_plugin_is_coming_along/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-23T14:30:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1p5b6pd</id>
    <title>Win 7 days of unlimited API access on GLM-4.6! 7 winners</title>
    <updated>2025-11-24T07:53:03+00:00</updated>
    <author>
      <name>/u/cobra91310</name>
      <uri>https://old.reddit.com/user/cobra91310</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cobra91310"&gt; /u/cobra91310 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/ZaiGLM/comments/1p5b6cw/win_7_days_of_unlimited_api_access_on_glm46_7/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5b6pd/win_7_days_of_unlimited_api_access_on_glm46_7/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p5b6pd/win_7_days_of_unlimited_api_access_on_glm46_7/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T07:53:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1p56i8v</id>
    <title>M.I.M.I.R - Now with visual intelligence built in for embeddings - MIT licensed - use with local ollama or llama.cpp for full control over your data</title>
    <updated>2025-11-24T03:29:23+00:00</updated>
    <author>
      <name>/u/Dense_Gate_5193</name>
      <uri>https://old.reddit.com/user/Dense_Gate_5193</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p56i8v/mimir_now_with_visual_intelligence_built_in_for/"&gt; &lt;img alt="M.I.M.I.R - Now with visual intelligence built in for embeddings - MIT licensed - use with local ollama or llama.cpp for full control over your data" src="https://preview.redd.it/icw2e1nbj43g1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e6af6e5db3bde853b33115fc981027e4bea84b11" title="M.I.M.I.R - Now with visual intelligence built in for embeddings - MIT licensed - use with local ollama or llama.cpp for full control over your data" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Dense_Gate_5193"&gt; /u/Dense_Gate_5193 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/icw2e1nbj43g1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p56i8v/mimir_now_with_visual_intelligence_built_in_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p56i8v/mimir_now_with_visual_intelligence_built_in_for/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T03:29:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1p5hoqh</id>
    <title>Mistral-Small3.2:latest - Broken after a recent Ollama update?</title>
    <updated>2025-11-24T13:56:05+00:00</updated>
    <author>
      <name>/u/Comfortable_Ad_8117</name>
      <uri>https://old.reddit.com/user/Comfortable_Ad_8117</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p5hoqh/mistralsmall32latest_broken_after_a_recent_ollama/"&gt; &lt;img alt="Mistral-Small3.2:latest - Broken after a recent Ollama update?" src="https://b.thumbs.redditmedia.com/Rw0CGw1zj8CmJZE93FbqE6s_PBI7HNwH1lT2EDsSJss.jpg" title="Mistral-Small3.2:latest - Broken after a recent Ollama update?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Has anyone else seen this behavior? Repetitive characters when interacting with the 24b Mistral model? This was working fine until a recent update of Ollama. Any suggestions for an alternative model around the same size that has similar vision capability and instruction following skills. &lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/dzdq4ybhn73g1.png?width=1030&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=30993c9fa83fb47de7923593a007e0a3fc7677fa"&gt;https://preview.redd.it/dzdq4ybhn73g1.png?width=1030&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=30993c9fa83fb47de7923593a007e0a3fc7677fa&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Comfortable_Ad_8117"&gt; /u/Comfortable_Ad_8117 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5hoqh/mistralsmall32latest_broken_after_a_recent_ollama/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5hoqh/mistralsmall32latest_broken_after_a_recent_ollama/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p5hoqh/mistralsmall32latest_broken_after_a_recent_ollama/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T13:56:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1p5lwse</id>
    <title>Neural Network?</title>
    <updated>2025-11-24T16:40:04+00:00</updated>
    <author>
      <name>/u/spreader123</name>
      <uri>https://old.reddit.com/user/spreader123</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p5lwse/neural_network/"&gt; &lt;img alt="Neural Network?" src="https://b.thumbs.redditmedia.com/p3QvsuKFfOO8YLriXQxxpJVaY4BrKd-MO8_AO9SEQSg.jpg" title="Neural Network?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/spreader123"&gt; /u/spreader123 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/neuralnetworks/comments/1p5jjig/neural_network/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5lwse/neural_network/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p5lwse/neural_network/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T16:40:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1p5jy43</id>
    <title>archgw (0.3.20) - removed all (500mb) python deps in the request path. Ollama and Rust-first now</title>
    <updated>2025-11-24T15:27:32+00:00</updated>
    <author>
      <name>/u/AdditionalWeb107</name>
      <uri>https://old.reddit.com/user/AdditionalWeb107</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/katanemo/archgw"&gt;archgw&lt;/a&gt; (a models-native sidecar proxy for AI agents) offered two capabilities that required loading small LLMs in memory: guardrails to prevent jailbreak attempts, and function-calling for routing requests to the right downstream tool or agent. These built-in features required the project running a thread-safe python process that used libs like transformers, torch, safetensors, etc. 500M in dependencies, not to mention all the security vulnerabilities in the dep tree. Not hating on python, but our GH project was flagged with all sorts of issues.&lt;/p&gt; &lt;p&gt;Those models are loaded as a separate out-of-process server via ollama/lama.cpp which you all know are built in C++/Go. Lighter, faster and safer. And ONLY if the developer uses these features of the product. This meant 9000 lines of less code, a total start time of &amp;lt;2 seconds (vs 30+ seconds), etc.&lt;/p&gt; &lt;p&gt;Why archgw? So that you can build AI agents in any language or framework and offload the plumbing work in AI (like agent routing/hand-off, guardrails, zero-code logs and traces, and a unified API for all LLMs) to a durable piece of infrastructure, deployed as a sidecar.&lt;/p&gt; &lt;p&gt;Proud of this release, so sharing üôè&lt;/p&gt; &lt;p&gt;P.S Sample demos, the CLI and some tests still use python. But we'll move those over to Rust in the coming months. We are punting convenience for robustness.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/AdditionalWeb107"&gt; /u/AdditionalWeb107 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5jy43/archgw_0320_removed_all_500mb_python_deps_in_the/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5jy43/archgw_0320_removed_all_500mb_python_deps_in_the/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p5jy43/archgw_0320_removed_all_500mb_python_deps_in_the/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T15:27:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6avsq</id>
    <title>¬øSabes la diferencia real entre una Automatizaci√≥n y un Agente de IA? (Tutorial pr√°ctico con n8n + Ollama)</title>
    <updated>2025-11-25T12:13:13+00:00</updated>
    <author>
      <name>/u/jokiruiz</name>
      <uri>https://old.reddit.com/user/jokiruiz</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p6avsq/sabes_la_diferencia_real_entre_una_automatizaci√≥n/"&gt; &lt;img alt="¬øSabes la diferencia real entre una Automatizaci√≥n y un Agente de IA? (Tutorial pr√°ctico con n8n + Ollama)" src="https://external-preview.redd.it/nqPKqdngYJvGcJS6ivPJyKa3KnmmSEx91P350wT-I1k.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=54d6da8f05cbff9c460009be72022ed9388a71a8" title="¬øSabes la diferencia real entre una Automatizaci√≥n y un Agente de IA? (Tutorial pr√°ctico con n8n + Ollama)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hola a todos. He estado trasteando con agentes de IA locales y quer√≠a compartir un flujo de trabajo que cre√©.&lt;/p&gt; &lt;p&gt;Mucha gente confunde una automatizaci√≥n cl√°sica (Si A -&amp;gt; entonces B) con un Agente (que razona y decide).&lt;/p&gt; &lt;p&gt;En este tutorial explico c√≥mo construir un agente desde cero que:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Tiene &amp;quot;Cerebro&amp;quot; (usando Ollama en local).&lt;/li&gt; &lt;li&gt;Tiene &amp;quot;Memoria&amp;quot; (para recordar el contexto).&lt;/li&gt; &lt;li&gt;Usa &amp;quot;Herramientas&amp;quot; (se conecta a una API del clima para decidir qu√© ropa recomendarte).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Lo mejor es que est√° hecho con n8n y sin escribir c√≥digo. Si os interesa el mundo de los Agentes de IA o el No-Code, echadle un vistazo:&lt;/p&gt; &lt;p&gt;¬øAlguien m√°s aqu√≠ est√° usando n8n para orquestar IAs locales? ¬°Os leo!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jokiruiz"&gt; /u/jokiruiz &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://youtu.be/H0CwMDC3cYQ?si=N7bubLYtAhkv9vEZ"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6avsq/sabes_la_diferencia_real_entre_una_automatizaci√≥n/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6avsq/sabes_la_diferencia_real_entre_una_automatizaci√≥n/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T12:13:13+00:00</published>
  </entry>
  <entry>
    <id>t3_1p5lmcw</id>
    <title>Need clarifications or advice with coding and ollama.</title>
    <updated>2025-11-24T16:29:37+00:00</updated>
    <author>
      <name>/u/Lotus-006</name>
      <uri>https://old.reddit.com/user/Lotus-006</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello, i'm not sure if tbe models can works like in vscode for coding with ai like claude sonnet or gpt with agent mode.&lt;/p&gt; &lt;p&gt;i tried some days before but the speed to react was slow even with my hardware i9-13900k and 96gb ddr5 at 6800mhz and RTX Msi 5070ti oc 16gb gen 5&lt;/p&gt; &lt;p&gt;i tried with ollama and also on docker desktop but not very usefull as in vscode compared to claude or gpt.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Lotus-006"&gt; /u/Lotus-006 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5lmcw/need_clarifications_or_advice_with_coding_and/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p5lmcw/need_clarifications_or_advice_with_coding_and/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p5lmcw/need_clarifications_or_advice_with_coding_and/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-24T16:29:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1p66utd</id>
    <title>M.I.M.I.R - drag and drop graph task UI + lambdas - MIT License - use ollama completely local for offline task orchestration.</title>
    <updated>2025-11-25T08:03:55+00:00</updated>
    <author>
      <name>/u/Dense_Gate_5193</name>
      <uri>https://old.reddit.com/user/Dense_Gate_5193</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Dense_Gate_5193"&gt; /u/Dense_Gate_5193 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1p66tku"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p66utd/mimir_drag_and_drop_graph_task_ui_lambdas_mit/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p66utd/mimir_drag_and_drop_graph_task_ui_lambdas_mit/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T08:03:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1p61c5w</id>
    <title>Computer Use with Claude Opus 4.5</title>
    <updated>2025-11-25T02:56:09+00:00</updated>
    <author>
      <name>/u/Impressive_Half_2819</name>
      <uri>https://old.reddit.com/user/Impressive_Half_2819</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p61c5w/computer_use_with_claude_opus_45/"&gt; &lt;img alt="Computer Use with Claude Opus 4.5" src="https://external-preview.redd.it/cmp6aDE1OHBpYjNnMQ_ZQVTLVe7PyWJ0CuMi4sbpJgazjwD6JSk5JzpvEusC.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f15feb81f8963c61b65ccb94fb57dde4fdc42069" title="Computer Use with Claude Opus 4.5" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Computer Use with cua playground.&lt;/p&gt; &lt;p&gt;Claude Opus 4.5 is 80.9% on SWE Bench. Pretty good for agentic and computer use tasks.&lt;/p&gt; &lt;p&gt;Github : &lt;a href="https://github.com/trycua"&gt;https://github.com/trycua&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Try yourself : &lt;a href="https://cua.ai/"&gt;https://cua.ai/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Impressive_Half_2819"&gt; /u/Impressive_Half_2819 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/6hq5mthpib3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p61c5w/computer_use_with_claude_opus_45/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p61c5w/computer_use_with_claude_opus_45/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T02:56:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6345t</id>
    <title>Anyone doing an import of AI2's open-source Olmo3 model to Ollama?</title>
    <updated>2025-11-25T04:24:46+00:00</updated>
    <author>
      <name>/u/Conser-ai</name>
      <uri>https://old.reddit.com/user/Conser-ai</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Subject line says it all. We use Ollama and small LMs for AI research, running locally for reproducibility. The Olmo series is particularly attractive since one can also know what it is trained on, thereby eliminating potential for data contamination. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Conser-ai"&gt; /u/Conser-ai &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6345t/anyone_doing_an_import_of_ai2s_opensource_olmo3/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6345t/anyone_doing_an_import_of_ai2s_opensource_olmo3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6345t/anyone_doing_an_import_of_ai2s_opensource_olmo3/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T04:24:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6co7w</id>
    <title>When to use ollama cloud models like kimi-k2-thinking:cloud?</title>
    <updated>2025-11-25T13:39:19+00:00</updated>
    <author>
      <name>/u/PrudentCondition6672</name>
      <uri>https://old.reddit.com/user/PrudentCondition6672</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I would like to know the use cases where these models with big context window could be used.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/PrudentCondition6672"&gt; /u/PrudentCondition6672 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6co7w/when_to_use_ollama_cloud_models_like/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6co7w/when_to_use_ollama_cloud_models_like/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6co7w/when_to_use_ollama_cloud_models_like/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T13:39:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1p64o5b</id>
    <title>Askimo: Open source of Ollama native desktop client</title>
    <updated>2025-11-25T05:50:03+00:00</updated>
    <author>
      <name>/u/Revolutionary-Judge9</name>
      <uri>https://old.reddit.com/user/Revolutionary-Judge9</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I‚Äôve been building a desktop client called Askimo, and I use it with Ollama and other AI providers every day. I know there are already a lot of Ollama GUIs out there, but I kept running into the same problems: browser tabs slowing down, long chats eating memory, and losing good prompts I wanted to reuse.&lt;/p&gt; &lt;p&gt;This app actually started as a CLI tool I wrote for automation at work. After running into slowdowns and crashes in browser-based chats, I wanted something more solid, so I built a desktop client too. I treated myself as the first customer and added the features I kept wishing other apps had but never did, so I ended up creating the one I wanted to use.&lt;/p&gt; &lt;p&gt;I‚Äôve attached a short demo video if you want to see how it works.&lt;/p&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1p64o5b/video/du0zq92pbc3g1/player"&gt;Askimo Demo&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I also wrote a quick overview of the desktop client‚Äôs features on my blog. You can find everything here:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Installation page: &lt;a href="https://askimo.chat/docs/desktop/installation/"&gt;https://askimo.chat/docs/desktop/installation/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;GitHub links: &lt;a href="https://github.com/haiphucnguyen/askimo"&gt;https://github.com/haiphucnguyen/askimo&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Askimo desktop features: &lt;a href="https://askimo.chat/blog/askimo-with-ollama-the-best-desktop-for-local-ai/"&gt;https://askimo.chat/blog/askimo-with-ollama-the-best-desktop-for-local-ai/&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I‚Äôm planning to keep adding more features, so any feedback from the community is definitely welcome.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Revolutionary-Judge9"&gt; /u/Revolutionary-Judge9 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p64o5b/askimo_open_source_of_ollama_native_desktop_client/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p64o5b/askimo_open_source_of_ollama_native_desktop_client/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p64o5b/askimo_open_source_of_ollama_native_desktop_client/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T05:50:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6h3jx</id>
    <title>Which model would you recommend for coding in Python, React, HTML..?</title>
    <updated>2025-11-25T16:33:26+00:00</updated>
    <author>
      <name>/u/cinephileindia2023</name>
      <uri>https://old.reddit.com/user/cinephileindia2023</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;My PC has 128GB DDR4 RAM and I have an Intel Arc 770 with 16GB VRAM. Please suggest.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cinephileindia2023"&gt; /u/cinephileindia2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6h3jx/which_model_would_you_recommend_for_coding_in/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6h3jx/which_model_would_you_recommend_for_coding_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6h3jx/which_model_would_you_recommend_for_coding_in/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T16:33:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6hbt7</id>
    <title>Improve code based response</title>
    <updated>2025-11-25T16:42:02+00:00</updated>
    <author>
      <name>/u/TheHidden001</name>
      <uri>https://old.reddit.com/user/TheHidden001</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I want to get chatgpt-like responses where I can prompt things like &amp;quot;give a docker compose file for XYZ&amp;quot; and it do so. However I've tried gpt-oss, gemma3 and llama 2 and in spite of working on the system prompt to try to coax it into returning code blocks, all the models just want to provide me links and say &amp;quot;you can go look at this...&amp;quot; &lt;/p&gt; &lt;p&gt;Any guidance would be appropriate!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheHidden001"&gt; /u/TheHidden001 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6hbt7/improve_code_based_response/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6hbt7/improve_code_based_response/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6hbt7/improve_code_based_response/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T16:42:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6k8zw</id>
    <title>Newbie, very confused: ollama.chat with model qen3:4b returns wildly different responses depending on wheter format="json" or format="", with the exact same input</title>
    <updated>2025-11-25T18:28:18+00:00</updated>
    <author>
      <name>/u/Synes_Godt_Om</name>
      <uri>https://old.reddit.com/user/Synes_Godt_Om</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi, I hope this is the appropriate forum to as the following question.&lt;/p&gt; &lt;p&gt;The code below shows two calls with the exact same input and the output. The only difference (AFAICT) is that in the first case I set &lt;code&gt;format='json'&lt;/code&gt; and in the second I don't.&lt;/p&gt; &lt;p&gt;I'm asking what is the explanation and what is the solution.&lt;/p&gt; &lt;p&gt;Thanks for any input that can help me understand it. :)&lt;/p&gt; &lt;p&gt;The two outputs are completely different in almost every way.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;messages = [ ollama.Message(role=&amp;quot;system&amp;quot;, content=&amp;quot;Your are a helpful assistant.&amp;quot;), ollama.Message(role=&amp;quot;user&amp;quot;, content=&amp;quot;tell me about the world&amp;quot;), ] chat_response_json = ollama.chat( model=&amp;quot;qwen3:4b&amp;quot;, messages=messages, format=&amp;quot;json&amp;quot;, ) chat_response = ollama.chat( model=&amp;quot;qwen3:4b&amp;quot;, messages=messages, ) &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;json response&lt;/h1&gt; &lt;pre&gt;&lt;code&gt; print(chat_response_json.message.content) { &amp;quot;introduction&amp;quot;: &amp;quot;Hello! I'm Qwen, a large language model developed by Tongyi Lab. I'm here to help you with all sorts of questions and tasks. How can I assist you today?&amp;quot;, &amp;quot;response&amp;quot;: &amp;quot;The world is incredibly diverse and complex, with countless cultures, languages, and ecosystems. There are over 200 countries and territories, each with its own unique history, traditions, and challenges. The Earth's surface is covered by oceans, continents, and various climates, creating a rich tapestry of life. Human societies have developed technologies, economies, and social structures that have shaped our modern world. But it's also a place of constant change and uncertainty‚Äîclimate shifts, political tensions, and global health issues can impact everyone. Despite these challenges, people around the world are working together to build a better future through cooperation, innovation, and understanding. What specific aspect of the world would you like to explore further?&amp;quot; } &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;non-json response&lt;/h1&gt; &lt;pre&gt;&lt;code&gt; print(chat_response.message.content) &amp;lt;think&amp;gt; Okay, the user asked me to &amp;quot;tell me about the world.&amp;quot; That's a pretty broad question! I need to figure out what they really mean here. Are they looking for a general overview of the planet? Current global events? Scientific facts about Earth? Or maybe something more specific like cultural aspects? Hmm, since they didn't specify, I should cover the basics but keep it engaging. I remember they mentioned they want me to be helpful, so I'll aim for something informative but not too technical. Maybe start with Earth's position in the universe to give some cosmic context, then move to physical features, climate, biodiversity, human societies, and current issues. Wait, I should check if they're a kid or an adult. The query is vague, so I'll assume general interest. Better avoid jargon. Also, they might be curious about recent news‚Äîlike how the world is changing right now. I'll include some current events but not dive too deep to keep it balanced. I wonder if they want a fun fact or something. Maybe add a light-hearted note at the end to keep it friendly. Oh, and I should emphasize that the world is diverse and interconnected‚Äîpeople often forget how much we rely on each other globally. Let me structure this: 1. Quick cosmic context (to hook them) 2. Earth's physical traits (land, water, atmosphere) 3. Climate and environment (since it's critical now) 4. Human societies (cultural diversity, economies) 5. Current challenges (climate change, conflicts) 6. End with a hopeful but realistic note about cooperation I need to be careful not to overwhelm. Keep paragraphs short. Also, avoid political bias‚Äîstick to facts, not opinions. For example, when talking about conflicts, say &amp;quot;some regions face challenges&amp;quot; instead of naming specific countries. ... Wait, the user might actually be testing me? Like, is this a trick question? Nah, probably just curious. I'll go with the straightforward approach. *Double-checking*: Am I missing anything important? Oh‚Äîbiodiversity! Should mention how many species exist and why it matters. And maybe touch on technology's role in connecting people globally. Alright, time to write. I'll start with something warm to set the tone: &amp;quot;Hey there! üëã&amp;quot; feels friendly. Then dive in. *Final thought*: Make sure the response ends by inviting follow-up questions. They might have a specific interest they didn't state yet. Like, if they're into climate, they'll ask next. Keep it open. &amp;lt;/think&amp;gt; Hey there! üëã That's a **fantastic** question‚Äîand one that‚Äôs actually *super* interesting to answer! The world is incredibly diverse, complex, and constantly changing. I‚Äôll give you a **clear, balanced, and engaging** overview‚Äîno jargon, just the essentials. Think of it like a &amp;quot;quick tour&amp;quot; of our planet üåç: --- ### üåü **1. What *is* the world?** The &amp;quot;world&amp;quot; here means **Earth** (our planet) and the **human society** that lives on it. But to be precise: - **Geographically**: Earth is a rocky planet in the **Solar System**, orbiting the Sun. It‚Äôs the only place in the universe known to support life (so far!). - **Societally**: Over **8 billion people** live across 195+ countries, speaking 7,000+ languages, with cultures, economies, and traditions that are *staggeringly* diverse. &amp;gt; üí° **Fun fact**: Earth is **99.9% water** (oceans, seas, lakes) and **0.1% land**‚Äîbut life thrives *mostly* on land! --- ### üåç **2. What makes Earth unique?** Here‚Äôs what makes our planet special: | **Feature** | **Why it matters** | |-----------------------|---------------------------------------------------------------------------------| | **Climate** | Has seasons, weather patterns, and a *habitable* temperature range (thanks to the atmosphere). | | **Biodiversity** | ~8.7 million species (most undiscovered!)‚Äîfrom microbes to blue whales. Critical for ecosystems. | | **Tectonic Activity** | Earthquakes, volcanoes, and mountains form over time (e.g., the Himalayas). | | **Atmosphere** | Nitrogen (78%), oxygen (21%), and traces of CO‚ÇÇ, water vapor, and other gases. | --- ### üë§ **3. How humans shape the world** Humans have **deeply impacted** Earth in both positive and challenging ways: - **Positives**: - Technology ‚Üí internet, medicine, renewable energy. - Global cooperation ‚Üí climate agreements, disease research, peace efforts. - Cultural exchange ‚Üí food, art, language, traditions worldwide. - **Challenges**: - **Climate change** (rising temperatures, extreme weather). - **Inequality** (1 in 5 people live in poverty; gaps in education, health, and resources). - **Conflict** (some regions face war, displacement, or resource scarcity). &amp;gt; üå± **Key insight**: The world is **interconnected**‚Äîwhat happens in one place affects others (e.g., a drought in Africa can impact food prices globally). --- ### üåé **4. Current global trends (2024)** Here‚Äôs what‚Äôs *most relevant right now*: - üî• **Climate action**: 190+ countries have climate targets (like the Paris Agreement), but fossil fuels still dominate energy. - üí° **Tech &amp;amp; society**: AI is reshaping jobs, healthcare, and communication‚Äîbut also raising privacy and ethics questions. - üåê **Global unity**: People are more connected than ever (via social media, trade, travel), but divisions (like political polarization) remain. - ‚öñÔ∏è **Peace efforts**: Ongoing talks on Ukraine, Gaza, and climate diplomacy show both tension *and* hope for collaboration. --- ### üí´ **5. Why this matters to *you*** The world isn‚Äôt just &amp;quot;a place&amp;quot;‚Äîit‚Äôs **your home**. Understanding it helps you: - Make better choices (e.g., reducing waste, supporting fair trade). - Appreciate diversity (e.g., learning about cultures you‚Äôve never experienced). - Feel empowered (e.g., small actions like voting, volunteering, or sharing knowledge can create change). &amp;gt; üí¨ **Real talk**: The world is *hard* sometimes‚Äîbut it‚Äôs also **more resilient and hopeful than you might think**. People across the globe are working together on issues that matter (like clean water, education, or ending poverty). --- ### ‚úÖ **In a nutshell** &amp;gt; **The world is Earth + humanity**‚Äîa dynamic, interconnected system where life thrives despite challenges. It‚Äôs *diverse*, *changing*, and **full of potential**. If you‚Äôd like to dive deeper into **any part** of this (e.g., climate science, cultural traditions, tech impacts, or how you can help), just say the word! I‚Äôm here to explore with you. üòä *P.S. What‚Äôs one thing about the world that *you* find most fascinating or worrying? I‚Äôd love to hear your thoughts!* üå± &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Synes_Godt_Om"&gt; /u/Synes_Godt_Om &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k8zw/newbie_very_confused_ollamachat_with_model_qen34b/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k8zw/newbie_very_confused_ollamachat_with_model_qen34b/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6k8zw/newbie_very_confused_ollamachat_with_model_qen34b/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T18:28:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1p65zvj</id>
    <title>Worth using both qwen 3 and llama3.2 for Linux system engineering?</title>
    <updated>2025-11-25T07:09:15+00:00</updated>
    <author>
      <name>/u/Zecside</name>
      <uri>https://old.reddit.com/user/Zecside</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Just got interested in deploying an Llm model locally to help me in my daily tasks as Linux sysadmin and I wonder if it would be useful. Leaving confidentiality issues solved , For example Can it help in debugging and log analysis? In the sense , are its reponses relevant? Thanks ! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Zecside"&gt; /u/Zecside &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p65zvj/worth_using_both_qwen_3_and_llama32_for_linux/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p65zvj/worth_using_both_qwen_3_and_llama32_for_linux/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p65zvj/worth_using_both_qwen_3_and_llama32_for_linux/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T07:09:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6k70p</id>
    <title>I built ForgeIndex, a directory for local AI</title>
    <updated>2025-11-25T18:26:14+00:00</updated>
    <author>
      <name>/u/Equivalent-Ad-9798</name>
      <uri>https://old.reddit.com/user/Equivalent-Ad-9798</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone, I‚Äôve been toying around with local models lately and in my search for tools I realized everything was scattered across GitHub, discords, Reddit threads, etc.&lt;/p&gt; &lt;p&gt;So I built ForgeIndex, &lt;a href="https://forgeindex.ai"&gt;https://forgeindex.ai&lt;/a&gt;, to help me index them. It‚Äôs a lightweight directory for open source local AI projects from other creators. The projects link directly to their respective GitHub repo and anyone can upload either their own project or someone else‚Äôs, there‚Äôs no accounts yet. The goal is to make it as easy as possible for users to discover new projects. It‚Äôs also mobile friendly so you can browse wherever you are.&lt;/p&gt; &lt;p&gt;I do have a long roadmap of features I have planned like user ratings, browse by category, accounts, creator pages, etc. In the meantime, if anyone has any suggestions or questions feel free to ask. Thanks so much for taking the time to read this post and I look forward to building with the community!&lt;/p&gt; &lt;p&gt;&lt;a href="https://forgeindex.ai"&gt;https://forgeindex.ai&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Equivalent-Ad-9798"&gt; /u/Equivalent-Ad-9798 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k70p/i_built_forgeindex_a_directory_for_local_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k70p/i_built_forgeindex_a_directory_for_local_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6k70p/i_built_forgeindex_a_directory_for_local_ai/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T18:26:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6ksif</id>
    <title>I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp; Private)</title>
    <updated>2025-11-25T18:48:21+00:00</updated>
    <author>
      <name>/u/sebastiankeller0205</name>
      <uri>https://old.reddit.com/user/sebastiankeller0205</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p6ksif/i_built_a_fully_local_offline_jarvis_using_python/"&gt; &lt;img alt="I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp;amp; Private)" src="https://external-preview.redd.it/ejlob3Fibmk4ZzNnMadeDPBN4xSc3qzffa_ecA_6QtCWYZC9kx9P5-kBQoJ9.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5790bebfc77514c0b5ef554bd6036f1e79bb3c92" title="I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp;amp; Private)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone! I wanted to share a project I've been working on. It's a fully functional, local AI assistant inspired by Iron Man's J.A.R.V.I.S.&lt;/p&gt; &lt;p&gt;I wanted something that runs &lt;strong&gt;locally&lt;/strong&gt; on my PC (for privacy and speed) but still has a personality.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;üé• Watch the video to see the HUD and Voice interaction in action!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;‚ö° Key Features:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;100% Local Brain:&lt;/strong&gt; Uses &lt;strong&gt;Ollama&lt;/strong&gt; (running the &lt;code&gt;dolphin-phi&lt;/code&gt; model) so it works offline and keeps data private.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Uncensored Persona:&lt;/strong&gt; Custom &amp;quot;God Mode&amp;quot; system prompts to bypass standard AI refusals.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Sci-Fi HUD:&lt;/strong&gt; Built with &lt;strong&gt;OpenCV&lt;/strong&gt; and &lt;strong&gt;Pillow&lt;/strong&gt;. It features a live video wallpaper, real-time CPU/RAM stats, and a &amp;quot;typewriter&amp;quot; effect for captions.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;System Automation:&lt;/strong&gt; Can open/close apps, create folders, and take screenshots via voice commands.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Dual Identity:&lt;/strong&gt; Seamlessly switches between &amp;quot;Jarvis&amp;quot; (Male) and &amp;quot;Friday&amp;quot; (Female) voices and personas.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Hybrid Control:&lt;/strong&gt; Supports both Voice Commands (SpeechRecognition) and a direct Text Input terminal on the HUD.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sebastiankeller0205"&gt; /u/sebastiankeller0205 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/vzwvvgji8g3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6ksif/i_built_a_fully_local_offline_jarvis_using_python/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6ksif/i_built_a_fully_local_offline_jarvis_using_python/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T18:48:21+00:00</published>
  </entry>
</feed>
