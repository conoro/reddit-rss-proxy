<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/ollama/.rss</id>
  <title>ollama</title>
  <updated>2025-11-26T21:34:44+00:00</updated>
  <link href="https://old.reddit.com/r/ollama/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Atom feed for r/ollama</subtitle>
  <entry>
    <id>t3_1p66utd</id>
    <title>M.I.M.I.R - drag and drop graph task UI + lambdas - MIT License - use ollama completely local for offline task orchestration.</title>
    <updated>2025-11-25T08:03:55+00:00</updated>
    <author>
      <name>/u/Dense_Gate_5193</name>
      <uri>https://old.reddit.com/user/Dense_Gate_5193</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Dense_Gate_5193"&gt; /u/Dense_Gate_5193 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1p66tku"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p66utd/mimir_drag_and_drop_graph_task_ui_lambdas_mit/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p66utd/mimir_drag_and_drop_graph_task_ui_lambdas_mit/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T08:03:55+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6pbjn</id>
    <title>I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp; Private)</title>
    <updated>2025-11-25T21:37:27+00:00</updated>
    <author>
      <name>/u/sebastiankeller0205</name>
      <uri>https://old.reddit.com/user/sebastiankeller0205</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p6pbjn/i_built_a_fully_local_offline_jarvis_using_python/"&gt; &lt;img alt="I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp;amp; Private)" src="https://external-preview.redd.it/4mv6xToVPp6IvykKnZuNWjXgGO03QF9fkswGHNzeCAY.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e360d347d6e217b15b3ec92698944699b5b2f6ba" title="I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp;amp; Private)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sebastiankeller0205"&gt; /u/sebastiankeller0205 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/4eiuyr0s8g3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6pbjn/i_built_a_fully_local_offline_jarvis_using_python/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6pbjn/i_built_a_fully_local_offline_jarvis_using_python/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T21:37:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6345t</id>
    <title>Anyone doing an import of AI2's open-source Olmo3 model to Ollama?</title>
    <updated>2025-11-25T04:24:46+00:00</updated>
    <author>
      <name>/u/Conser-ai</name>
      <uri>https://old.reddit.com/user/Conser-ai</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Subject line says it all. We use Ollama and small LMs for AI research, running locally for reproducibility. The Olmo series is particularly attractive since one can also know what it is trained on, thereby eliminating potential for data contamination. Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Conser-ai"&gt; /u/Conser-ai &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6345t/anyone_doing_an_import_of_ai2s_opensource_olmo3/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6345t/anyone_doing_an_import_of_ai2s_opensource_olmo3/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6345t/anyone_doing_an_import_of_ai2s_opensource_olmo3/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T04:24:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6co7w</id>
    <title>When to use ollama cloud models like kimi-k2-thinking:cloud?</title>
    <updated>2025-11-25T13:39:19+00:00</updated>
    <author>
      <name>/u/PrudentCondition6672</name>
      <uri>https://old.reddit.com/user/PrudentCondition6672</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I would like to know the use cases where these models with big context window could be used.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/PrudentCondition6672"&gt; /u/PrudentCondition6672 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6co7w/when_to_use_ollama_cloud_models_like/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6co7w/when_to_use_ollama_cloud_models_like/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6co7w/when_to_use_ollama_cloud_models_like/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T13:39:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1p61c5w</id>
    <title>Computer Use with Claude Opus 4.5</title>
    <updated>2025-11-25T02:56:09+00:00</updated>
    <author>
      <name>/u/Impressive_Half_2819</name>
      <uri>https://old.reddit.com/user/Impressive_Half_2819</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p61c5w/computer_use_with_claude_opus_45/"&gt; &lt;img alt="Computer Use with Claude Opus 4.5" src="https://external-preview.redd.it/cmp6aDE1OHBpYjNnMQ_ZQVTLVe7PyWJ0CuMi4sbpJgazjwD6JSk5JzpvEusC.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f15feb81f8963c61b65ccb94fb57dde4fdc42069" title="Computer Use with Claude Opus 4.5" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Computer Use with cua playground.&lt;/p&gt; &lt;p&gt;Claude Opus 4.5 is 80.9% on SWE Bench. Pretty good for agentic and computer use tasks.&lt;/p&gt; &lt;p&gt;Github : &lt;a href="https://github.com/trycua"&gt;https://github.com/trycua&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Try yourself : &lt;a href="https://cua.ai/"&gt;https://cua.ai/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Impressive_Half_2819"&gt; /u/Impressive_Half_2819 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/6hq5mthpib3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p61c5w/computer_use_with_claude_opus_45/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p61c5w/computer_use_with_claude_opus_45/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T02:56:09+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6h3jx</id>
    <title>Which model would you recommend for coding in Python, React, HTML..?</title>
    <updated>2025-11-25T16:33:26+00:00</updated>
    <author>
      <name>/u/cinephileindia2023</name>
      <uri>https://old.reddit.com/user/cinephileindia2023</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;My PC has 128GB DDR4 RAM and I have an Intel Arc 770 with 16GB VRAM. Please suggest.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cinephileindia2023"&gt; /u/cinephileindia2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6h3jx/which_model_would_you_recommend_for_coding_in/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6h3jx/which_model_would_you_recommend_for_coding_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6h3jx/which_model_would_you_recommend_for_coding_in/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T16:33:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6hbt7</id>
    <title>Improve code based response</title>
    <updated>2025-11-25T16:42:02+00:00</updated>
    <author>
      <name>/u/TheHidden001</name>
      <uri>https://old.reddit.com/user/TheHidden001</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I want to get chatgpt-like responses where I can prompt things like &amp;quot;give a docker compose file for XYZ&amp;quot; and it do so. However I've tried gpt-oss, gemma3 and llama 2 and in spite of working on the system prompt to try to coax it into returning code blocks, all the models just want to provide me links and say &amp;quot;you can go look at this...&amp;quot; &lt;/p&gt; &lt;p&gt;Any guidance would be appropriate!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheHidden001"&gt; /u/TheHidden001 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6hbt7/improve_code_based_response/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6hbt7/improve_code_based_response/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6hbt7/improve_code_based_response/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T16:42:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1p64o5b</id>
    <title>Askimo: Open source of Ollama native desktop client</title>
    <updated>2025-11-25T05:50:03+00:00</updated>
    <author>
      <name>/u/Revolutionary-Judge9</name>
      <uri>https://old.reddit.com/user/Revolutionary-Judge9</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I‚Äôve been building a desktop client called Askimo, and I use it with Ollama and other AI providers every day. I know there are already a lot of Ollama GUIs out there, but I kept running into the same problems: browser tabs slowing down, long chats eating memory, and losing good prompts I wanted to reuse.&lt;/p&gt; &lt;p&gt;This app actually started as a CLI tool I wrote for automation at work. After running into slowdowns and crashes in browser-based chats, I wanted something more solid, so I built a desktop client too. I treated myself as the first customer and added the features I kept wishing other apps had but never did, so I ended up creating the one I wanted to use.&lt;/p&gt; &lt;p&gt;I‚Äôve attached a short demo video if you want to see how it works.&lt;/p&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1p64o5b/video/du0zq92pbc3g1/player"&gt;Askimo Demo&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I also wrote a quick overview of the desktop client‚Äôs features on my blog. You can find everything here:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Installation page: &lt;a href="https://askimo.chat/docs/desktop/installation/"&gt;https://askimo.chat/docs/desktop/installation/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;GitHub links: &lt;a href="https://github.com/haiphucnguyen/askimo"&gt;https://github.com/haiphucnguyen/askimo&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Askimo desktop features: &lt;a href="https://askimo.chat/blog/askimo-with-ollama-the-best-desktop-for-local-ai/"&gt;https://askimo.chat/blog/askimo-with-ollama-the-best-desktop-for-local-ai/&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I‚Äôm planning to keep adding more features, so any feedback from the community is definitely welcome.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Revolutionary-Judge9"&gt; /u/Revolutionary-Judge9 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p64o5b/askimo_open_source_of_ollama_native_desktop_client/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p64o5b/askimo_open_source_of_ollama_native_desktop_client/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p64o5b/askimo_open_source_of_ollama_native_desktop_client/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T05:50:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6k8zw</id>
    <title>Newbie, very confused: ollama.chat with model qen3:4b returns wildly different responses depending on wheter format="json" or format="", with the exact same input</title>
    <updated>2025-11-25T18:28:18+00:00</updated>
    <author>
      <name>/u/Synes_Godt_Om</name>
      <uri>https://old.reddit.com/user/Synes_Godt_Om</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi, I hope this is the appropriate forum to as the following question.&lt;/p&gt; &lt;p&gt;The code below shows two calls with the exact same input and the output. The only difference (AFAICT) is that in the first case I set &lt;code&gt;format='json'&lt;/code&gt; and in the second I don't.&lt;/p&gt; &lt;p&gt;I'm asking what is the explanation and what is the solution.&lt;/p&gt; &lt;p&gt;Thanks for any input that can help me understand it. :)&lt;/p&gt; &lt;p&gt;The two outputs are completely different in almost every way.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;messages = [ ollama.Message(role=&amp;quot;system&amp;quot;, content=&amp;quot;Your are a helpful assistant.&amp;quot;), ollama.Message(role=&amp;quot;user&amp;quot;, content=&amp;quot;tell me about the world&amp;quot;), ] chat_response_json = ollama.chat( model=&amp;quot;qwen3:4b&amp;quot;, messages=messages, format=&amp;quot;json&amp;quot;, ) chat_response = ollama.chat( model=&amp;quot;qwen3:4b&amp;quot;, messages=messages, ) &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;json response&lt;/h1&gt; &lt;pre&gt;&lt;code&gt; print(chat_response_json.message.content) { &amp;quot;introduction&amp;quot;: &amp;quot;Hello! I'm Qwen, a large language model developed by Tongyi Lab. I'm here to help you with all sorts of questions and tasks. How can I assist you today?&amp;quot;, &amp;quot;response&amp;quot;: &amp;quot;The world is incredibly diverse and complex, with countless cultures, languages, and ecosystems. There are over 200 countries and territories, each with its own unique history, traditions, and challenges. The Earth's surface is covered by oceans, continents, and various climates, creating a rich tapestry of life. Human societies have developed technologies, economies, and social structures that have shaped our modern world. But it's also a place of constant change and uncertainty‚Äîclimate shifts, political tensions, and global health issues can impact everyone. Despite these challenges, people around the world are working together to build a better future through cooperation, innovation, and understanding. What specific aspect of the world would you like to explore further?&amp;quot; } &lt;/code&gt;&lt;/pre&gt; &lt;h1&gt;non-json response&lt;/h1&gt; &lt;pre&gt;&lt;code&gt; print(chat_response.message.content) &amp;lt;think&amp;gt; Okay, the user asked me to &amp;quot;tell me about the world.&amp;quot; That's a pretty broad question! I need to figure out what they really mean here. Are they looking for a general overview of the planet? Current global events? Scientific facts about Earth? Or maybe something more specific like cultural aspects? Hmm, since they didn't specify, I should cover the basics but keep it engaging. I remember they mentioned they want me to be helpful, so I'll aim for something informative but not too technical. Maybe start with Earth's position in the universe to give some cosmic context, then move to physical features, climate, biodiversity, human societies, and current issues. Wait, I should check if they're a kid or an adult. The query is vague, so I'll assume general interest. Better avoid jargon. Also, they might be curious about recent news‚Äîlike how the world is changing right now. I'll include some current events but not dive too deep to keep it balanced. I wonder if they want a fun fact or something. Maybe add a light-hearted note at the end to keep it friendly. Oh, and I should emphasize that the world is diverse and interconnected‚Äîpeople often forget how much we rely on each other globally. Let me structure this: 1. Quick cosmic context (to hook them) 2. Earth's physical traits (land, water, atmosphere) 3. Climate and environment (since it's critical now) 4. Human societies (cultural diversity, economies) 5. Current challenges (climate change, conflicts) 6. End with a hopeful but realistic note about cooperation I need to be careful not to overwhelm. Keep paragraphs short. Also, avoid political bias‚Äîstick to facts, not opinions. For example, when talking about conflicts, say &amp;quot;some regions face challenges&amp;quot; instead of naming specific countries. ... Wait, the user might actually be testing me? Like, is this a trick question? Nah, probably just curious. I'll go with the straightforward approach. *Double-checking*: Am I missing anything important? Oh‚Äîbiodiversity! Should mention how many species exist and why it matters. And maybe touch on technology's role in connecting people globally. Alright, time to write. I'll start with something warm to set the tone: &amp;quot;Hey there! üëã&amp;quot; feels friendly. Then dive in. *Final thought*: Make sure the response ends by inviting follow-up questions. They might have a specific interest they didn't state yet. Like, if they're into climate, they'll ask next. Keep it open. &amp;lt;/think&amp;gt; Hey there! üëã That's a **fantastic** question‚Äîand one that‚Äôs actually *super* interesting to answer! The world is incredibly diverse, complex, and constantly changing. I‚Äôll give you a **clear, balanced, and engaging** overview‚Äîno jargon, just the essentials. Think of it like a &amp;quot;quick tour&amp;quot; of our planet üåç: --- ### üåü **1. What *is* the world?** The &amp;quot;world&amp;quot; here means **Earth** (our planet) and the **human society** that lives on it. But to be precise: - **Geographically**: Earth is a rocky planet in the **Solar System**, orbiting the Sun. It‚Äôs the only place in the universe known to support life (so far!). - **Societally**: Over **8 billion people** live across 195+ countries, speaking 7,000+ languages, with cultures, economies, and traditions that are *staggeringly* diverse. &amp;gt; üí° **Fun fact**: Earth is **99.9% water** (oceans, seas, lakes) and **0.1% land**‚Äîbut life thrives *mostly* on land! --- ### üåç **2. What makes Earth unique?** Here‚Äôs what makes our planet special: | **Feature** | **Why it matters** | |-----------------------|---------------------------------------------------------------------------------| | **Climate** | Has seasons, weather patterns, and a *habitable* temperature range (thanks to the atmosphere). | | **Biodiversity** | ~8.7 million species (most undiscovered!)‚Äîfrom microbes to blue whales. Critical for ecosystems. | | **Tectonic Activity** | Earthquakes, volcanoes, and mountains form over time (e.g., the Himalayas). | | **Atmosphere** | Nitrogen (78%), oxygen (21%), and traces of CO‚ÇÇ, water vapor, and other gases. | --- ### üë§ **3. How humans shape the world** Humans have **deeply impacted** Earth in both positive and challenging ways: - **Positives**: - Technology ‚Üí internet, medicine, renewable energy. - Global cooperation ‚Üí climate agreements, disease research, peace efforts. - Cultural exchange ‚Üí food, art, language, traditions worldwide. - **Challenges**: - **Climate change** (rising temperatures, extreme weather). - **Inequality** (1 in 5 people live in poverty; gaps in education, health, and resources). - **Conflict** (some regions face war, displacement, or resource scarcity). &amp;gt; üå± **Key insight**: The world is **interconnected**‚Äîwhat happens in one place affects others (e.g., a drought in Africa can impact food prices globally). --- ### üåé **4. Current global trends (2024)** Here‚Äôs what‚Äôs *most relevant right now*: - üî• **Climate action**: 190+ countries have climate targets (like the Paris Agreement), but fossil fuels still dominate energy. - üí° **Tech &amp;amp; society**: AI is reshaping jobs, healthcare, and communication‚Äîbut also raising privacy and ethics questions. - üåê **Global unity**: People are more connected than ever (via social media, trade, travel), but divisions (like political polarization) remain. - ‚öñÔ∏è **Peace efforts**: Ongoing talks on Ukraine, Gaza, and climate diplomacy show both tension *and* hope for collaboration. --- ### üí´ **5. Why this matters to *you*** The world isn‚Äôt just &amp;quot;a place&amp;quot;‚Äîit‚Äôs **your home**. Understanding it helps you: - Make better choices (e.g., reducing waste, supporting fair trade). - Appreciate diversity (e.g., learning about cultures you‚Äôve never experienced). - Feel empowered (e.g., small actions like voting, volunteering, or sharing knowledge can create change). &amp;gt; üí¨ **Real talk**: The world is *hard* sometimes‚Äîbut it‚Äôs also **more resilient and hopeful than you might think**. People across the globe are working together on issues that matter (like clean water, education, or ending poverty). --- ### ‚úÖ **In a nutshell** &amp;gt; **The world is Earth + humanity**‚Äîa dynamic, interconnected system where life thrives despite challenges. It‚Äôs *diverse*, *changing*, and **full of potential**. If you‚Äôd like to dive deeper into **any part** of this (e.g., climate science, cultural traditions, tech impacts, or how you can help), just say the word! I‚Äôm here to explore with you. üòä *P.S. What‚Äôs one thing about the world that *you* find most fascinating or worrying? I‚Äôd love to hear your thoughts!* üå± &lt;/code&gt;&lt;/pre&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Synes_Godt_Om"&gt; /u/Synes_Godt_Om &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k8zw/newbie_very_confused_ollamachat_with_model_qen34b/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k8zw/newbie_very_confused_ollamachat_with_model_qen34b/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6k8zw/newbie_very_confused_ollamachat_with_model_qen34b/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T18:28:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6te1v</id>
    <title>which providers does Ollama cloud use ? and what are the actual limits for pro plans?</title>
    <updated>2025-11-26T00:27:25+00:00</updated>
    <author>
      <name>/u/Brilliant-Vehicle994</name>
      <uri>https://old.reddit.com/user/Brilliant-Vehicle994</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey everyone &lt;/p&gt; &lt;p&gt;Has it ever been disclosed which providers does ollama cloud llm use ?&lt;/p&gt; &lt;p&gt;Also what are the usage limits for their premium plans , it currently just say &lt;/p&gt; &lt;p&gt;Max&lt;/p&gt; &lt;h1&gt;$100/mo&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;5x more model usage&lt;/li&gt; &lt;li&gt;5x premium model requests&lt;/li&gt; &lt;li&gt;Access to Gemini 3 Pro Preview and other premium models &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Can it be used for enterprise apps with high usage ?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Brilliant-Vehicle994"&gt; /u/Brilliant-Vehicle994 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6te1v/which_providers_does_ollama_cloud_use_and_what/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6te1v/which_providers_does_ollama_cloud_use_and_what/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6te1v/which_providers_does_ollama_cloud_use_and_what/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T00:27:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6zcua</id>
    <title>Update: Added a Thermal Map, radar, and kill switch to my Python/OLLAMA J.A.R.V.I.S. HUD</title>
    <updated>2025-11-26T05:18:59+00:00</updated>
    <author>
      <name>/u/sebastiankeller0205</name>
      <uri>https://old.reddit.com/user/sebastiankeller0205</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p6zcua/update_added_a_thermal_map_radar_and_kill_switch/"&gt; &lt;img alt="Update: Added a Thermal Map, radar, and kill switch to my Python/OLLAMA J.A.R.V.I.S. HUD" src="https://external-preview.redd.it/Z2ZrM3V5bnNjajNnMZp5IY_SZKcdLsFezUK5V8jRpnVeC-4DflOcgzCh9oPu.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b98ca8183603f777d5d024101fd0846a42d6daea" title="Update: Added a Thermal Map, radar, and kill switch to my Python/OLLAMA J.A.R.V.I.S. HUD" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I‚Äôm back with a massive update to my J.A.R.V.I.S. desktop HUD, I‚Äôve expanded the python script (using Open CV and psutil) to include a live thermal heat map for CPU temps a network device proximity radar a fan curve visualizer and even a working process kill switch for stubborn apps It is fully functional and pulls real-time data while running transparently over the wallpaper. I am currently finalizing the code cleanup for a public release but if you want early access to the repository to try it out, just DM me and I will send it your way.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sebastiankeller0205"&gt; /u/sebastiankeller0205 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/xgw7bblscj3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6zcua/update_added_a_thermal_map_radar_and_kill_switch/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6zcua/update_added_a_thermal_map_radar_and_kill_switch/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T05:18:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1p65zvj</id>
    <title>Worth using both qwen 3 and llama3.2 for Linux system engineering?</title>
    <updated>2025-11-25T07:09:15+00:00</updated>
    <author>
      <name>/u/Zecside</name>
      <uri>https://old.reddit.com/user/Zecside</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Just got interested in deploying an Llm model locally to help me in my daily tasks as Linux sysadmin and I wonder if it would be useful. Leaving confidentiality issues solved , For example Can it help in debugging and log analysis? In the sense , are its reponses relevant? Thanks ! &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Zecside"&gt; /u/Zecside &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p65zvj/worth_using_both_qwen_3_and_llama32_for_linux/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p65zvj/worth_using_both_qwen_3_and_llama32_for_linux/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p65zvj/worth_using_both_qwen_3_and_llama32_for_linux/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T07:09:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6k70p</id>
    <title>I built ForgeIndex, a directory for local AI</title>
    <updated>2025-11-25T18:26:14+00:00</updated>
    <author>
      <name>/u/Equivalent-Ad-9798</name>
      <uri>https://old.reddit.com/user/Equivalent-Ad-9798</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone, I‚Äôve been toying around with local models lately and in my search for tools I realized everything was scattered across GitHub, discords, Reddit threads, etc.&lt;/p&gt; &lt;p&gt;So I built ForgeIndex, &lt;a href="https://forgeindex.ai"&gt;https://forgeindex.ai&lt;/a&gt;, to help me index them. It‚Äôs a lightweight directory for open source local AI projects from other creators. The projects link directly to their respective GitHub repo and anyone can upload either their own project or someone else‚Äôs, there‚Äôs no accounts yet. The goal is to make it as easy as possible for users to discover new projects. It‚Äôs also mobile friendly so you can browse wherever you are.&lt;/p&gt; &lt;p&gt;I do have a long roadmap of features I have planned like user ratings, browse by category, accounts, creator pages, etc. In the meantime, if anyone has any suggestions or questions feel free to ask. Thanks so much for taking the time to read this post and I look forward to building with the community!&lt;/p&gt; &lt;p&gt;&lt;a href="https://forgeindex.ai"&gt;https://forgeindex.ai&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Equivalent-Ad-9798"&gt; /u/Equivalent-Ad-9798 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k70p/i_built_forgeindex_a_directory_for_local_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6k70p/i_built_forgeindex_a_directory_for_local_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6k70p/i_built_forgeindex_a_directory_for_local_ai/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T18:26:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6upfe</id>
    <title>M.I.M.I.R - NornicDB - cognitive-inspired vector native DB - golang - MIT license - neo4j compatible</title>
    <updated>2025-11-26T01:27:44+00:00</updated>
    <author>
      <name>/u/Dense_Gate_5193</name>
      <uri>https://old.reddit.com/user/Dense_Gate_5193</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Dense_Gate_5193"&gt; /u/Dense_Gate_5193 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/ChatGPTCoding/comments/1p6um8w/mimir_nornicdb_cognitiveinspired_vector_native_db/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6upfe/mimir_nornicdb_cognitiveinspired_vector_native_db/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6upfe/mimir_nornicdb_cognitiveinspired_vector_native_db/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T01:27:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6p7x8</id>
    <title>Genuine question : NEWBIE ALERT</title>
    <updated>2025-11-25T21:33:31+00:00</updated>
    <author>
      <name>/u/Moumene_69420</name>
      <uri>https://old.reddit.com/user/Moumene_69420</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;HI , i am new to the Ollama thing i just tested it like a year ago with deepseek i think it was 7B and now i am using qwen3:1.7b and i want to turn it uncensored and give it memory , RAG and internet access , but i do not know how , any videos tricks or courses books , just any ressource to help will be good&lt;/p&gt; &lt;p&gt;also i use it on linux so just the CLI , but i am thinking of giving it some sloppy UI if i have too &lt;/p&gt; &lt;p&gt;thanks in advance &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Moumene_69420"&gt; /u/Moumene_69420 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6p7x8/genuine_question_newbie_alert/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6p7x8/genuine_question_newbie_alert/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6p7x8/genuine_question_newbie_alert/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T21:33:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6svcr</id>
    <title>Power consumption of short queries vs verbose ones?</title>
    <updated>2025-11-26T00:04:22+00:00</updated>
    <author>
      <name>/u/offeredthrowaway</name>
      <uri>https://old.reddit.com/user/offeredthrowaway</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Trying to benchmark different simple factual queries. eg. What is the capital of France vs France Capital&lt;/p&gt; &lt;p&gt;Anyone around here come across or have run your own benchmarks?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/offeredthrowaway"&gt; /u/offeredthrowaway &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6svcr/power_consumption_of_short_queries_vs_verbose_ones/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6svcr/power_consumption_of_short_queries_vs_verbose_ones/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6svcr/power_consumption_of_short_queries_vs_verbose_ones/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T00:04:22+00:00</published>
  </entry>
  <entry>
    <id>t3_1p708k3</id>
    <title>I made a free site with file tools + a local AI chat that connects to Ollama</title>
    <updated>2025-11-26T06:08:00+00:00</updated>
    <author>
      <name>/u/opal-emporium</name>
      <uri>https://old.reddit.com/user/opal-emporium</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/opal-emporium"&gt; /u/opal-emporium &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/LocalLLaMA/comments/1p707ev/i_made_a_free_site_with_file_tools_a_local_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p708k3/i_made_a_free_site_with_file_tools_a_local_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p708k3/i_made_a_free_site_with_file_tools_a_local_ai/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T06:08:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6zmij</id>
    <title>Synology AI Console to Ollama, won‚Äôt work with all models.</title>
    <updated>2025-11-26T05:33:34+00:00</updated>
    <author>
      <name>/u/shooter808</name>
      <uri>https://old.reddit.com/user/shooter808</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;TLDR: it works! But not with my model of choice. Hopefully a fix by Ollama and/or Synology is coming. Posting here in case someone else was encountering the same issue and save them some time.&lt;/p&gt; &lt;p&gt;Post: Now that Synology AI console supports locally hosted AI, I hooked it up to Ollama to see how well it does. Coupled with Synology Office it feels great having my own private AI help me get stuff done. However, it doesn‚Äôt appear to support all models as I‚Äôve only gotten it to work with Llama3.2:3b. It failed to verify on gpt-oss:20b and deepseek-r1.&lt;/p&gt; &lt;p&gt;Synology‚Äôs response was: After a thorough review with our development team, we found that Synology AI Console requires models to support the OpenAI-compatible parameter tool_choice: required to verify tool usage capabilities. However, Ollama currently does not support the tool_choice parameter, so even though the gpt-oss:20b model supports tool use internally, the Console mistakenly flags it as unsupported.&lt;/p&gt; &lt;p&gt;Really excited to see what the future holds for NAS platforms that utilize local AI tools like Ollama. Looking forward to a private chatbot that can organize, summarize, and auto tag all my files.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/shooter808"&gt; /u/shooter808 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6zmij/synology_ai_console_to_ollama_wont_work_with_all/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6zmij/synology_ai_console_to_ollama_wont_work_with_all/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6zmij/synology_ai_console_to_ollama_wont_work_with_all/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T05:33:34+00:00</published>
  </entry>
  <entry>
    <id>t3_1p75i0r</id>
    <title>Big Stability + UI Update for My Offline AI App - Dark Mode, Image Preview &amp; Voice Features Added</title>
    <updated>2025-11-26T11:35:19+00:00</updated>
    <author>
      <name>/u/ConstructionLegal613</name>
      <uri>https://old.reddit.com/user/ConstructionLegal613</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p75i0r/big_stability_ui_update_for_my_offline_ai_app/"&gt; &lt;img alt="Big Stability + UI Update for My Offline AI App - Dark Mode, Image Preview &amp;amp; Voice Features Added" src="https://b.thumbs.redditmedia.com/Owe31r4JxBMYUuyu7tJjCqg8w_qiRlEUbyyawGpKUYM.jpg" title="Big Stability + UI Update for My Offline AI App - Dark Mode, Image Preview &amp;amp; Voice Features Added" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt; &lt;p&gt;I‚Äôve just shipped a new update to Private Mind ‚Äì my fully offline AI app for iOS/macOS and wanted to share what‚Äôs new.&lt;/p&gt; &lt;p&gt;- What‚Äôs New in This Update&lt;/p&gt; &lt;p&gt;Here‚Äôs everything I improved over the last 2 days:&lt;/p&gt; &lt;p&gt;- Dark Mode + Light Mode&lt;/p&gt; &lt;p&gt;The entire UI now adapts automatically or can be switched manually.&lt;/p&gt; &lt;p&gt;- Improved UI &amp;amp; smoother layout&lt;/p&gt; &lt;p&gt;Cleaner message bubbles, better spacing, refined toolbar icons, and an overall more polished look.&lt;/p&gt; &lt;p&gt;- Much better error handling&lt;/p&gt; &lt;p&gt;If a model can‚Äôt load or the device doesn‚Äôt have enough RAM, the app now shows a safe message instead of crashing.&lt;/p&gt; &lt;p&gt;- 0 crashes in the last 48h&lt;/p&gt; &lt;p&gt;Stability is way better now thanks to everyone who reported issues earlier.&lt;/p&gt; &lt;p&gt;- Image preview inside chat&lt;/p&gt; &lt;p&gt;When you take a photo for OCR, you can now tap to view the full image inside the chat thread.&lt;/p&gt; &lt;p&gt;- Voice playback improvements&lt;/p&gt; &lt;p&gt;You can now play generated audio responses smoothly inside the chat.&lt;/p&gt; &lt;p&gt;- About the App&lt;/p&gt; &lt;p&gt;Private Mind is a local-only AI assistant that runs entirely offline no cloud, no logins, no tracking.&lt;/p&gt; &lt;p&gt;Models run directly on your device.&lt;/p&gt; &lt;p&gt;App Store:&lt;/p&gt; &lt;p&gt;&lt;a href="https://apps.apple.com/us/app/private-mind-offline-ai/id6754819594"&gt;https://apps.apple.com/us/app/private-mind-offline-ai/id6754819594&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ConstructionLegal613"&gt; /u/ConstructionLegal613 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1p75i0r"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p75i0r/big_stability_ui_update_for_my_offline_ai_app/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p75i0r/big_stability_ui_update_for_my_offline_ai_app/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T11:35:19+00:00</published>
  </entry>
  <entry>
    <id>t3_1p7eejz</id>
    <title>Sebastian Raschka can help georgi gerganov to acelerate the develop of "Gated DeltaNet for Linear Attention" in llama cpp to integrate it in lmstudio , for the qwen3-next 80b a3b model can run? anyone can told this men to join and colaborate and help to resolve this issue for opensource community?</title>
    <updated>2025-11-26T17:50:44+00:00</updated>
    <author>
      <name>/u/Icy_Resolution8390</name>
      <uri>https://old.reddit.com/user/Icy_Resolution8390</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;We need resolve this problem to add this fantastic model run in linux and window platform , this is the very best model for low specs ia servers.&lt;/p&gt; &lt;p&gt;Songlin Yang, Jan Kautz y Ali Hatamizadeh,Georgi gerganov,Sebastian Raschka&lt;/p&gt; &lt;p&gt;Please can colaborate togheter for make this model useful en lmstudio for debian and Linux&lt;/p&gt; &lt;p&gt;Thanks for all the AI opensource community!!!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Icy_Resolution8390"&gt; /u/Icy_Resolution8390 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p7eejz/sebastian_raschka_can_help_georgi_gerganov_to/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p7eejz/sebastian_raschka_can_help_georgi_gerganov_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p7eejz/sebastian_raschka_can_help_georgi_gerganov_to/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T17:50:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1p7ixd5</id>
    <title>Getting errors when trying to add models to Ollama</title>
    <updated>2025-11-26T20:43:26+00:00</updated>
    <author>
      <name>/u/_Time_Flies_</name>
      <uri>https://old.reddit.com/user/_Time_Flies_</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hello. Starting today I have been getting:&lt;/p&gt; &lt;p&gt;Error: 500 Internal Server Error: llama runner process has terminated: exit status 2&lt;/p&gt; &lt;p&gt;This happens any time I try and add a new model from the site using the ollama run command. I also get the same error when trying to add gguf's manually off of huggingface. This just started today and I'm not sure what the cause could be. Anyone know why this is happening? Sorry if this is a dumb question, still very new to Ollama and all of this stuff.&lt;/p&gt; &lt;p&gt;Thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/_Time_Flies_"&gt; /u/_Time_Flies_ &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p7ixd5/getting_errors_when_trying_to_add_models_to_ollama/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p7ixd5/getting_errors_when_trying_to_add_models_to_ollama/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p7ixd5/getting_errors_when_trying_to_add_models_to_ollama/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T20:43:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1p77caj</id>
    <title>CISA Alert: Shai Hulud Worm - NPM Packages Compromised</title>
    <updated>2025-11-26T13:10:16+00:00</updated>
    <author>
      <name>/u/The_Son_of_Hermes</name>
      <uri>https://old.reddit.com/user/The_Son_of_Hermes</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://www.cisa.gov/news-events/alerts/2025/09/23/widespread-supply-chain-compromise-impacting-npm-ecosystem"&gt;https://www.cisa.gov/news-events/alerts/2025/09/23/widespread-supply-chain-compromise-impacting-npm-ecosystem&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/The_Son_of_Hermes"&gt; /u/The_Son_of_Hermes &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p77caj/cisa_alert_shai_hulud_worm_npm_packages/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p77caj/cisa_alert_shai_hulud_worm_npm_packages/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p77caj/cisa_alert_shai_hulud_worm_npm_packages/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T13:10:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1p72mcm</id>
    <title>I made AO Chat UI (Actually Open Chat UI) - because I was horrified that OpenWebUI and others let admins read all users chat data by default, with no GUI option to disable this.</title>
    <updated>2025-11-26T08:32:53+00:00</updated>
    <author>
      <name>/u/Toby-Richardson</name>
      <uri>https://old.reddit.com/user/Toby-Richardson</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I made this alternative chat interface for a project, because I was mortified that Open Web UI and most others let you view all the user chats, with no regard for privacy.&lt;/p&gt; &lt;p&gt;You could disable admin chat access, but this had to be done in the .env file because it was never designed to be privacy friendly.&lt;/p&gt; &lt;p&gt;All of the existing options I tried, couldn't solve these problems:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;No inbuilt privacy options.&lt;/li&gt; &lt;li&gt;User chat data stored as plain text.&lt;/li&gt; &lt;li&gt;No anonymous user support. You could allow non-logged-in users in Open Web UI by specifying it .env or docker-compose, but it disabled all the accounts including the admin account, kinda making it useless.&lt;/li&gt; &lt;li&gt;No customisation options. Since Open Web UI changed from being open source, it required an enterprise licence to change the branding, but they wont say how much that licence is.&lt;/li&gt; &lt;li&gt;Usage limits couldn't be configured differently for logged in vs anonymous users.&lt;/li&gt; &lt;li&gt;Librechat and some others are in multiple containers making them more of a pain to install.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So I made AO Chat UI with the following key features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;All chats are encrypted at rest and not visible to admins. Server access and viewing the .env file will allow you to decrypt the messages, so I'm planning on adding password derived encryption keys for each user.&lt;/li&gt; &lt;li&gt;Simultaneous anonymous and account based use, with different usage limits for each type (IP based for anonymous).&lt;/li&gt; &lt;li&gt;Fully customisable text, branding and colours. Easily configurable through the admin control panel.&lt;/li&gt; &lt;li&gt;SEO/metadata and social media metadata customisation in the control panel.&lt;/li&gt; &lt;li&gt;The admin panel is accessible by admin users, or with a master password that is saved in .env. This is used to promote the first admin account, rather than having the first account automatically be admin which is what the other interfaces currently do.&lt;/li&gt; &lt;li&gt;Easily configurable API rate limiting in the control panel. I'm using Mistral's free API tier on the test project, so this has been important to stop it responding with an error all the time.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I do have a demo version currently active, but it is being used on a subdomain for my business website, so I wasn't sure if putting the link to that here, would be considered too self-promotional?&lt;/p&gt; &lt;p&gt;All the details and readme are at &lt;a href="https://github.com/Tobric/ao-chat-ui"&gt;https://github.com/Tobric/ao-chat-ui&lt;/a&gt;&lt;/p&gt; &lt;p&gt;I'm not a developer, so I don't know if this vibe coded mess will actually be that helpful to anyone, but it has been working for me, so figured there was no point hoarding it. I released it under MIT.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Toby-Richardson"&gt; /u/Toby-Richardson &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p72mcm/i_made_ao_chat_ui_actually_open_chat_ui_because_i/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p72mcm/i_made_ao_chat_ui_actually_open_chat_ui_because_i/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p72mcm/i_made_ao_chat_ui_actually_open_chat_ui_because_i/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T08:32:53+00:00</published>
  </entry>
  <entry>
    <id>t3_1p76voa</id>
    <title>Vector Space App (Local AI on ANE) has Passed App Store Review</title>
    <updated>2025-11-26T12:48:27+00:00</updated>
    <author>
      <name>/u/Glad-Speaker3006</name>
      <uri>https://old.reddit.com/user/Glad-Speaker3006</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p76voa/vector_space_app_local_ai_on_ane_has_passed_app/"&gt; &lt;img alt="Vector Space App (Local AI on ANE) has Passed App Store Review" src="https://external-preview.redd.it/MnFsY3luemFsbDNnMWJEPodVP1EzYvt7bPiQ5CvDsyBLxVPE-pb0b5HQ5QZU.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=a5156fb9457b2e86149861a2429293161ef5baa4" title="Vector Space App (Local AI on ANE) has Passed App Store Review" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;strong&gt;Vector Space&lt;/strong&gt;, my project focused on running open-source AI models directly on the Apple Neural Engine, has officially &lt;strong&gt;passed App Store review&lt;/strong&gt; and is cleared for release. The goal of this project is to explore what‚Äôs possible with on-device inference and potentially achieve up to &lt;strong&gt;5√ó better energy efficiency&lt;/strong&gt; by leveraging the ANE.&lt;/p&gt; &lt;p&gt;Some folks previously raised concerns about safety or potential malware, so I submitted it to the App Store for an additional layer of verification. I'm happy to say it‚Äôs been fully approved ‚Äî hopefully this helps put any worries to rest.&lt;/p&gt; &lt;p&gt;üì± &lt;strong&gt;App Store Link:&lt;/strong&gt; &lt;a href="https://apps.apple.com/us/app/vector-space-ai/id6746352865"&gt;https://apps.apple.com/us/app/vector-space-ai/id6746352865&lt;/a&gt;&lt;/p&gt; &lt;p&gt;If you‚Äôd like to get involved ‚Äî feature ideas, bug reports, discussion about local AI, anything at all ‚Äî I‚Äôd love to hear from you. I‚Äôm committed to responding to every feature request and shaping this into the best local AI app we can build together.&lt;/p&gt; &lt;p&gt;üí¨ &lt;strong&gt;Discord:&lt;/strong&gt; &lt;a href="https://discord.gg/eeTtvSPZ5X"&gt;https://discord.gg/eeTtvSPZ5X&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks to everyone who has shown interest so far. Your feedback and support truly help keep this project moving. üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Glad-Speaker3006"&gt; /u/Glad-Speaker3006 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/ha083v5bll3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p76voa/vector_space_app_local_ai_on_ane_has_passed_app/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p76voa/vector_space_app_local_ai_on_ane_has_passed_app/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-26T12:48:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1p6ksif</id>
    <title>I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp; Private)</title>
    <updated>2025-11-25T18:48:21+00:00</updated>
    <author>
      <name>/u/sebastiankeller0205</name>
      <uri>https://old.reddit.com/user/sebastiankeller0205</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/ollama/comments/1p6ksif/i_built_a_fully_local_offline_jarvis_using_python/"&gt; &lt;img alt="I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp;amp; Private)" src="https://external-preview.redd.it/ejlob3Fibmk4ZzNnMadeDPBN4xSc3qzffa_ecA_6QtCWYZC9kx9P5-kBQoJ9.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5790bebfc77514c0b5ef554bd6036f1e79bb3c92" title="I built a fully local, offline J.A.R.V.I.S. using Python and Ollama (Uncensored &amp;amp; Private)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi everyone! I wanted to share a project I've been working on. It's a fully functional, local AI assistant inspired by Iron Man's J.A.R.V.I.S.&lt;/p&gt; &lt;p&gt;I wanted something that runs &lt;strong&gt;locally&lt;/strong&gt; on my PC (for privacy and speed) but still has a personality.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;üé• Watch the video to see the HUD and Voice interaction in action!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;‚ö° Key Features:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;100% Local Brain:&lt;/strong&gt; Uses &lt;strong&gt;Ollama&lt;/strong&gt; (running the &lt;code&gt;dolphin-phi&lt;/code&gt; model) so it works offline and keeps data private.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Uncensored Persona:&lt;/strong&gt; Custom &amp;quot;God Mode&amp;quot; system prompts to bypass standard AI refusals.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Sci-Fi HUD:&lt;/strong&gt; Built with &lt;strong&gt;OpenCV&lt;/strong&gt; and &lt;strong&gt;Pillow&lt;/strong&gt;. It features a live video wallpaper, real-time CPU/RAM stats, and a &amp;quot;typewriter&amp;quot; effect for captions.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;System Automation:&lt;/strong&gt; Can open/close apps, create folders, and take screenshots via voice commands.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Dual Identity:&lt;/strong&gt; Seamlessly switches between &amp;quot;Jarvis&amp;quot; (Male) and &amp;quot;Friday&amp;quot; (Female) voices and personas.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Hybrid Control:&lt;/strong&gt; Supports both Voice Commands (SpeechRecognition) and a direct Text Input terminal on the HUD.&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sebastiankeller0205"&gt; /u/sebastiankeller0205 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/vzwvvgji8g3g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/ollama/comments/1p6ksif/i_built_a_fully_local_offline_jarvis_using_python/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/ollama/comments/1p6ksif/i_built_a_fully_local_offline_jarvis_using_python/"/>
    <category term="ollama" label="r/ollama"/>
    <published>2025-11-25T18:48:21+00:00</published>
  </entry>
</feed>
