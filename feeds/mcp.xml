<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/mcp/.rss</id>
  <title>Model Context Protocol (MCP)</title>
  <updated>2026-01-29T12:17:28+00:00</updated>
  <link href="https://old.reddit.com/r/mcp/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools</subtitle>
  <entry>
    <id>t3_1qodaze</id>
    <title>Sims 1 Legacy MCP</title>
    <updated>2026-01-27T13:05:39+00:00</updated>
    <author>
      <name>/u/pevers</name>
      <uri>https://old.reddit.com/user/pevers</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/"&gt; &lt;img alt="Sims 1 Legacy MCP" src="https://preview.redd.it/nnn207a64wfg1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d1b1ac60b422ac94d6308ec4c500920e114851ed" title="Sims 1 Legacy MCP" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A MCP server we have all been waiting for. This is a hack that adds a MCP server to the Sims 1 Legacy so that you can use AI to interact with your Sims household. I created it as an exercise to reverse engineer games using GhydraMCP and Claude Code. At the moment it is read-only but I'm working on extending the MCP server to also query actions (imagine having a household of different LLMs).&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/pevers/sims-mcp"&gt;https://github.com/pevers/sims-mcp&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/pevers"&gt; /u/pevers &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/nnn207a64wfg1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-27T13:05:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp9xf0</id>
    <title>I built 15 Python MCP tools to supercharge AI coding assistants (now open source!) . Would love a feedback and a star</title>
    <updated>2026-01-28T12:23:36+00:00</updated>
    <author>
      <name>/u/Notalabel_4566</name>
      <uri>https://old.reddit.com/user/Notalabel_4566</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp9xf0/i_built_15_python_mcp_tools_to_supercharge_ai/"&gt; &lt;img alt="I built 15 Python MCP tools to supercharge AI coding assistants (now open source!) . Would love a feedback and a star" src="https://external-preview.redd.it/AIek67RvZPUU6ae5tAPAw6mk1AsW5RMQJaFcsW246uI.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=92ee771c555b0fe191dfe850aa75c57faf8ae41f" title="I built 15 Python MCP tools to supercharge AI coding assistants (now open source!) . Would love a feedback and a star" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Think of them as specialized tools that your AI can use to understand and improve your codebase.&lt;/p&gt; &lt;p&gt;All 15 tools are organized in a clean monorepo with:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Individual pyproject.toml for each tool&lt;/li&gt; &lt;li&gt;Shared quality tooling configuration&lt;/li&gt; &lt;li&gt;Per-tool READMEs and documentation&lt;/li&gt; &lt;li&gt;Easy installation via pip or uvx&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Notalabel_4566"&gt; /u/Notalabel_4566 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/Abhisheksinha1506/Client-mcpserver"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp9xf0/i_built_15_python_mcp_tools_to_supercharge_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp9xf0/i_built_15_python_mcp_tools_to_supercharge_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T12:23:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1qog1wq</id>
    <title>I wrote Concierge, an Open Source library to convert MCPs into tool groups, stages and workflows which are progressively discovered as agents interact with the server.</title>
    <updated>2026-01-27T14:56:15+00:00</updated>
    <author>
      <name>/u/Prestigious-Play8738</name>
      <uri>https://old.reddit.com/user/Prestigious-Play8738</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt; &lt;p&gt;Anyone else tired of configuring 50 tools into MCP and just hoping the agent figures it out? (invoking the right tools in the right order).&lt;/p&gt; &lt;p&gt;We keep hitting same problems:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Agent calls `checkout()` before `add_to_cart()`&lt;/li&gt; &lt;li&gt;Context bloat: 50+ tools served for every conversation message.&lt;/li&gt; &lt;li&gt;Semantic loss: Agent does not know which tools are relevant for the current interaction&lt;/li&gt; &lt;li&gt;Adding a system prompt describing the order of tool invocation and praying that the agent follows it.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So I wrote Concierge. It converts your MCP into a stateful graph, where you can organize tools into stages and workflows, and agents only have tools &lt;strong&gt;visible to the current stage&lt;/strong&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from concierge import Concierge app = Concierge(&amp;quot;my-server&amp;quot;) app.stages = { &amp;quot;browse&amp;quot;: [&amp;quot;search_products&amp;quot;], &amp;quot;cart&amp;quot;: [&amp;quot;add_to_cart&amp;quot;], &amp;quot;checkout&amp;quot;: [&amp;quot;pay&amp;quot;] } app.transitions = { &amp;quot;browse&amp;quot;: [&amp;quot;cart&amp;quot;], &amp;quot;cart&amp;quot;: [&amp;quot;checkout&amp;quot;] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This also supports sharded distributed state and semantic search for thousands of tools. (also compatible with existing MCPs)&lt;/p&gt; &lt;p&gt;Do try it out and love to know what you think. Thanks!&lt;/p&gt; &lt;p&gt;Repo: &lt;a href="https://github.com/concierge-hq/concierge"&gt;https://github.com/concierge-hq/concierge&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Install it with: &lt;code&gt;pip install concierge-sdk&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Prestigious-Play8738"&gt; /u/Prestigious-Play8738 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-27T14:56:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp64x4</id>
    <title>Lightweight CLI tool to interact with MCP</title>
    <updated>2026-01-28T08:49:27+00:00</updated>
    <author>
      <name>/u/konradkokosa</name>
      <uri>https://old.reddit.com/user/konradkokosa</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"&gt; &lt;img alt="Lightweight CLI tool to interact with MCP" src="https://b.thumbs.redditmedia.com/i-RI13_vgrHZLc5pTOfOSCoXqgJOewB2ly3VU7kZYnM.jpg" title="Lightweight CLI tool to interact with MCP" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I was surprised to find that a tool I expected to exist didn't - a simple REPL CLI tool to investigate MCP servers. I know there is MCP Inspector but I needed something I can quickly fire up, list and call some tools, and close it. I found some one-shot CLI tools for this but nothing interactive/REPL. &lt;/p&gt; &lt;p&gt;So, I've made one:&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/rrvh2tu9z1gg1.png?width=821&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d94c3b7dc46522b786fe87ed62fa726b252c9c70"&gt;https://preview.redd.it/rrvh2tu9z1gg1.png?width=821&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d94c3b7dc46522b786fe87ed62fa726b252c9c70&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Repository: &lt;a href="https://github.com/kkokosa/repl-mcp"&gt;https://github.com/kkokosa/repl-mcp&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/konradkokosa"&gt; /u/konradkokosa &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T08:49:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpeai7</id>
    <title>Jan, 2026: "KNOWLEDGE ATTAINS DEMOCRACY"</title>
    <updated>2026-01-28T15:23:56+00:00</updated>
    <author>
      <name>/u/0xraghu</name>
      <uri>https://old.reddit.com/user/0xraghu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpeai7/jan_2026_knowledge_attains_democracy/"&gt; &lt;img alt="Jan, 2026: &amp;quot;KNOWLEDGE ATTAINS DEMOCRACY&amp;quot;" src="https://b.thumbs.redditmedia.com/5r-GibJgzjn7OYiQu-TqrehB9JZiQ-KlNiy4YdfY6sA.jpg" title="Jan, 2026: &amp;quot;KNOWLEDGE ATTAINS DEMOCRACY&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/0xraghu"&gt; /u/0xraghu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/ClaudeCode/comments/1qp3j03/jan_2026_knowledge_attains_democracy/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpeai7/jan_2026_knowledge_attains_democracy/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpeai7/jan_2026_knowledge_attains_democracy/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T15:23:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1qph3b8</id>
    <title>Bridging AI Development Ecosystems: VSCode LM Tools ↔️ MCP</title>
    <updated>2026-01-28T17:03:25+00:00</updated>
    <author>
      <name>/u/Traditional-Tart-393</name>
      <uri>https://old.reddit.com/user/Traditional-Tart-393</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Traditional-Tart-393"&gt; /u/Traditional-Tart-393 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/vscode/comments/1qph2tq/bridging_ai_development_ecosystems_vscode_lm/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qph3b8/bridging_ai_development_ecosystems_vscode_lm/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qph3b8/bridging_ai_development_ecosystems_vscode_lm/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T17:03:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1qphmfw</id>
    <title>Building the MCP inspector for teams</title>
    <updated>2026-01-28T17:21:32+00:00</updated>
    <author>
      <name>/u/matt8p</name>
      <uri>https://old.reddit.com/user/matt8p</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qphmfw/building_the_mcp_inspector_for_teams/"&gt; &lt;img alt="Building the MCP inspector for teams" src="https://external-preview.redd.it/NGVrZGVpbXFpNGdnMf9EYl3am4o-FFeuqYpEkF3jqWjTj3_Zb9gvJIEcnwAR.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5e06a8930dca0b24aea93988aaac267791aa44e5" title="Building the MCP inspector for teams" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey y'all, it's Matt from &lt;a href="https://www.mcpjam.com/"&gt;MCPJam&lt;/a&gt;. We recently launched workspaces within MCPJam inspector. You can think of them as folders for your MCP servers, helping you organize your work if you work on multiple projects. Workspaces are also shareable, making it easy to share your workflow amongst your team. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;MCPJam&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For context, MCPJam is an open source MCP inspector alternative. It's like the MCP inspector but with a built in LLM playground, visual OAuth debugger, and support for ChatGPT apps SDK / MCP apps. &lt;/p&gt; &lt;p&gt;We started the last project last May and are working on it full time now. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Check it out&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We hope MCP developers find our tool useful. If this sounds interesting, please consider giving the project a try! &lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/MCPJam/inspector"&gt;https://github.com/MCPJam/inspector&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/matt8p"&gt; /u/matt8p &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/61u3zdmqi4gg1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qphmfw/building_the_mcp_inspector_for_teams/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qphmfw/building_the_mcp_inspector_for_teams/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T17:21:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpja9a</id>
    <title>100% open source MCP server for PostgreSQL: now with write access, reduced token consumption, improved UX, &amp; more</title>
    <updated>2026-01-28T18:17:25+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.pgedge.com/blog/what-s-new-in-the-pgedge-postgres-mcp-server-beta-2-and-beta-3"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpja9a/100_open_source_mcp_server_for_postgresql_now/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpja9a/100_open_source_mcp_server_for_postgresql_now/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T18:17:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp7qh7</id>
    <title>A browser sandbox for Agent, https://deeptask.ai/</title>
    <updated>2026-01-28T10:26:16+00:00</updated>
    <author>
      <name>/u/Chix9527</name>
      <uri>https://old.reddit.com/user/Chix9527</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"&gt; &lt;img alt="A browser sandbox for Agent, https://deeptask.ai/" src="https://b.thumbs.redditmedia.com/b3h79nXpd10_yOYiHgjaiw-E0fBLiKxHNoBtMR4CvLs.jpg" title="A browser sandbox for Agent, https://deeptask.ai/" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Code as skills. &lt;a href="https://deeptask.ai/"&gt;https://deeptask.ai/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/rpaayld7h2gg1.png?width=3061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7ee134534f982d06c5ad5b2d07b3332fe4a329d1"&gt;https://preview.redd.it/rpaayld7h2gg1.png?width=3061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7ee134534f982d06c5ad5b2d07b3332fe4a329d1&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Chix9527"&gt; /u/Chix9527 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T10:26:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpodm7</id>
    <title>what patterns have you noticed when choosing AI models?</title>
    <updated>2026-01-28T21:20:05+00:00</updated>
    <author>
      <name>/u/justgetting-started</name>
      <uri>https://old.reddit.com/user/justgetting-started</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/justgetting-started"&gt; /u/justgetting-started &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/aipromptprogramming/comments/1qpoaz6/what_patterns_have_you_noticed_when_choosing_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpodm7/what_patterns_have_you_noticed_when_choosing_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpodm7/what_patterns_have_you_noticed_when_choosing_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T21:20:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpenvd</id>
    <title>Jira automation + MCP server to break Figma designs into stories</title>
    <updated>2026-01-28T15:37:49+00:00</updated>
    <author>
      <name>/u/No-Addendum-2793</name>
      <uri>https://old.reddit.com/user/No-Addendum-2793</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpenvd/jira_automation_mcp_server_to_break_figma_designs/"&gt; &lt;img alt="Jira automation + MCP server to break Figma designs into stories" src="https://external-preview.redd.it/iK469q4nYpN59xJv0IAPgnsXWm7p5vamg_BpAK1i_no.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3cc27c93b29334531db4b439a28a4eea095db233" title="Jira automation + MCP server to break Figma designs into stories" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey all! I’ve been experimenting with AI workflows inside Jira, and my team built an MCP server + Jira automations that help turn Figma designs into Jira stories (all open source)&lt;/p&gt; &lt;p&gt;Workflow is basically:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Clarify scope&lt;/strong&gt; (assumptions + questions based on the design/comments)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Split the work&lt;/strong&gt; (breaks the feature into smaller stories)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Write the tickets&lt;/strong&gt; (generates full Jira tickets w/ acceptance criteria + Figma links)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I recorded a short YouTube demo walkthrough and included the &lt;strong&gt;r&lt;/strong&gt;epo + setup instructions in the description.&lt;/p&gt; &lt;p&gt;Happy to answer questions / would appreciate feedback from anyone building with MCP or agent workflows.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/No-Addendum-2793"&gt; /u/No-Addendum-2793 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.youtube.com/watch?v=MK0tdwDBTmc"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpenvd/jira_automation_mcp_server_to_break_figma_designs/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpenvd/jira_automation_mcp_server_to_break_figma_designs/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T15:37:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp9c1l</id>
    <title>How are you running MCP servers beyond local demos?</title>
    <updated>2026-01-28T11:54:27+00:00</updated>
    <author>
      <name>/u/Sumanth_077</name>
      <uri>https://old.reddit.com/user/Sumanth_077</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;For anyone using MCP beyond quick demos, how are you running MCP servers in practice?&lt;/p&gt; &lt;p&gt;Are you mostly:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;running them locally on a workstation when they need access to files or editors&lt;/li&gt; &lt;li&gt;containerizing them and running them somewhere managed, either one per agent or shared&lt;/li&gt; &lt;li&gt;or treating them more like remote services and just calling them over HTTP&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these seems to come with different tradeoffs around isolation, reuse, and ops overhead.&lt;/p&gt; &lt;p&gt;I’ve been looking at managed setups on Clarifai where public MCP servers are deployed as APIs and discovered by models at inference time, instead of being bundled into every runtime.&lt;/p&gt; &lt;p&gt;Curious what people here are doing today and what’s been annoying or unexpectedly smooth.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Sumanth_077"&gt; /u/Sumanth_077 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T11:54:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpp5hl</id>
    <title>Building opensource Zero Server Code Intelligence Engine</title>
    <updated>2026-01-28T21:49:15+00:00</updated>
    <author>
      <name>/u/DeathShot7777</name>
      <uri>https://old.reddit.com/user/DeathShot7777</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpp5hl/building_opensource_zero_server_code_intelligence/"&gt; &lt;img alt="Building opensource Zero Server Code Intelligence Engine" src="https://external-preview.redd.it/eGs5MTUzdTV2NWdnMX8xZ7UL_WAflwTq0BqeDmN95WRo5Ajh0fAkuzEXaT9M.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5fcf2583014651d67ae6686c4e1a8cab038ac570" title="Building opensource Zero Server Code Intelligence Engine" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi, guys, I m building GitNexus, an opensource Code Intelligence Engine which works fully client sided in-browser. There have been lot of progress since I last posted.&lt;/p&gt; &lt;p&gt;Repo: &lt;a href="https://github.com/abhigyanpatwari/GitNexus"&gt;https://github.com/abhigyanpatwari/GitNexus&lt;/a&gt; ( ⭐ would help so much, u have no idea!! )&lt;br /&gt; Try: &lt;a href="https://gitnexus.vercel.app/"&gt;https://gitnexus.vercel.app/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It creates a Knowledge Graph from github repos and exposes an Agent with specially designed tools and also MCP support. Idea is to solve the project wide context issue in tools like cursor, claude code, etc and have a shared code intelligence layer for multiple agents. It provides a reliable way to retrieve full context important for codebase audits, blast radius detection of code changes and deep architectural understanding of the codebase for both humans and LLM. ( Ever encountered the issue where cursor updates some part of the codebase but fails to adapt other dependent functions around it ? this should solve it )&lt;/p&gt; &lt;p&gt;&lt;strong&gt;I tested it using cursor through MCP. Even without the impact tool and LLM enrichment feature, haiku 4.5 model was able to produce better Architecture documentation compared to opus 4.5 without MCP on PyBamm repo ( its a complex battery modelling repo )&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Opus 4.5 was asked to get into as much detail as possible but haiku had a simple prompt asking it to explain the architecture. The output files were compared in chatgpt 5.2 chat link: &lt;a href="https://chatgpt.com/share/697a7a2c-9524-8009-8112-32b83c6c9fe4"&gt;https://chatgpt.com/share/697a7a2c-9524-8009-8112-32b83c6c9fe4&lt;/a&gt;&lt;/p&gt; &lt;p&gt;( IK its not a good enough benchmark but still promising )&lt;/p&gt; &lt;p&gt;Quick tech jargon:&lt;/p&gt; &lt;p&gt;- Everything including db engine, embeddings model, all works in-browser client sided&lt;/p&gt; &lt;p&gt;- The project architecture flowchart u can see in the video is generated without LLM during repo ingestion so is reliable.&lt;/p&gt; &lt;p&gt;- Creates clusters ( using leidens algo ) and process maps during ingestion.&lt;/p&gt; &lt;p&gt;- It has all the usual tools like grep, semantic search, etc but enhanced majorly using process maps and clusters making the tool themselves smart hence a lot of the decisions the LLM had to make to retrieve context is offloaded into the tools, making it much more reliable even with non sota models.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What I need help with:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;- To convert it into a actually useful product do u think I should make it like a CLI tool that keeps track of local code changes and updating the graph?&lt;/p&gt; &lt;p&gt;- Is there some way to get some free API credits or sponsorship or something so that I can test gitnexus with multiple providers&lt;/p&gt; &lt;p&gt;- Some insights into enterprise code problems like security audits or dead code detection or any other potential usecase I can tune gitnexus for?&lt;/p&gt; &lt;p&gt;Any cool idea and suggestion helps a lot. The comments on previous post helped a LOT, thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DeathShot7777"&gt; /u/DeathShot7777 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/wincxnt5v5gg1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpp5hl/building_opensource_zero_server_code_intelligence/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpp5hl/building_opensource_zero_server_code_intelligence/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T21:49:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpa84z</id>
    <title>HTTP2/HTTP3 support in the future?</title>
    <updated>2026-01-28T12:38:07+00:00</updated>
    <author>
      <name>/u/DorkyMcDorky</name>
      <uri>https://old.reddit.com/user/DorkyMcDorky</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Quick question for &lt;a href="/r/mcp"&gt;r/mcp&lt;/a&gt;: has anyone considered an HTTP/2 or HTTP/3 transport option for MCP, even if HTTP/1 stays the baseline? I get the tradeoffs like HTTP/1 ubiquity, stateless infra, and simpler deployment, but I am curious how folks weigh those against streaming and long lived connections.&lt;/p&gt; &lt;p&gt;I know HTTP/2 or HTTP/3 can be a pain in cloud environments and external facing SaaS, but for internal networks and home labs it is much easier and brings real benefits like multiplexing and true streaming. Maybe MCP is mainly targeting SaaS cloud infra, but it feels like a huge miss that there is no true streaming option for internal use cases.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DorkyMcDorky"&gt; /u/DorkyMcDorky &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T12:38:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpvlmy</id>
    <title>Wake - Terminal context for Claude Code via MCP</title>
    <updated>2026-01-29T02:11:50+00:00</updated>
    <author>
      <name>/u/averagemrjoe</name>
      <uri>https://old.reddit.com/user/averagemrjoe</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I built an tool that records terminal sessions and exposes them to Claude Code via MCP. The idea: stop copy-pasting logs and command output into chat.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;code&gt;wake shell&lt;/code&gt; spawns your shell inside a PTY, capturing all commands and output&lt;/li&gt; &lt;li&gt;Shell hooks (zsh/bash) notify wake when commands start/end&lt;/li&gt; &lt;li&gt;Everything gets stored in a local SQLite database&lt;/li&gt; &lt;li&gt;The &lt;code&gt;wake-mcp&lt;/code&gt; server exposes this data via MCP tools&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;MCP Tools:&lt;/strong&gt;&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th&gt;Tool&lt;/th&gt; &lt;th&gt;Purpose&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_status&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Current session info&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_list_commands&lt;/code&gt;&lt;/td&gt; &lt;td&gt;List recent commands with metadata + summaries&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_get_output&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Fetch full output for specific command IDs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_log&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Recent commands with truncated output&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_search&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Search command history&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_dump&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Export session as markdown&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_annotate&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Add notes to the session&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;The &lt;code&gt;wake_list_commands&lt;/code&gt; + &lt;code&gt;wake_get_output&lt;/code&gt; pattern enables tiered retrieval - Claude sees command metadata first, then fetches full output only when needed. Reduces context usage significantly.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Local LLM summarization:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;New in v0.5.0: wake automatically summarizes command outputs using a local Qwen2.5-0.5B model (~468MB). Summaries appear in &lt;code&gt;wake_list_commands&lt;/code&gt;, so Claude can quickly understand what happened without reading thousands of lines of build logs.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Runs on CPU (no GPU needed)&lt;/li&gt; &lt;li&gt;Downloads automatically on first use&lt;/li&gt; &lt;li&gt;All inference happens locally&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;sh curl -sSf https://raw.githubusercontent.com/joemckenney/wake/main/install.sh | sh eval &amp;quot;$(wake init zsh)&amp;quot; # or bash claude mcp add wake-mcp -- wake-mcp &lt;/code&gt;&lt;/p&gt; &lt;p&gt;GitHub: &lt;a href="https://github.com/joemckenney/wake"&gt;https://github.com/joemckenney/wake&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Happy to answer questions about the MCP integration or architecture.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/averagemrjoe"&gt; /u/averagemrjoe &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvlmy/wake_terminal_context_for_claude_code_via_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvlmy/wake_terminal_context_for_claude_code_via_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpvlmy/wake_terminal_context_for_claude_code_via_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T02:11:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpjn96</id>
    <title>How I program everywhere</title>
    <updated>2026-01-28T18:29:58+00:00</updated>
    <author>
      <name>/u/Eyoba_19</name>
      <uri>https://old.reddit.com/user/Eyoba_19</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;So I've been programming in the metro, when waiting for the doctor, heck even in the bathroom. I mean it's quite the downfall from my dream of sitting in front of multiple large monitors with cmatrix style code, dark hoodies and insane typing speeds with Jarvis handing me my coffee.&lt;/p&gt; &lt;p&gt;But yeah I think I like this more.&lt;/p&gt; &lt;p&gt;So wanted to share how I do it, starting with the tools I use: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Linear for managing my tasks&lt;/li&gt; &lt;li&gt;Github for hosting my repo&lt;/li&gt; &lt;li&gt;Slack/Telegram for communication (currently in progress, but promising I tell you)&lt;/li&gt; &lt;li&gt;LLMs - codex and claude code (expanding to gemini)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;How they come together, imagine this: &lt;/p&gt; &lt;p&gt;Using Linear on my phone, I write down a task for my project, put it in spec status.&lt;/p&gt; &lt;p&gt;Few minutes later I see a spec, read it, if I'm happy, I set it as ready for dev, few minutes later a PR is ready.&lt;/p&gt; &lt;p&gt;If there are any failed checks on actions, no worries few minutes later they're all fixed and ready for merge, just needs my approval. &lt;/p&gt; &lt;p&gt;I make a few comments, few minutes again all fixed, I look at it again, if I'm happy, I approve and merge. &lt;/p&gt; &lt;p&gt;And how long? 30min, maybe an hour max, what could’ve possibly taken me a day or even a week?&lt;/p&gt; &lt;p&gt;Here’s the cool thing, I’m always doing multiple tasks and all in parallel. That was possibly weeks I was saving. Yeah Ik it’s pretty wild.&lt;/p&gt; &lt;p&gt;So what's happening under the hood?&lt;/p&gt; &lt;p&gt;Well whenever a Linear task is created a webhook is sent to my server (Linear has their webhook Api specs online so you could easily check the data that’s sent back). In the payload, I check whether the sent request is an issue/comment, see if it’s labeled AI (linear allows custom labels) and that the current status is &amp;quot;Spec&amp;quot; or &amp;quot;Ready for dev (custom status), any other status just returns from here.&lt;/p&gt; &lt;p&gt;If the paylod is an issue and it’s in Spec, the webhook will use linear’s graphql api to comment “Writing spec” and assign itself to the task, fetches latest repo, automatically creates a new worktree, and then launches a docker container with the worktree mounted as a volume, the container has codex/claude in it(you can just use a slim alpine and install codex/claude on it) and passes on the command “work on {issue_identifier}”. &lt;/p&gt; &lt;p&gt;The LLM has linear’s mcp configured (you can check my last &lt;a href="https://www.reddit.com/r/mcp/comments/1qlhj62/a_few_of_the_mcps_i_use_on_a_daily_basis/"&gt;post&lt;/a&gt; for the MCPs I use) so it can easily fetch the issue contents, see the title and any description in the issue, refer the codebase and write a proper spec directly to linear. I do not kill the container after the spec, mainly to save costs and to reuse context for following tasks.&lt;/p&gt; &lt;p&gt;If the spec isn’t ideal, I can comment under the spec/issue with the changes I want. Webhook fires-&amp;gt; payload is parsed-&amp;gt; content of the comment is checked, it must include “@ai”, if so it’s meant for the ai, since the container is still alive the llm can re-use the context session, saves me a lot of credit, you’ll thank me for it. Now command is passed- “Amend the spec on issue {issue_identifier} according to this comment {comment_content}”. The LLM does its thing and posts the new spec.&lt;/p&gt; &lt;p&gt;Once I’m satisfied with the spec, I move the issue to “Ready for Dev”, another webhook-&amp;gt; parse the payload-&amp;gt; checks issue statuses and sees it’s ready for dev, moves it to &amp;quot;In Progress&amp;quot;, fetches that same container and passes the command- “Issue {issue_identifier} is ready for implementation, start working on it, once finished commit and push to origin with a new PR”.&lt;/p&gt; &lt;p&gt;I’ll continue on another post on how I do the git side of things and communication as well, how I converse with codex/claude about new features and then tell it- “yeah sounds good, start working on on it” and it immediately sets up the linear issue, and does everything on its own, it’s pretty sick. &lt;/p&gt; &lt;p&gt;But yeah, happy to get any more ways to improve on it, hope this helps and would love to see you guys set up your own coding Jarvis too ;).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Eyoba_19"&gt; /u/Eyoba_19 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T18:29:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpysua</id>
    <title>"Clink": MCP Server for Provider-agnostic Collaboration</title>
    <updated>2026-01-29T04:36:14+00:00</updated>
    <author>
      <name>/u/Mannentreu</name>
      <uri>https://old.reddit.com/user/Mannentreu</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I've been working on a distributed platform called &amp;quot;Clink&amp;quot; that allows any MCP-enabled agent to collaborate with both humans and other agents.&lt;/p&gt; &lt;p&gt;I'd like to run some pilot programs with small or mid-sized teams of AI-forward developers and non-dev contributors. Please reach out if you're interested!&lt;/p&gt; &lt;p&gt;Marketing site: &lt;a href="https://clink.voxos.ai/"&gt;https://clink.voxos.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Docs: &lt;a href="https://docs.clink.voxos.ai/"&gt;https://docs.clink.voxos.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Web dashboard: &lt;a href="https://app.clink.voxos.ai/"&gt;https://app.clink.voxos.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;MCP npm pkg: &lt;a href="https://www.npmjs.com/package/@voxos-ai/clink-mcp-server"&gt;https://www.npmjs.com/package/@voxos-ai/clink-mcp-server&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Npm pkg source: &lt;a href="https://github.com/Voxos-ai-Inc/clink-mcp-server"&gt;https://github.com/Voxos-ai-Inc/clink-mcp-server&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Mannentreu"&gt; /u/Mannentreu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpysua/clink_mcp_server_for_provideragnostic/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpysua/clink_mcp_server_for_provideragnostic/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpysua/clink_mcp_server_for_provideragnostic/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T04:36:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpz8ap</id>
    <title>I built a trend prediction system using Google Trends MCP and here's what I found about AI in January 2026</title>
    <updated>2026-01-29T04:57:02+00:00</updated>
    <author>
      <name>/u/-SLOW-MO-JOHN-D</name>
      <uri>https://old.reddit.com/user/-SLOW-MO-JOHN-D</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpz8ap/i_built_a_trend_prediction_system_using_google/"&gt; &lt;img alt="I built a trend prediction system using Google Trends MCP and here's what I found about AI in January 2026" src="https://external-preview.redd.it/CkmvrfQTiP7HYMFPNIWJPjzI5K9-8M0FuMHy8WYwBuY.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d92bd4f28d36954b7fa271c07f7739cc96af4fea" title="I built a trend prediction system using Google Trends MCP and here's what I found about AI in January 2026" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/-SLOW-MO-JOHN-D"&gt; /u/-SLOW-MO-JOHN-D &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/4sbfqlmkt7gg1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpz8ap/i_built_a_trend_prediction_system_using_google/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpz8ap/i_built_a_trend_prediction_system_using_google/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T04:57:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpvgiz</id>
    <title>Made a free MCP server for generating local business websites</title>
    <updated>2026-01-29T02:05:46+00:00</updated>
    <author>
      <name>/u/dwbdwb</name>
      <uri>https://old.reddit.com/user/dwbdwb</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Built an MCP that creates websites for local businesses. You give it a business name/location, it pulls data from Google, Yelp, etc. and generates a full site with SEO, schema markup, the works.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Endpoint:&lt;/strong&gt; &lt;a href="https://webzum.com/api/mcp"&gt;&lt;code&gt;https://webzum.com/api/mcp&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tools:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;search_businesses&lt;/code&gt; — find businesses by name/phone/location&lt;/li&gt; &lt;li&gt;&lt;code&gt;create_site&lt;/code&gt; — generate site from business data&lt;/li&gt; &lt;li&gt;&lt;code&gt;get_site_status&lt;/code&gt; — poll build progress&lt;/li&gt; &lt;li&gt;&lt;code&gt;generate_geo_page&lt;/code&gt; — make landing pages for specific cities/services&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;No API key needed. Streamable HTTP transport.&lt;/p&gt; &lt;p&gt;Useful if you're building agents for agencies, lead gen, or local SEO stuff.&lt;/p&gt; &lt;p&gt;More info: &lt;a href="https://webzum.com"&gt;https://webzum.com&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dwbdwb"&gt; /u/dwbdwb &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvgiz/made_a_free_mcp_server_for_generating_local/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvgiz/made_a_free_mcp_server_for_generating_local/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpvgiz/made_a_free_mcp_server_for_generating_local/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T02:05:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1qq1ogn</id>
    <title>Generate a Tone of Voice Analysis from a Website Sitemap.xml</title>
    <updated>2026-01-29T07:06:17+00:00</updated>
    <author>
      <name>/u/richardbaxter</name>
      <uri>https://old.reddit.com/user/richardbaxter</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qq1ogn/generate_a_tone_of_voice_analysis_from_a_website/"&gt; &lt;img alt="Generate a Tone of Voice Analysis from a Website Sitemap.xml" src="https://external-preview.redd.it/k3rtWS_JgKJEBdEzgpjWBFZADfoW8joputCtib2-MsA.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f5ff78c70ea41ad8e430897c2966b096d2e95ced" title="Generate a Tone of Voice Analysis from a Website Sitemap.xml" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;This mcp extracts statistical voice models from your published writing. It will generate an immersive style guides (&amp;quot;writing_style.md) that gives an LLM the schema to replicate how you write by creating examples, rhythm patterns and warnings to the LLM about AI cliche text and punctuation.&lt;/p&gt; &lt;p&gt;Technical features:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Function Word Stylometry&lt;/strong&gt; - Uses z-score analysis against reference English corpora to identify your unconscious patterns&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Statistical Distributions (Not Averages)&lt;/strong&gt; - measures clustering patterns, burstiness coefficient, and sentences per paragraph with variance&lt;/p&gt; &lt;p&gt;&lt;strong&gt;N-Gram Pattern Extraction&lt;/strong&gt; - Character n-grams: (Typing rhythms, punctuation habits), Word n-grams, POS n-grams&lt;/p&gt; &lt;p&gt;&lt;strong&gt;AI Detection Markers (v2.0)&lt;/strong&gt; - Over-indexing detection, Under-indexing detection, Lexical diversity and Expression markers.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Use Case&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;If you're automating content - for whatever reason, internal reporting is a good example, the output of this MCP provides a working style guide for your LLM to closely mimic your own tone of voice. &lt;/p&gt; &lt;p&gt;No, it doesn't trick the best AI content detection but it sure can sound a lot more like you. Enjoy!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/richardbaxter"&gt; /u/richardbaxter &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/houtini-ai/voice-analyser-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qq1ogn/generate_a_tone_of_voice_analysis_from_a_website/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qq1ogn/generate_a_tone_of_voice_analysis_from_a_website/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T07:06:17+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpn0d5</id>
    <title>LAD-A2A: How AI agents find each other on local networks</title>
    <updated>2026-01-28T20:29:18+00:00</updated>
    <author>
      <name>/u/franzvill</name>
      <uri>https://old.reddit.com/user/franzvill</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;AI agents are getting really good at doing things, but they're completely blind to their physical surroundings.&lt;/p&gt; &lt;p&gt;If you walk into a hotel and you have an AI assistant (like the Chatgpt mobile app), it has no idea there may be a concierge agent on the network that could help you book a spa, check breakfast times, or request late checkout. Same thing at offices, hospitals, cruise ships. The agents are there, but there's no way to discover them.&lt;/p&gt; &lt;p&gt;A2A (Google's agent-to-agent protocol) handles how agents talk to each other. MCP handles how agents use tools. But neither answers a basic question: how do you find agents in the first place?&lt;/p&gt; &lt;p&gt;So I built LAD-A2A, a simple discovery protocol. When you connect to a Wi-Fi, your agent can automatically find what's available using mDNS (like how AirDrop finds nearby devices) or a standard HTTP endpoint.&lt;/p&gt; &lt;p&gt;The spec is intentionally minimal. I didn't want to reinvent A2A or create another complex standard. LAD-A2A just handles discovery, then hands off to A2A for actual communication.&lt;/p&gt; &lt;p&gt;Open source, Apache 2.0. Includes a working Python implementation you can run to see it in action. Repo can be found at franzvill/lad.&lt;/p&gt; &lt;p&gt;Curious what people think!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/franzvill"&gt; /u/franzvill &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T20:29:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1qq3ibm</id>
    <title>My rubber ducks learned to browse the web (and stopped Chrome DevTools from nuking Claude's context)</title>
    <updated>2026-01-29T08:56:00+00:00</updated>
    <author>
      <name>/u/nesquikm</name>
      <uri>https://old.reddit.com/user/nesquikm</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qq3ibm/my_rubber_ducks_learned_to_browse_the_web_and/"&gt; &lt;img alt="My rubber ducks learned to browse the web (and stopped Chrome DevTools from nuking Claude's context)" src="https://external-preview.redd.it/8uEl2QSQUUhiqhE7_szLtZylHkUpVTRLcYjoDipqSZ8.png?width=140&amp;amp;height=70&amp;amp;auto=webp&amp;amp;s=877fe97874ee246cc2b4caae1a2ccbc443497969" title="My rubber ducks learned to browse the web (and stopped Chrome DevTools from nuking Claude's context)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;em&gt;Processing img 90yrfdtr79gg1...&lt;/em&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Chrome DevTools MCP dumps thousands of tokens of DOM snapshots into your Claude context. Every. Single. Click. I made Gemini Flash process the DOM instead, through the rubber duck MCP bridge. Claude only sees &amp;quot;the button uid is 8_37&amp;quot;. Context saved, usage saved, sanity — a work in progress.&lt;/p&gt; &lt;h1&gt;The Problem&lt;/h1&gt; &lt;p&gt;I use Chrome DevTools MCP to automate browser testing. The flow looks innocent:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;1. take_snapshot → find a button 2. click → click it 3. take_snapshot → find the next element 4. click → click it 5. ... repeat 12 more times &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Each &lt;code&gt;take_snapshot&lt;/code&gt; returns the &lt;strong&gt;entire page as a Chrome accessibility tree&lt;/strong&gt; — think of it as The Giant Text Dump. For a complex web app, that's 20–30k+ characters (roughly 5–15k tokens). All of it goes straight into Claude's context.&lt;/p&gt; &lt;p&gt;A typical multi-step browser flow: &lt;strong&gt;6 snapshots × 5–15k tokens = tens of thousands of tokens of raw DOM&lt;/strong&gt; fed to Opus. That's like making a Michelin-star chef read the entire phone book before cooking your eggs.&lt;/p&gt; &lt;p&gt;On a Claude Code subscription, this eats into your usage limits and bloats your context window, triggering compaction sooner. On API billing, it just hurts your wallet directly.&lt;/p&gt; &lt;h1&gt;The Solution: Ducks As Middleware&lt;/h1&gt; &lt;p&gt;What if the DOM never touches Claude's context?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Before:&lt;/strong&gt; Claude (Opus) talks to Chrome DevTools MCP directly. Every snapshot — thousands of DOM tokens — lands in Opus context.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;After:&lt;/strong&gt; Claude asks a duck. The duck calls Chrome DevTools, processes the entire DOM, and returns a tiny answer.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Claude → ask_duck(&amp;quot;find the Submit button&amp;quot;) Duck → [calls take_snapshot, parses 25k chars] Duck → &amp;quot;uid is 1_462&amp;quot; Claude → [sees 10 tokens, not 15,000] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;a href="https://github.com/nesquikm/mcp-rubber-duck"&gt;MCP Rubber Duck&lt;/a&gt; is an MCP server that lets you route work to other LLMs (Gemini, GPT, Groq, local models) and MCP tools. Its MCP bridge lets ducks call other MCP servers autonomously. I connected Chrome DevTools to the bridge, and now Gemini Flash does all the DOM wrestling. Claude only sees short summaries.&lt;/p&gt; &lt;h1&gt;Setup&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;You'll need:&lt;/strong&gt; Claude Code (or any MCP host), &lt;a href="https://github.com/nesquikm/mcp-rubber-duck"&gt;mcp-rubber-duck&lt;/a&gt;, Chrome DevTools MCP, and a Gemini API key.&lt;/p&gt; &lt;p&gt;Add Chrome DevTools to the rubber duck's bridge config. In your &lt;code&gt;~/.claude.json&lt;/code&gt; (Claude Code's config file), add these env vars to the rubber-duck MCP server:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&amp;quot;MCP_SERVER_CHROME_TYPE&amp;quot;: &amp;quot;stdio&amp;quot;, &amp;quot;MCP_SERVER_CHROME_COMMAND&amp;quot;: &amp;quot;npx&amp;quot;, &amp;quot;MCP_SERVER_CHROME_ARGS&amp;quot;: &amp;quot;chrome-devtools-mcp@latest&amp;quot;, &amp;quot;MCP_SERVER_CHROME_ENABLED&amp;quot;: &amp;quot;true&amp;quot;, &amp;quot;MCP_TRUSTED_TOOLS_CHROME&amp;quot;: &amp;quot;*&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Remove any direct &lt;code&gt;chrome-devtools&lt;/code&gt; MCP server from your project config. Only one process can own the Chrome profile. Two chrome-devtools-mcp processes fighting over a SingletonLock file is not a debugging experience I recommend.&lt;/p&gt; &lt;p&gt;Restart Claude Code. Check bridge status:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;mcp__rubber-duck__mcp_status 🟢 chrome (stdio) - connected, 26 tools &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The duck can now click buttons. We're all doomed.&lt;/p&gt; &lt;h1&gt;How It Actually Looks&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;Old way&lt;/strong&gt; — Opus processes everything:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;→ take_snapshot [entire DOM into Opus context] → Opus parses it, finds uid → Usage: ~5–15k Opus tokens per snapshot &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;New way&lt;/strong&gt; — duck processes everything:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;→ ask_duck(gemini): &amp;quot;Call take_snapshot. Find button containing Submit. Report ONLY its uid.&amp;quot; → Gemini Flash: &amp;quot;8_37&amp;quot; [DOM processed in duck's context, invisible to Opus] → Opus sees: &amp;quot;8_37&amp;quot; → Usage: ~100 Opus tokens + Gemini tokens (your Gemini API, not Claude quota) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The DOM snapshot lives and dies inside the duck's context. Claude never knows the page has 47 nested divs for a single button.&lt;/p&gt; &lt;h1&gt;The Gotchas (There Are Always Gotchas)&lt;/h1&gt; &lt;h1&gt;1. One Tool Per Duck Prompt&lt;/h1&gt; &lt;p&gt;In practice, Gemini Flash is far more reliable when each prompt triggers a single, focused tool call:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Bad: &amp;quot;Navigate to the page, take snapshot, find the button&amp;quot; → [half a tool call, three apologies, and a paragraph about its limitations] Good: &amp;quot;Call take_snapshot MCP tool. Find the Submit button. Report ONLY its uid.&amp;quot; → &amp;quot;1_462&amp;quot; ✓ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;One MCP tool call per ask_duck. The duck is smart but not &amp;quot;follow a 12-step plan&amp;quot; smart.&lt;/p&gt; &lt;h1&gt;2. Cache Busting&lt;/h1&gt; &lt;p&gt;Rubber Duck caches identical prompts by design to save repeated LLM calls. Great, until you actually want to repeat an action:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Bad: &amp;quot;Call click MCP tool with uid 8_37. Report the result.&amp;quot; &amp;quot;Call click MCP tool with uid 8_37. Report the result.&amp;quot; → Second one returns cached, button never clicked Good: &amp;quot;Call click MCP tool with uid 8_37. Report the result.&amp;quot; &amp;quot;Click the Submit button now. Call click with uid 8_37.&amp;quot; → Both execute ✓ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Vary your prompt wording and the cache won't bite you.&lt;/p&gt; &lt;h1&gt;3. Directive Prompts&lt;/h1&gt; &lt;p&gt;This isn't duck-specific — it's &amp;quot;tool-using LLMs 101&amp;quot; — but it bites you here too:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Me: &amp;quot;Can you take a snapshot?&amp;quot; Gemini: &amp;quot;I can call take_snapshot, but it provides a text snapshot of the page's accessibility tree, not information about 'buttons' or 'forms.' Could you please clarify...&amp;quot; Me: &amp;quot;Call take_snapshot MCP tool. Report what you see.&amp;quot; Gemini: [actually does it] ✓ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&amp;quot;Call X MCP tool&amp;quot; not &amp;quot;Can you use X&amp;quot;. Be the manager, not the coworker.&lt;/p&gt; &lt;h1&gt;The Numbers&lt;/h1&gt; &lt;p&gt;A typical multi-step browser automation (navigate → interact with UI → fill forms → verify result):&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th align="left"&gt;_&lt;/th&gt; &lt;th align="left"&gt;Direct Chrome MCP&lt;/th&gt; &lt;th align="left"&gt;Duck Bridge&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td align="left"&gt;Opus tokens (per snapshot)&lt;/td&gt; &lt;td align="left"&gt;~5,000–15,000&lt;/td&gt; &lt;td align="left"&gt;~100 (summary only)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;Snapshots seen by Opus&lt;/td&gt; &lt;td align="left"&gt;~6&lt;/td&gt; &lt;td align="left"&gt;0&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;Total Opus context impact&lt;/td&gt; &lt;td align="left"&gt;Tens of thousands of tokens&lt;/td&gt; &lt;td align="left"&gt;~600 tokens&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;Who processes DOM&lt;/td&gt; &lt;td align="left"&gt;Opus (your subscription)&lt;/td&gt; &lt;td align="left"&gt;Gemini Flash (pennies via API)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align="left"&gt;You could use even cheaper models. &lt;code&gt;gemini-2.5-flash-lite&lt;/code&gt; has a massive context window and costs almost nothing — perfect for DOM parsing where you don't need deep reasoning, just &amp;quot;find the button called Submit.&amp;quot;&lt;/td&gt; &lt;td align="left"&gt;&lt;/td&gt; &lt;td align="left"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;h1&gt;Bonus: Multimodal Possibilities&lt;/h1&gt; &lt;p&gt;The setup above uses &lt;code&gt;take_snapshot&lt;/code&gt; (text accessibility tree), but Chrome DevTools also has &lt;code&gt;take_screenshot&lt;/code&gt; (actual images). Since Gemini is multimodal, you could have the duck process visual screenshots instead of DOM trees:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ask_duck(gemini): &amp;quot;Call take_screenshot. Describe what you see. Is there a Submit button? Where is it?&amp;quot; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Visual debugging through a cheap multimodal model, without the screenshot ever touching your host LLM's context. I haven't fully tested this path yet, but the architecture supports it.&lt;/p&gt; &lt;h1&gt;The Architecture&lt;/h1&gt; &lt;pre&gt;&lt;code&gt;┌──────────────────────────────────┐ │ Claude Code (Opus) │ │ │ │ &amp;quot;ask_duck: find Submit button&amp;quot; │ │ │ │ ┌────────────────────────────┐ │ │ │ Rubber Duck MCP Server │ │ │ │ │ │ │ │ Gemini Flash ←→ Chrome │ │ │ │ [processes DevTools │ │ │ │ entire DOM] [26 tools]│ │ │ └────────────────────────────┘ │ │ │ │ Duck returns: &amp;quot;uid is 8_37&amp;quot; │ │ Opus context: ~100 tokens │ └──────────────────────────────────┘ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The DOM enters the duck. A uid exits the duck. Your context window thanks the duck.&lt;/p&gt; &lt;h1&gt;Try It&lt;/h1&gt; &lt;p&gt;GitHub: &lt;a href="https://github.com/nesquikm/mcp-rubber-duck"&gt;https://github.com/nesquikm/mcp-rubber-duck&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The bridge supports any MCP server — stdio or HTTP. Chrome DevTools is just one use case. Any tool that produces massive output (documentation scrapers, code analyzers, log parsers) can be routed through a cheap duck to keep your host LLM's context clean.&lt;/p&gt; &lt;p&gt;The ducks went from arguing about tabs vs spaces to browsing the internet and filling out forms. They're one PR away from a LinkedIn profile.&lt;/p&gt; &lt;p&gt;P.S. — The duck found a button, clicked it, filled a modal, and submitted a form. All while Opus sat there reviewing a 10-token summary like a CEO reading a one-page brief. Peak delegation.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/nesquikm"&gt; /u/nesquikm &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qq3ibm/my_rubber_ducks_learned_to_browse_the_web_and/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qq3ibm/my_rubber_ducks_learned_to_browse_the_web_and/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qq3ibm/my_rubber_ducks_learned_to_browse_the_web_and/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T08:56:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1qq0rab</id>
    <title>Figma MCP is read-only, so I built a write-enabled MCP using code execution</title>
    <updated>2026-01-29T06:14:54+00:00</updated>
    <author>
      <name>/u/marv1nnnnn</name>
      <uri>https://old.reddit.com/user/marv1nnnnn</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qq0rab/figma_mcp_is_readonly_so_i_built_a_writeenabled/"&gt; &lt;img alt="Figma MCP is read-only, so I built a write-enabled MCP using code execution" src="https://external-preview.redd.it/2G9izi-zBseQvm-cfUBoPWn0lswzbxtzmSHDnyb5Jq4.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e35be390d9bc62f7934773215a0d241dc5de82a6" title="Figma MCP is read-only, so I built a write-enabled MCP using code execution" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/marv1nnnnn"&gt; /u/marv1nnnnn &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/youware-labs/figma-pilot"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qq0rab/figma_mcp_is_readonly_so_i_built_a_writeenabled/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qq0rab/figma_mcp_is_readonly_so_i_built_a_writeenabled/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T06:14:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7pl2v</id>
    <title>Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers</title>
    <updated>2024-12-06T01:23:42+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt; &lt;img alt="Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers" src="https://external-preview.redd.it/_brkexfHYjxC2eADV5MfgvEttUuxvpShYZ2vAIxM6cI.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ecb04d6570882855a6cd592912cb4a1ca169c5f8" title="Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/punkpeye/awesome-mcp-servers/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T01:23:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7qe88</id>
    <title>Join the Model Context Protocol Discord Server!</title>
    <updated>2024-12-06T02:04:10+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/discord"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T02:04:10+00:00</published>
  </entry>
</feed>
