<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/mcp/.rss</id>
  <title>Model Context Protocol (MCP)</title>
  <updated>2025-12-10T04:54:21+00:00</updated>
  <link href="https://old.reddit.com/r/mcp/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools</subtitle>
  <entry>
    <id>t3_1phhpt4</id>
    <title>How I turned claude into my actual personal assistant (and made it 10x better with one mcp)</title>
    <updated>2025-12-08T16:59:56+00:00</updated>
    <author>
      <name>/u/mate_0107</name>
      <uri>https://old.reddit.com/user/mate_0107</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1phhpt4/how_i_turned_claude_into_my_actual_personal/"&gt; &lt;img alt="How I turned claude into my actual personal assistant (and made it 10x better with one mcp)" src="https://external-preview.redd.it/NkDpVDcLhdWFKNStojdcUCn214mcg0s4ijIhoAFjGn0.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6cae5b4aef9733a90a2389e706d58108f3321c7c" title="How I turned claude into my actual personal assistant (and made it 10x better with one mcp)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I was a chatgpt paid user until 5 months ago. Started building a memory mcp for AI agents and had to use claude to test it. Once I saw how claude seamlessly searches CORE and pulls relevant context, I couldn't go back. Cancelled chatgpt pro, switched to caude.&lt;/p&gt; &lt;p&gt;Now I tell claude &amp;quot;Block deep work time for my Linear tasks this week&amp;quot; and it pulls my Linear tasks, checks Google Calendar for conflicts, searches my deep work preferences from CORE, and schedules everything.&lt;/p&gt; &lt;p&gt;That's what CORE does - memory and actions working together.&lt;/p&gt; &lt;p&gt;I build CORE as a memory layer to provide AI tools like claude with persistent memory that works across all your tools, and the ability to actually act in your apps. Not just read them, but send emails, create calendar events, add Linear tasks, search Slack, update Notion. Full read-write access.&lt;/p&gt; &lt;p&gt;Here's my day. I'm brainstorming a new feature in claude. Later I'm in Cursor coding and ask &amp;quot;search that feature discussion from core&amp;quot; and it knows. I tell claude &amp;quot;send an email to the user who signed up&amp;quot; and it drafts it in my writing style, pulls project context from memory, and sends it through Gmail. &amp;quot;Add a task to Linear for the API work&amp;quot; and it's done.&lt;/p&gt; &lt;p&gt;Claude knows my projects, my preferences, how I work. When I'm debugging, it remembers architecture decisions we made months ago and why. That context follows me everywhere - cursor, claude code, windsurf, vs code, any tool that support mcp.&lt;/p&gt; &lt;p&gt;Claude has memory but it's a black box. I can't see what it refers, can't organize it, can't tell it &amp;quot;use THIS context.&amp;quot; With CORE I can. I keep features in one document, content guidelines in another, project decisions in another. Claude pulls the exact context I need. The memory is also temporal - it tracks when things changed and why.&lt;/p&gt; &lt;p&gt;Claude has memory and can refer old chats but it's a black box for me. I can't see what it refers from old chats, can't organize it, and can't tell it &amp;quot;use THIS context for this task.&amp;quot; With CORE I can. I keep all my features context in one document in CORE, all my content guidelines in another, my project decisions in another. When I need them, I just reference them and claude pulls the exact context.&lt;/p&gt; &lt;p&gt;Before CORE: &amp;quot;Draft an email to the xyz about our new feature&amp;quot; -&amp;gt; claude writes generic email -&amp;gt; I manually add feature context, messaging, my writing style -&amp;gt; copy/paste to Gmail -&amp;gt; tomorrow claude forgot everything.&lt;/p&gt; &lt;p&gt;With CORE: &amp;quot;Send an email to the xyz about our new feature, search about feature, my writing style from core&amp;quot;&lt;/p&gt; &lt;p&gt;That's a personal assistant. Remembers how you work, acts on your behalf, follows you across every tool. It's not a chatbot I re-train every conversation. It's an assistant that knows me.&lt;/p&gt; &lt;p&gt;If you want to try it, setup takes about 5 minutes.&lt;/p&gt; &lt;p&gt;Guide: &lt;a href="https://docs.getcore.me/providers/claude"&gt;https://docs.getcore.me/providers/claude&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Core is also open source so you can self-host the whole thing from &lt;a href="https://github.com/RedPlanetHQ/core"&gt;https://github.com/RedPlanetHQ/core&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://reddit.com/link/1phhpt4/video/qywbeaw2h06g1/player"&gt;https://reddit.com/link/1phhpt4/video/qywbeaw2h06g1/player&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mate_0107"&gt; /u/mate_0107 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1phhpt4/how_i_turned_claude_into_my_actual_personal/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1phhpt4/how_i_turned_claude_into_my_actual_personal/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1phhpt4/how_i_turned_claude_into_my_actual_personal/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-08T16:59:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi6nyw</id>
    <title>Octocode Research MCP is now in your IDE as extension üîçüêô</title>
    <updated>2025-12-09T12:54:11+00:00</updated>
    <author>
      <name>/u/_bgauryy_</name>
      <uri>https://old.reddit.com/user/_bgauryy_</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1pi6nyw/octocode_research_mcp_is_now_in_your_ide_as/"&gt; &lt;img alt="Octocode Research MCP is now in your IDE as extension üîçüêô" src="https://preview.redd.it/fxapvxuzd66g1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=cddd96792aa37229255b5d439459e2c90fd4ab8d" title="Octocode Research MCP is now in your IDE as extension üîçüêô" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Octocode MCP is powerful research tool that helps research anything anywhere&lt;br /&gt; You can find more details about it here: &lt;a href="http://octocode.ai"&gt;octocode.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Please follow installation guide üôè&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/_bgauryy_"&gt; /u/_bgauryy_ &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/fxapvxuzd66g1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi6nyw/octocode_research_mcp_is_now_in_your_ide_as/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi6nyw/octocode_research_mcp_is_now_in_your_ide_as/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T12:54:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi38ps</id>
    <title>OpenMCPSpec: The Future of Agent-Tool Reliability</title>
    <updated>2025-12-09T09:33:06+00:00</updated>
    <author>
      <name>/u/CarefulLeading9053</name>
      <uri>https://old.reddit.com/user/CarefulLeading9053</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;h1&gt;üì¢ The Future of Agent-Tool Reliability!&lt;/h1&gt; &lt;p&gt;&lt;strong&gt;The Problem:&lt;/strong&gt; We all love LLM Agents, but we hate the fragility. In the enterprise, current Model Context Protocols (MCPs) often lead to agents making unreliable tool calls, creating massive &lt;strong&gt;governance debt&lt;/strong&gt;, and leaving developers struggling with brittle, high-maintenance integrations.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; We're thrilled to introduce &lt;strong&gt;OpenMCPSpec&lt;/strong&gt;‚Äîa novel, open-source specification framework designed to turn those fragile tools into robust, lifecycle-managed software artifacts for enterprise LLM-Agent systems.&lt;/p&gt; &lt;h1&gt;What Makes OpenMCPSpec a Game-Changer? üí°&lt;/h1&gt; &lt;p&gt;OpenMCPSpec isn't just another API definition; it‚Äôs an integration contract built for trust and performance. It embeds critical context right into the service definition, allowing agent systems to operate with unprecedented reliability:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Declarative Reliability:&lt;/strong&gt; We address tool-calling fragility at its source. The spec includes &lt;strong&gt;LLM reliability hints&lt;/strong&gt; that provide semantic context, dramatically improving the agent's ability to select the correct tool and generate flawless arguments.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Contract-Enforced Governance:&lt;/strong&gt; Say goodbye to security being an afterthought. OpenMCPSpec formally embeds essential Non-Functional Requirements (NFRs) like &lt;strong&gt;PII sensitivity flags&lt;/strong&gt; and &lt;strong&gt;Role-Based Access Control (RBAC)&lt;/strong&gt; directly into the contract. This allows the agent system to enforce compliance &lt;em&gt;before&lt;/em&gt; business logic is even executed.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Dynamic Lifecycle Management:&lt;/strong&gt; The framework mandates a machine-readable &lt;strong&gt;Enumeration&lt;/strong&gt; summary, enabling agents to dynamically discover and negotiate compatibility with MCP servers at runtime. This kills the brittleness that plagues continuous deployment environments.&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Why You Should Get Involved Now ü§ù&lt;/h1&gt; &lt;p&gt;We have a formal JSON schema, a detailed research paper (more on that later üòâ), and a reference implementation. But this is just the beginning.&lt;/p&gt; &lt;p&gt;We need your help to evolve OpenMCPSpec into the industry standard for LLM-Agent service integration across all major ecosystems.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;We are inviting contributors, architects, and communities to join us to:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Develop Client Libraries:&lt;/strong&gt; Build starter kits for Python (LangChain/LangGraph), TypeScript, Go, etc., to consume the OpenMCPSpec.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Define Domain Extensions:&lt;/strong&gt; Help us create standardized nlp_hints and metadata fields for specific industries (e.g., Core Banking, Healthcare, Logistics).&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Validate and Stress Test:&lt;/strong&gt; Implement the spec in real-world environments and contribute to our validation metrics.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;üëâ &lt;strong&gt;Explore the specification, star the repo, and join the discussion!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;üîó OpenMCPSpec Repository:&lt;/strong&gt; &lt;a href="https://github.com/pvchaitu/mcp-agents-intents-schema-spec"&gt;https://github.com/pvchaitu/mcp-agents-intents-schema-spec&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Let's solve enterprise agent fragility, together! #LLMAgents #OpenSource #AI #EnterpriseAI #OpenMCPSpec #ToolCalling&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/CarefulLeading9053"&gt; /u/CarefulLeading9053 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi38ps/openmcpspec_the_future_of_agenttool_reliability/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi38ps/openmcpspec_the_future_of_agenttool_reliability/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi38ps/openmcpspec_the_future_of_agenttool_reliability/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T09:33:06+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi84th</id>
    <title>Banana Image MCP ‚Äì Enables Claude and other AI assistants to generate high-quality images up to 4K resolution using Google's Gemini image models, with support for flexible aspect ratios, natural language editing, and Google Search grounding for accurate results.</title>
    <updated>2025-12-09T14:00:04+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@zengwenliang416/banana-image-mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi84th/banana_image_mcp_enables_claude_and_other_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi84th/banana_image_mcp_enables_claude_and_other_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T14:00:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi8i5k</id>
    <title>The MCP ecosystem is a mess. Who wants to help design a better catalog?</title>
    <updated>2025-12-09T14:15:37+00:00</updated>
    <author>
      <name>/u/Mean-Ad-4755</name>
      <uri>https://old.reddit.com/user/Mean-Ad-4755</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;One year in, and finding reliable &lt;strong&gt;MCP Servers&lt;/strong&gt; is still a nightmare. I spend way too much time digging through Docker Hub, GitHub, and random docs, only to paste unverified configs.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Am I the only one feeling this pain, or am I missing something?&lt;/strong&gt; (Is there a good registry I just haven't found?)&lt;/p&gt; &lt;p&gt;If not, I want to build a &lt;strong&gt;Vendor-Neutral, Community-Vetted Catalog&lt;/strong&gt;. It would aggregate all sources and be a free public utility.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; I‚Äôm a startup founder and I need a reliable catalog for my own product. But honestly, I‚Äôm just sick of the chaos. This is a basic problem that we need to solve as a community.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Want to help build it?&lt;/strong&gt; I created a community at &lt;a href="/r/MCPRegistry"&gt;r/MCPRegistry&lt;/a&gt; to post updates and gather feedback. I'd love for you to join if you want to follow the progress.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Sanity Check:&lt;/strong&gt; I don't want to build this if no one cares. If this is something you would actually use, please &lt;strong&gt;let me know in the comments&lt;/strong&gt; so I know there is real demand.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Mean-Ad-4755"&gt; /u/Mean-Ad-4755 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi8i5k/the_mcp_ecosystem_is_a_mess_who_wants_to_help/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi8i5k/the_mcp_ecosystem_is_a_mess_who_wants_to_help/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi8i5k/the_mcp_ecosystem_is_a_mess_who_wants_to_help/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T14:15:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi9zev</id>
    <title>Vvkmnn/claude-praetorian-mcp: ‚öúÔ∏è An MCP server for aggressive TOON based context compaction &amp; recycling in Claude Code</title>
    <updated>2025-12-09T15:16:15+00:00</updated>
    <author>
      <name>/u/v3_14</name>
      <uri>https://old.reddit.com/user/v3_14</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1pi9zev/vvkmnnclaudepraetorianmcp_an_mcp_server_for/"&gt; &lt;img alt="Vvkmnn/claude-praetorian-mcp: ‚öúÔ∏è An MCP server for aggressive TOON based context compaction &amp;amp; recycling in Claude Code" src="https://external-preview.redd.it/JKJr7P5I4N5bRwxC1ysElOXJ7vkliLolwLBMTuhIi24.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=63db2b0ff6c232faaf0a0aca766096deb1c4a291" title="Vvkmnn/claude-praetorian-mcp: ‚öúÔ∏è An MCP server for aggressive TOON based context compaction &amp;amp; recycling in Claude Code" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/v3_14"&gt; /u/v3_14 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/fw5y6gko176g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi9zev/vvkmnnclaudepraetorianmcp_an_mcp_server_for/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi9zev/vvkmnnclaudepraetorianmcp_an_mcp_server_for/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T15:16:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1pib4nl</id>
    <title>microCMS MCP Server ‚Äì A Model Context Protocol (MCP) compliant server that allows Large Language Models (LLMs) to search and retrieve content from microCMS APIs.</title>
    <updated>2025-12-09T16:00:05+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@SpringMT/microcms-mcp-server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pib4nl/microcms_mcp_server_a_model_context_protocol_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pib4nl/microcms_mcp_server_a_model_context_protocol_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T16:00:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1pic1uu</id>
    <title>Looking to host my web app in Digital Ocean using MCPs as a new Vibecoder. Is it good?</title>
    <updated>2025-12-09T16:34:22+00:00</updated>
    <author>
      <name>/u/Entire_Put_1444</name>
      <uri>https://old.reddit.com/user/Entire_Put_1444</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Entire_Put_1444"&gt; /u/Entire_Put_1444 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pic1uu/looking_to_host_my_web_app_in_digital_ocean_using/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pic1uu/looking_to_host_my_web_app_in_digital_ocean_using/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pic1uu/looking_to_host_my_web_app_in_digital_ocean_using/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T16:34:22+00:00</published>
  </entry>
  <entry>
    <id>t3_1pic588</id>
    <title>I built DiffPilot ‚Äì a 100% local MCP server for PR code review (VS Code, Copilot, Claude)</title>
    <updated>2025-12-09T16:37:49+00:00</updated>
    <author>
      <name>/u/MindOk9299</name>
      <uri>https://old.reddit.com/user/MindOk9299</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/MindOk9299"&gt; /u/MindOk9299 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/mcp/comments/1pic4iy/i_built_diffpilot_a_100_local_mcp_server_for_pr/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pic588/i_built_diffpilot_a_100_local_mcp_server_for_pr/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pic588/i_built_diffpilot_a_100_local_mcp_server_for_pr/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T16:37:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1picqod</id>
    <title>Canvas MCP Server ‚Äì Enables AI assistants like Claude to interact with Canvas LMS through the Canvas API, providing tools for managing courses, announcements, rubrics, assignments, and student data.</title>
    <updated>2025-12-09T17:00:04+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@ranver/mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1picqod/canvas_mcp_server_enables_ai_assistants_like/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1picqod/canvas_mcp_server_enables_ai_assistants_like/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T17:00:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi4a81</id>
    <title>Open-source: convert Figma designs to code with Flowbite MCP</title>
    <updated>2025-12-09T10:39:43+00:00</updated>
    <author>
      <name>/u/elwingo1</name>
      <uri>https://old.reddit.com/user/elwingo1</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1pi4a81/opensource_convert_figma_designs_to_code_with/"&gt; &lt;img alt="Open-source: convert Figma designs to code with Flowbite MCP" src="https://external-preview.redd.it/dnQ4Nzl1ZXpwNTZnMTm9C7ERHThZ6Y7dKzoGVOzLqAcSbDIlGGGf5TWNK-Rn.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=64987590b7ac43dddfba10da63f19753740701c3" title="Open-source: convert Figma designs to code with Flowbite MCP" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey everyone üëã&lt;/p&gt; &lt;p&gt;We built an open-source &lt;a href="https://flowbite.com/docs/getting-started/mcp/"&gt;MCP server for Flowbite&lt;/a&gt; that allows you to convert Figma designs to code with the right context in a Tailwind CSS and Flowbite project.&lt;/p&gt; &lt;p&gt;It also provides the right context of the UI library with resources and you can also generate theme files based on branded HEX color inputs.&lt;/p&gt; &lt;p&gt;Feedback is more than welcome and contributions too as it is MIT licensed.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/themesberg/flowbite-mcp"&gt;GitHub Repository&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://flowbite.com/docs/getting-started/mcp/"&gt;Documentation on Flowbite&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/elwingo1"&gt; /u/elwingo1 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/lnlvj2ezp56g1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi4a81/opensource_convert_figma_designs_to_code_with/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi4a81/opensource_convert_figma_designs_to_code_with/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T10:39:43+00:00</published>
  </entry>
  <entry>
    <id>t3_1pij51d</id>
    <title>HubSpot MCP Server ‚Äì A server implementation that enables AI assistants to interact with HubSpot CRM data, allowing for seamless creation and management of contacts and companies, retrieval of activity history, and access to engagement data through natural language commands.</title>
    <updated>2025-12-09T21:00:04+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@lkm1developer/hubspot-mcp-server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pij51d/hubspot_mcp_server_a_server_implementation_that/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pij51d/hubspot_mcp_server_a_server_implementation_that/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T21:00:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1pije0e</id>
    <title>Kubernetes MCP</title>
    <updated>2025-12-09T21:09:52+00:00</updated>
    <author>
      <name>/u/Funny_Welcome_5575</name>
      <uri>https://old.reddit.com/user/Funny_Welcome_5575</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have private aks cluster which uses kubelogin to login. So initially i need to activate PIM then need to connect to context in local which askes to put device code. So i wamna ask two things 1.Since my cluster is private if i create chatbot for users to check and troubleshoot items how authentication i can add in my python code so if the users have access only they can do any activates inside the cluster&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Funny_Welcome_5575"&gt; /u/Funny_Welcome_5575 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pije0e/kubernetes_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pije0e/kubernetes_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pije0e/kubernetes_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T21:09:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1pieehj</id>
    <title>mcp-nvd ‚Äì A Model Context Protocol server implementation to query the NIST National Vulnerability Database (NVD) via its API.</title>
    <updated>2025-12-09T18:00:04+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@marcoeg/mcp-nvd"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pieehj/mcpnvd_a_model_context_protocol_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pieehj/mcpnvd_a_model_context_protocol_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T18:00:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1pikmp9</id>
    <title>MCP Google Server ‚Äì A Model Context Protocol server that provides web search capabilities using Google Custom Search API and webpage content extraction functionality.</title>
    <updated>2025-12-09T22:00:07+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@pgzhang/mcp"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pikmp9/mcp_google_server_a_model_context_protocol_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pikmp9/mcp_google_server_a_model_context_protocol_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T22:00:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1pifwe8</id>
    <title>MCP Database Server ‚Äì A Model Context Protocol server that enables LLMs to interact with databases (currently MongoDB) through natural language, supporting operations like querying, inserting, deleting documents, and running aggregation pipelines.</title>
    <updated>2025-12-09T19:00:02+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@manpreet2000/mcp-database-server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pifwe8/mcp_database_server_a_model_context_protocol/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pifwe8/mcp_database_server_a_model_context_protocol/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T19:00:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1pimr54</id>
    <title>Does Quarkus MCP streamable Http support Cursor?</title>
    <updated>2025-12-09T23:25:43+00:00</updated>
    <author>
      <name>/u/weeveratsea</name>
      <uri>https://old.reddit.com/user/weeveratsea</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I build customized MCP by Quarkus, but never could connect to Cursor. Does anyone use Qaurkus MCP server?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/weeveratsea"&gt; /u/weeveratsea &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pimr54/does_quarkus_mcp_streamable_http_support_cursor/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pimr54/does_quarkus_mcp_streamable_http_support_cursor/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pimr54/does_quarkus_mcp_streamable_http_support_cursor/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T23:25:43+00:00</published>
  </entry>
  <entry>
    <id>t3_1pi0d5c</id>
    <title>Yeah, most MCPs are bad. So how do we make tool calling actually work?</title>
    <updated>2025-12-09T06:25:14+00:00</updated>
    <author>
      <name>/u/ImaginationInFocus</name>
      <uri>https://old.reddit.com/user/ImaginationInFocus</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Our eng team works on tools for AI agents and has spent far too many hours testing tools. Yes, many MCP servers today are inefficient and flaky in accomplishing the goal task. &lt;/p&gt; &lt;p&gt;But MCP servers are not hopeless. They just aren‚Äôt functional without engineering workarounds that most teams never discover.&lt;/p&gt; &lt;p&gt;This article isn't novel. It‚Äôs just sharing how we approached evaluation and how we improve MCP tools on these metrics.&lt;/p&gt; &lt;h1&gt;How We Evaluate Tool Calling&lt;/h1&gt; &lt;p&gt;Typically, tool calling evals assess how different models perform at using the same set of tools. We flipped this around and tested for a single LLM (Sonnet 4.5) which toolset design is best?&lt;/p&gt; &lt;p&gt;To start, we compared an LLM using an API (of Clerk, Render, or Attio, for example) versus those same tools routed through toolsets we generated and optimized.&lt;/p&gt; &lt;p&gt;For each scenario we measured 5 metrics:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;strong&gt;Goal attainment&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Runtime&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Token usage&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Error count&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Output quality&lt;/strong&gt;, using LLM as a judge on accuracy, completeness, and clarity&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;With the optimizations below, overall we saw:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Goal attainment&lt;/strong&gt; increased 30% while &lt;strong&gt;runtime&lt;/strong&gt; decreased 50% and &lt;strong&gt;token usage&lt;/strong&gt; decreased 80%.&lt;/p&gt; &lt;p&gt;Here's what we did:&lt;/p&gt; &lt;h1&gt;Table stakes optimizations&lt;/h1&gt; &lt;p&gt;Skipping explanations on these since everyone in the sub is probably already doing it...&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Tool name and description optimizations&lt;/li&gt; &lt;li&gt;Tool selection&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Tool Batching&lt;/h1&gt; &lt;p&gt;Agents normally call tools one at a time. We added tool batching, which allows the agent to parallelize work.&lt;/p&gt; &lt;p&gt;Instead of:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Call tool A on ID 1 ‚Üí Reason ‚Üí Call tool A on ID 2 ‚Üí Reason ‚Üí Repeat &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The agent can perform one tool call with all IDs at once.&lt;/p&gt; &lt;p&gt;This turned out to be one of our biggest practical wins. Without batching, the model burns tokens figuring out what to do next, which IDs remain, and which tool to use. It can also get lazy and stop early before processing everything it should. Every remote call adds latency too, which makes MCP servers painfully slow.&lt;/p&gt; &lt;p&gt;In our evals, batching plus workflows made the biggest improvements on the metric of ‚Äúgoal attainment.‚Äù&lt;/p&gt; &lt;h1&gt;Workflows&lt;/h1&gt; &lt;p&gt;MCP servers let AI interact with software in a non-deterministic way, which is powerful but sometimes unpredictable. Workflows give us a way to embed deterministic logic inside that flexible environment so certain processes run the same way every time.&lt;/p&gt; &lt;p&gt;You can think of workflows as predictable/manageable Code Mode (which you can read more about from &lt;a href="https://blog.cloudflare.com/code-mode/"&gt;Cloudflare&lt;/a&gt; and &lt;a href="https://www.anthropic.com/engineering/code-execution-with-mcp"&gt;Anthropic&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;A workflow is essentially a multi-step API sequence with parameter mapping. Creating them is the challenging part. When the desired sequence is obvious, we define it manually. When it isn‚Äôt, we let the AI operate with a standard MCP and then run an LLM analysis over the chat history to identify recurring tool-call patterns that should be turned into workflows. Finally, the LLM calls the workflow as one compound tool.&lt;/p&gt; &lt;h1&gt;Response Filtering&lt;/h1&gt; &lt;p&gt;We added response filtering to handle endpoints that return large, uncurated result sets. It allows the LLM to request subsets such as ‚Äúrecords where X‚Äù after receiving a response.&lt;/p&gt; &lt;p&gt;Response filtering performs filtering on the response &lt;strong&gt;values&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;In practice, many MCP tools expose APIs that return paginated data, and the LLM sees only one page at a time. The filter is applied after that page arrives, so the LLM never has access to the full dataset on the client side. Any filter you apply later operates only on this incomplete slice, which means it is easy to filter your way into incorrect conclusions.&lt;/p&gt; &lt;h1&gt;Response Projection&lt;/h1&gt; &lt;p&gt;Projection can be turned on per-tool. It enables the LLM to specify which fields it cares out about in the output schema and then the tool only returns those fields.&lt;/p&gt; &lt;p&gt;Response projection performs filtering on the response &lt;strong&gt;fields&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;When we detect that a response would be ‚Äútoo large,‚Äù the system automatically triggers response projection and filtering.&lt;/p&gt; &lt;h1&gt;Response Compression&lt;/h1&gt; &lt;p&gt;We implemented lossless JSON compression that preserves all information while removing blank fields and collapsing repeated content. For example, a response like:&lt;/p&gt; &lt;p&gt;&lt;code&gt;{{id: a, label: green} {id:b, label: green} {id:c, label: green} etc.}&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Becomes&lt;/p&gt; &lt;p&gt;&lt;code&gt;{ {id: a}, {id: b}, {id: c} } The label for all objects is green.&lt;/code&gt;&lt;/p&gt; &lt;p&gt;This reduces token usage 30‚Äì40%.&lt;/p&gt; &lt;p&gt;When a JSON response is not too large or deeply nested, we apply another layer of optimization by converting the structure into a markdown table. This further reduces token usage 20-30%.&lt;/p&gt; &lt;p&gt;Combined with projection and batching, we see 80%+ reduction in token usage.&lt;/p&gt; &lt;h1&gt;Next Steps&lt;/h1&gt; &lt;p&gt;We have several next steps planned:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;We plan to introduce a ‚Äúconsistency‚Äù metric and run each evaluation set multiple times to see how toolset optimizations affect repeatability.&lt;/li&gt; &lt;li&gt;We plan to run head-to-head comparisons of optimized MCP servers versus existing MCP servers. Our experience so far is that many MCPs from well known companies struggle in practice, and we want to quantify that.&lt;/li&gt; &lt;li&gt;Finally, we want to expand testing across more models. We used Sonnet 4.5 for this and we want to broaden the LLM test set to see how these optimizations generalize.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;If you're curious, I posted a deeper dive of this on our &lt;a href="https://www.tadata.com/blog/how-we-make-ai-tool-calling-work"&gt;blog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To steal a line I saw from someone else and liked: Thoughts are mine, edited (lightly) by AI ü§ñ &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ImaginationInFocus"&gt; /u/ImaginationInFocus &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi0d5c/yeah_most_mcps_are_bad_so_how_do_we_make_tool/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pi0d5c/yeah_most_mcps_are_bad_so_how_do_we_make_tool/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pi0d5c/yeah_most_mcps_are_bad_so_how_do_we_make_tool/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T06:25:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1pihjng</id>
    <title>Foundry MCP Server ‚Äì An MCP server that allows AI assistants to interact with Foundry datasets, ontology objects, and functions through natural language queries and commands.</title>
    <updated>2025-12-09T20:00:07+00:00</updated>
    <author>
      <name>/u/modelcontextprotocol</name>
      <uri>https://old.reddit.com/user/modelcontextprotocol</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/modelcontextprotocol"&gt; /u/modelcontextprotocol &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/servers/@qwert666/mcp-server-foundry"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pihjng/foundry_mcp_server_an_mcp_server_that_allows_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pihjng/foundry_mcp_server_an_mcp_server_that_allows_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T20:00:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1picumi</id>
    <title>I built an MCP that lets you review ANY branch diff with Copilot - no GitHub PR needed</title>
    <updated>2025-12-09T17:03:52+00:00</updated>
    <author>
      <name>/u/MindOk9299</name>
      <uri>https://old.reddit.com/user/MindOk9299</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Been lurking here for a while and finally built something worth sharing.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The Problem:&lt;/strong&gt; You checkout a feature branch to review someone's code, but there's no way to easily get AI-assisted code review without creating a PR first. Or you want to self-review your own changes before pushing.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The Solution:&lt;/strong&gt; DiffPilot - an MCP server that brings diff-aware code review directly into VS Code + Copilot.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Here's the magic:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Just checkout any branch and ask Copilot:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;@workspace #review_pr_changes &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;That's it. It auto-detects your base branch (main/master/develop), grabs the diff, and gives you a proper code review.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Why this is actually useful:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;üî• &lt;strong&gt;Works without GitHub/GitLab integration&lt;/strong&gt; - Your company uses Azure DevOps? TFS? Self-hosted git? Air-gapped environment? Doesn't matter. It's 100% local git.&lt;/p&gt; &lt;p&gt;üî• &lt;strong&gt;Self-review before pushing&lt;/strong&gt; - Catch your own mistakes before your teammates do. Just run review on your branch before creating the PR.&lt;/p&gt; &lt;p&gt;üî• &lt;strong&gt;Reviewer workflow&lt;/strong&gt; - Checkout the branch you're reviewing, ask for review with focus areas like &amp;quot;focus on security&amp;quot; or &amp;quot;check error handling&amp;quot;&lt;/p&gt; &lt;p&gt;üî• &lt;strong&gt;Zero config&lt;/strong&gt; - No tokens, no API keys, no repository setup. It just works with whatever repo you have open.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Other tools included:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;#scan_secrets&lt;/code&gt; - catches API keys before you commit them (saved my ass twice already)&lt;/li&gt; &lt;li&gt;&lt;code&gt;#generate_commit_message&lt;/code&gt; - analyzes your staged changes&lt;/li&gt; &lt;li&gt;&lt;code&gt;#generate_pr_description&lt;/code&gt; - creates the whole PR template&lt;/li&gt; &lt;li&gt;&lt;code&gt;#suggest_tests&lt;/code&gt; - tells you what tests to write for your changes&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Real workflow example:&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;git checkout feature/user-authentication @workspace #review_pr_changes focus on security and error handling &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Copilot now sees the actual diff and reviews it properly instead of guessing.&lt;/p&gt; &lt;p&gt;Works with GitHub Copilot Chat in VS Code. Also works with Claude Desktop if you're into that.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/MindOk9299"&gt; /u/MindOk9299 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1picumi/i_built_an_mcp_that_lets_you_review_any_branch/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1picumi/i_built_an_mcp_that_lets_you_review_any_branch/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1picumi/i_built_an_mcp_that_lets_you_review_any_branch/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T17:03:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1pioyws</id>
    <title>Can I call Gemini CLI in Gemini CLI via MCP?</title>
    <updated>2025-12-10T01:02:35+00:00</updated>
    <author>
      <name>/u/fleker2</name>
      <uri>https://old.reddit.com/user/fleker2</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I have a bit of a workflow that takes in a long list of entries and performs a Gemini action on each one (calling an MCP tool). I have tried to put this in one prompt but Gemini gets too confused.&lt;/p&gt; &lt;p&gt;To fix this, I can use a bash script which calls Gemini through the command-line in sequence.&lt;/p&gt; &lt;p&gt;gemini --yolo --model gemini-2.5-flash --prompt &amp;quot;...&amp;quot;&lt;/p&gt; &lt;p&gt;This works well but now I want to set it up so that I can run this bash script in my MCP server (or translate the calls).&lt;/p&gt; &lt;p&gt;My MCP server is a hodge-podge of tools built in Node.js using the fastmcp library. I run it in a local server and connect via localhost HTTP. While everything else responds well, if I try to use this server to execute my bash script it seems to stall out before any gemini calls are executed.&lt;/p&gt; &lt;p&gt;I tried to rewrite the server to use Node.js methods instead, like `exec`, `spawn`, and `execSync` / `spawnSync`. But while my tool will reach that line of code, it never actually finishes executing and everything just stalls.&lt;/p&gt; &lt;p&gt;Even if I make the prompt something simple like &amp;quot;hello&amp;quot;, it never runs. If I run this command individually in a test Node file it does work.&lt;/p&gt; &lt;p&gt;Is it possible for me to do this? I'm trying to build some sort of agent-ish system and want to build more examples of giving Gemini CLI a simple instruction and running manual tools and LLMs to write custom workflows.&lt;/p&gt; &lt;p&gt;To make matters more complicated, this is running in WSL on Windows, which might have its own very particularly problems.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/fleker2"&gt; /u/fleker2 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pioyws/can_i_call_gemini_cli_in_gemini_cli_via_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pioyws/can_i_call_gemini_cli_in_gemini_cli_via_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pioyws/can_i_call_gemini_cli_in_gemini_cli_via_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-10T01:02:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1piga1d</id>
    <title>MCP token costs exploded at 10+ servers - here's how we fixed it</title>
    <updated>2025-12-09T19:13:48+00:00</updated>
    <author>
      <name>/u/dinkinflika0</name>
      <uri>https://old.reddit.com/user/dinkinflika0</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;We built &lt;a href="https://github.com/maximhq/bifrost"&gt;&lt;strong&gt;Bifrost&lt;/strong&gt;&lt;/a&gt;, an LLM gateway that sits between your app and models. It handles routing, caching, observability, and MCP.&lt;/p&gt; &lt;h1&gt;The problem we hit&lt;/h1&gt; &lt;p&gt;We started with &lt;strong&gt;3 MCP servers;&lt;/strong&gt; everything worked great.&lt;br /&gt; Then we added &lt;strong&gt;7 more&lt;/strong&gt; (Notion, Slack, Gmail, Docs, internal APIs‚Ä¶).&lt;/p&gt; &lt;p&gt;Suddenly, the LLM was receiving &lt;strong&gt;~150 tool definitions on every single request&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The pain:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Token explosion&lt;/strong&gt; - 150 tool schemas sent before the model even reads the question&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Latency death&lt;/strong&gt; - 6‚Äì10 LLM turns for multi-step workflows&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Cost spiral&lt;/strong&gt; - paying repeatedly to send the same 150 tool definitions&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Example workflow: &lt;em&gt;search web ‚Üí get YouTube videos ‚Üí create a Doc&lt;/em&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Turn 1: prompt + 150 tools ‚Üí web.search Turn 2: prompt + result + 150 tools ‚Üí youtube.listChannels Turn 3: prompt + results + 150 tools ‚Üí youtube.listVideos ... ~6 total turns &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Each intermediate result loops back through the model.&lt;/p&gt; &lt;p&gt;Our solution: &lt;strong&gt;Bifrost MCP Code Mode&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Instead of exposing 150 tools, the model sees &lt;strong&gt;just 3&lt;/strong&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;listFiles&lt;/code&gt; ‚Äî discover MCP servers&lt;/li&gt; &lt;li&gt;&lt;code&gt;readFile&lt;/code&gt; ‚Äî load TypeScript definitions on demand&lt;/li&gt; &lt;li&gt;&lt;code&gt;executeCode&lt;/code&gt; ‚Äî run code in a sandbox&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The model writes &lt;strong&gt;one code block&lt;/strong&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import * as web from &amp;quot;servers/web&amp;quot;; import * as youtube from &amp;quot;servers/youtube&amp;quot;; import * as docs from &amp;quot;servers/docs&amp;quot;; const company = await web.search({ ... }); const channels = await youtube.listChannels({ ... }); const videos = await youtube.listVideos({ ... }); return await docs.createDoc({ ... }); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We execute it once.&lt;/p&gt; &lt;p&gt;All MCP calls run inside the sandbox; &lt;strong&gt;intermediate results never touch the model&lt;/strong&gt;.&lt;/p&gt; &lt;h1&gt;Results&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;60‚Äì70% fewer tokens&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;3‚Äì4 turns instead of 6‚Äì10&lt;/strong&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Better orchestration&lt;/strong&gt; (code gives us loops, branching, and error handling)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can mix &lt;strong&gt;code mode&lt;/strong&gt; and &lt;strong&gt;classic tool calling&lt;/strong&gt; per MCP server, so adoption can be gradual. Anyone else hitting this at scale?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dinkinflika0"&gt; /u/dinkinflika0 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1piga1d/mcp_token_costs_exploded_at_10_servers_heres_how/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1piga1d/mcp_token_costs_exploded_at_10_servers_heres_how/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1piga1d/mcp_token_costs_exploded_at_10_servers_heres_how/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T19:13:48+00:00</published>
  </entry>
  <entry>
    <id>t3_1pid0vu</id>
    <title>MCP moves to the Linux Foundation's new Agentic AI Foundation</title>
    <updated>2025-12-09T17:10:07+00:00</updated>
    <author>
      <name>/u/evantahler</name>
      <uri>https://old.reddit.com/user/evantahler</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Management of the following projects moves to the Linux Foundation:&lt;/p&gt; &lt;p&gt;- MCP&lt;/p&gt; &lt;p&gt;- goose&lt;/p&gt; &lt;p&gt;- &lt;a href="http://AGENTS.md"&gt;AGENTS.md&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Learn more @ &lt;a href="https://aaif.io/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation-aaif-anchored-by-new-project-contributions-including-model-context-protocol-mcp-goose-and-agents-md/"&gt;https://aaif.io/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation-aaif-anchored-by-new-project-contributions-including-model-context-protocol-mcp-goose-and-agents-md/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/evantahler"&gt; /u/evantahler &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pid0vu/mcp_moves_to_the_linux_foundations_new_agentic_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1pid0vu/mcp_moves_to_the_linux_foundations_new_agentic_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1pid0vu/mcp_moves_to_the_linux_foundations_new_agentic_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2025-12-09T17:10:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7pl2v</id>
    <title>Awesome MCP Servers ‚Äì A curated list of awesome Model Context Protocol (MCP) servers</title>
    <updated>2024-12-06T01:23:42+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt; &lt;img alt="Awesome MCP Servers ‚Äì A curated list of awesome Model Context Protocol (MCP) servers" src="https://external-preview.redd.it/_brkexfHYjxC2eADV5MfgvEttUuxvpShYZ2vAIxM6cI.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ecb04d6570882855a6cd592912cb4a1ca169c5f8" title="Awesome MCP Servers ‚Äì A curated list of awesome Model Context Protocol (MCP) servers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/punkpeye/awesome-mcp-servers/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T01:23:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7qe88</id>
    <title>Join the Model Context Protocol Discord Server!</title>
    <updated>2024-12-06T02:04:10+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/discord"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T02:04:10+00:00</published>
  </entry>
</feed>
