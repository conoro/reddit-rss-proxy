<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/mcp/.rss</id>
  <title>Model Context Protocol (MCP)</title>
  <updated>2026-01-29T06:53:47+00:00</updated>
  <link href="https://old.reddit.com/r/mcp/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools</subtitle>
  <entry>
    <id>t3_1qobxmj</id>
    <title>MCP apps VS Apps SDK (OpenAI)</title>
    <updated>2026-01-27T12:01:00+00:00</updated>
    <author>
      <name>/u/0xKoller</name>
      <uri>https://old.reddit.com/user/0xKoller</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;MCP Apps is now an official extension to the Model Context Protocol (MCP), enabling tools to return interactive UI components that render directly within MCP clients. It overcomes the limitations of text-based interactions by delivering rich, sandboxed UI experiences right inside conversations, while keeping the model involved through seamless bidirectional communication.&lt;/p&gt; &lt;p&gt;Before this, we had OpenAI's Apps SDK, a proprietary alternative that allowed similar functionality but was limited to the ChatGPT sandbox, with exclusive runtime variables and APIs. In contrast, MCP Apps enables UI rendering in &lt;em&gt;any&lt;/em&gt; MCP client that supports it, promoting a more open and portable ecosystem.&lt;/p&gt; &lt;h1&gt;GPT Apps vs. MCP Apps&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Backbone&lt;/strong&gt;: GPT Apps build on MCP plus OpenAI's proprietary widget runtime, while MCP Apps use pure MCP with a standardized UI extension.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;UI Declaration&lt;/strong&gt;: GPT Apps declare UIs via &lt;code&gt;_meta.openai/outputTemplate&lt;/code&gt; or similar, whereas MCP Apps use the standard &lt;code&gt;_meta.ui.resourceUri: &amp;quot;ui://dashboard&amp;quot;&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;UI Delivery&lt;/strong&gt;: Both deliver bundled HTML/JS resources served by an MCP server.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Host and UI&lt;/strong&gt;: GPT Apps rely on OpenAI-specific widget runtime and postMessage, but MCP Apps standardize it with JSON-RPC over postMessage.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The ecosystem has converged remarkably fast. MCP Apps emerges as the open, multi-platform winner going forward and with ChatGPT now supporting the official standard, you no longer have to choose between them. OpenAI may even phase out their proprietary development in the near future.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/0xKoller"&gt; /u/0xKoller &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qobxmj/mcp_apps_vs_apps_sdk_openai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-27T12:01:00+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp7kqb</id>
    <title>poly-mcp/GitLab-MCP-Server: MCP server for GitLab integration with AI assistants. Works with Cursor, ChatGPT and PolyMCP. Manage merge requests, analyze CI/CD pipelines, create ADR documents.</title>
    <updated>2026-01-28T10:17:08+00:00</updated>
    <author>
      <name>/u/Just_Vugg_PolyMCP</name>
      <uri>https://old.reddit.com/user/Just_Vugg_PolyMCP</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp7kqb/polymcpgitlabmcpserver_mcp_server_for_gitlab/"&gt; &lt;img alt="poly-mcp/GitLab-MCP-Server: MCP server for GitLab integration with AI assistants. Works with Cursor, ChatGPT and PolyMCP. Manage merge requests, analyze CI/CD pipelines, create ADR documents." src="https://external-preview.redd.it/pIP8syx-VXNYHFQcTSjOim8JyqpG2rSv0e3N3WcNbr4.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=cb03f2d8acd710f732bccac06a507ee02e3f3d17" title="poly-mcp/GitLab-MCP-Server: MCP server for GitLab integration with AI assistants. Works with Cursor, ChatGPT and PolyMCP. Manage merge requests, analyze CI/CD pipelines, create ADR documents." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Just_Vugg_PolyMCP"&gt; /u/Just_Vugg_PolyMCP &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/poly-mcp/GitLab-MCP-Server"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp7kqb/polymcpgitlabmcpserver_mcp_server_for_gitlab/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp7kqb/polymcpgitlabmcpserver_mcp_server_for_gitlab/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T10:17:08+00:00</published>
  </entry>
  <entry>
    <id>t3_1qodaze</id>
    <title>Sims 1 Legacy MCP</title>
    <updated>2026-01-27T13:05:39+00:00</updated>
    <author>
      <name>/u/pevers</name>
      <uri>https://old.reddit.com/user/pevers</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/"&gt; &lt;img alt="Sims 1 Legacy MCP" src="https://preview.redd.it/nnn207a64wfg1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d1b1ac60b422ac94d6308ec4c500920e114851ed" title="Sims 1 Legacy MCP" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A MCP server we have all been waiting for. This is a hack that adds a MCP server to the Sims 1 Legacy so that you can use AI to interact with your Sims household. I created it as an exercise to reverse engineer games using GhydraMCP and Claude Code. At the moment it is read-only but I'm working on extending the MCP server to also query actions (imagine having a household of different LLMs).&lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/pevers/sims-mcp"&gt;https://github.com/pevers/sims-mcp&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/pevers"&gt; /u/pevers &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/nnn207a64wfg1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qodaze/sims_1_legacy_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-27T13:05:39+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp9xf0</id>
    <title>I built 15 Python MCP tools to supercharge AI coding assistants (now open source!) . Would love a feedback and a star</title>
    <updated>2026-01-28T12:23:36+00:00</updated>
    <author>
      <name>/u/Notalabel_4566</name>
      <uri>https://old.reddit.com/user/Notalabel_4566</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp9xf0/i_built_15_python_mcp_tools_to_supercharge_ai/"&gt; &lt;img alt="I built 15 Python MCP tools to supercharge AI coding assistants (now open source!) . Would love a feedback and a star" src="https://external-preview.redd.it/AIek67RvZPUU6ae5tAPAw6mk1AsW5RMQJaFcsW246uI.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=92ee771c555b0fe191dfe850aa75c57faf8ae41f" title="I built 15 Python MCP tools to supercharge AI coding assistants (now open source!) . Would love a feedback and a star" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Think of them as specialized tools that your AI can use to understand and improve your codebase.&lt;/p&gt; &lt;p&gt;All 15 tools are organized in a clean monorepo with:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Individual pyproject.toml for each tool&lt;/li&gt; &lt;li&gt;Shared quality tooling configuration&lt;/li&gt; &lt;li&gt;Per-tool READMEs and documentation&lt;/li&gt; &lt;li&gt;Easy installation via pip or uvx&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Notalabel_4566"&gt; /u/Notalabel_4566 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/Abhisheksinha1506/Client-mcpserver"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp9xf0/i_built_15_python_mcp_tools_to_supercharge_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp9xf0/i_built_15_python_mcp_tools_to_supercharge_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T12:23:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1qog1wq</id>
    <title>I wrote Concierge, an Open Source library to convert MCPs into tool groups, stages and workflows which are progressively discovered as agents interact with the server.</title>
    <updated>2026-01-27T14:56:15+00:00</updated>
    <author>
      <name>/u/Prestigious-Play8738</name>
      <uri>https://old.reddit.com/user/Prestigious-Play8738</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt; &lt;p&gt;Anyone else tired of configuring 50 tools into MCP and just hoping the agent figures it out? (invoking the right tools in the right order).&lt;/p&gt; &lt;p&gt;We keep hitting same problems:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Agent calls `checkout()` before `add_to_cart()`&lt;/li&gt; &lt;li&gt;Context bloat: 50+ tools served for every conversation message.&lt;/li&gt; &lt;li&gt;Semantic loss: Agent does not know which tools are relevant for the current interaction&lt;/li&gt; &lt;li&gt;Adding a system prompt describing the order of tool invocation and praying that the agent follows it.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;So I wrote Concierge. It converts your MCP into a stateful graph, where you can organize tools into stages and workflows, and agents only have tools &lt;strong&gt;visible to the current stage&lt;/strong&gt;.&lt;/p&gt; &lt;pre&gt;&lt;code&gt;from concierge import Concierge app = Concierge(&amp;quot;my-server&amp;quot;) app.stages = { &amp;quot;browse&amp;quot;: [&amp;quot;search_products&amp;quot;], &amp;quot;cart&amp;quot;: [&amp;quot;add_to_cart&amp;quot;], &amp;quot;checkout&amp;quot;: [&amp;quot;pay&amp;quot;] } app.transitions = { &amp;quot;browse&amp;quot;: [&amp;quot;cart&amp;quot;], &amp;quot;cart&amp;quot;: [&amp;quot;checkout&amp;quot;] } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This also supports sharded distributed state and semantic search for thousands of tools. (also compatible with existing MCPs)&lt;/p&gt; &lt;p&gt;Do try it out and love to know what you think. Thanks!&lt;/p&gt; &lt;p&gt;Repo: &lt;a href="https://github.com/concierge-hq/concierge"&gt;https://github.com/concierge-hq/concierge&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Install it with: &lt;code&gt;pip install concierge-sdk&lt;/code&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Prestigious-Play8738"&gt; /u/Prestigious-Play8738 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qog1wq/i_wrote_concierge_an_open_source_library_to/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-27T14:56:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp64x4</id>
    <title>Lightweight CLI tool to interact with MCP</title>
    <updated>2026-01-28T08:49:27+00:00</updated>
    <author>
      <name>/u/konradkokosa</name>
      <uri>https://old.reddit.com/user/konradkokosa</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"&gt; &lt;img alt="Lightweight CLI tool to interact with MCP" src="https://b.thumbs.redditmedia.com/i-RI13_vgrHZLc5pTOfOSCoXqgJOewB2ly3VU7kZYnM.jpg" title="Lightweight CLI tool to interact with MCP" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I was surprised to find that a tool I expected to exist didn't - a simple REPL CLI tool to investigate MCP servers. I know there is MCP Inspector but I needed something I can quickly fire up, list and call some tools, and close it. I found some one-shot CLI tools for this but nothing interactive/REPL. &lt;/p&gt; &lt;p&gt;So, I've made one:&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/rrvh2tu9z1gg1.png?width=821&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d94c3b7dc46522b786fe87ed62fa726b252c9c70"&gt;https://preview.redd.it/rrvh2tu9z1gg1.png?width=821&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d94c3b7dc46522b786fe87ed62fa726b252c9c70&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Repository: &lt;a href="https://github.com/kkokosa/repl-mcp"&gt;https://github.com/kkokosa/repl-mcp&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/konradkokosa"&gt; /u/konradkokosa &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp64x4/lightweight_cli_tool_to_interact_with_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T08:49:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpeai7</id>
    <title>Jan, 2026: "KNOWLEDGE ATTAINS DEMOCRACY"</title>
    <updated>2026-01-28T15:23:56+00:00</updated>
    <author>
      <name>/u/0xraghu</name>
      <uri>https://old.reddit.com/user/0xraghu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpeai7/jan_2026_knowledge_attains_democracy/"&gt; &lt;img alt="Jan, 2026: &amp;quot;KNOWLEDGE ATTAINS DEMOCRACY&amp;quot;" src="https://b.thumbs.redditmedia.com/5r-GibJgzjn7OYiQu-TqrehB9JZiQ-KlNiy4YdfY6sA.jpg" title="Jan, 2026: &amp;quot;KNOWLEDGE ATTAINS DEMOCRACY&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/0xraghu"&gt; /u/0xraghu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/ClaudeCode/comments/1qp3j03/jan_2026_knowledge_attains_democracy/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpeai7/jan_2026_knowledge_attains_democracy/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpeai7/jan_2026_knowledge_attains_democracy/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T15:23:56+00:00</published>
  </entry>
  <entry>
    <id>t3_1qph3b8</id>
    <title>Bridging AI Development Ecosystems: VSCode LM Tools ↔️ MCP</title>
    <updated>2026-01-28T17:03:25+00:00</updated>
    <author>
      <name>/u/Traditional-Tart-393</name>
      <uri>https://old.reddit.com/user/Traditional-Tart-393</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Traditional-Tart-393"&gt; /u/Traditional-Tart-393 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/vscode/comments/1qph2tq/bridging_ai_development_ecosystems_vscode_lm/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qph3b8/bridging_ai_development_ecosystems_vscode_lm/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qph3b8/bridging_ai_development_ecosystems_vscode_lm/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T17:03:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1qphmfw</id>
    <title>Building the MCP inspector for teams</title>
    <updated>2026-01-28T17:21:32+00:00</updated>
    <author>
      <name>/u/matt8p</name>
      <uri>https://old.reddit.com/user/matt8p</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qphmfw/building_the_mcp_inspector_for_teams/"&gt; &lt;img alt="Building the MCP inspector for teams" src="https://external-preview.redd.it/NGVrZGVpbXFpNGdnMf9EYl3am4o-FFeuqYpEkF3jqWjTj3_Zb9gvJIEcnwAR.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5e06a8930dca0b24aea93988aaac267791aa44e5" title="Building the MCP inspector for teams" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey y'all, it's Matt from &lt;a href="https://www.mcpjam.com/"&gt;MCPJam&lt;/a&gt;. We recently launched workspaces within MCPJam inspector. You can think of them as folders for your MCP servers, helping you organize your work if you work on multiple projects. Workspaces are also shareable, making it easy to share your workflow amongst your team. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;MCPJam&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;For context, MCPJam is an open source MCP inspector alternative. It's like the MCP inspector but with a built in LLM playground, visual OAuth debugger, and support for ChatGPT apps SDK / MCP apps. &lt;/p&gt; &lt;p&gt;We started the last project last May and are working on it full time now. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Check it out&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;We hope MCP developers find our tool useful. If this sounds interesting, please consider giving the project a try! &lt;/p&gt; &lt;p&gt;&lt;a href="https://github.com/MCPJam/inspector"&gt;https://github.com/MCPJam/inspector&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/matt8p"&gt; /u/matt8p &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/61u3zdmqi4gg1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qphmfw/building_the_mcp_inspector_for_teams/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qphmfw/building_the_mcp_inspector_for_teams/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T17:21:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpja9a</id>
    <title>100% open source MCP server for PostgreSQL: now with write access, reduced token consumption, improved UX, &amp; more</title>
    <updated>2026-01-28T18:17:25+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.pgedge.com/blog/what-s-new-in-the-pgedge-postgres-mcp-server-beta-2-and-beta-3"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpja9a/100_open_source_mcp_server_for_postgresql_now/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpja9a/100_open_source_mcp_server_for_postgresql_now/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T18:17:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp7qh7</id>
    <title>A browser sandbox for Agent, https://deeptask.ai/</title>
    <updated>2026-01-28T10:26:16+00:00</updated>
    <author>
      <name>/u/Chix9527</name>
      <uri>https://old.reddit.com/user/Chix9527</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"&gt; &lt;img alt="A browser sandbox for Agent, https://deeptask.ai/" src="https://b.thumbs.redditmedia.com/b3h79nXpd10_yOYiHgjaiw-E0fBLiKxHNoBtMR4CvLs.jpg" title="A browser sandbox for Agent, https://deeptask.ai/" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Code as skills. &lt;a href="https://deeptask.ai/"&gt;https://deeptask.ai/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/rpaayld7h2gg1.png?width=3061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7ee134534f982d06c5ad5b2d07b3332fe4a329d1"&gt;https://preview.redd.it/rpaayld7h2gg1.png?width=3061&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7ee134534f982d06c5ad5b2d07b3332fe4a329d1&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Chix9527"&gt; /u/Chix9527 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp7qh7/a_browser_sandbox_for_agent_httpsdeeptaskai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T10:26:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpodm7</id>
    <title>what patterns have you noticed when choosing AI models?</title>
    <updated>2026-01-28T21:20:05+00:00</updated>
    <author>
      <name>/u/justgetting-started</name>
      <uri>https://old.reddit.com/user/justgetting-started</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/justgetting-started"&gt; /u/justgetting-started &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="/r/aipromptprogramming/comments/1qpoaz6/what_patterns_have_you_noticed_when_choosing_ai/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpodm7/what_patterns_have_you_noticed_when_choosing_ai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpodm7/what_patterns_have_you_noticed_when_choosing_ai/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T21:20:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpenvd</id>
    <title>Jira automation + MCP server to break Figma designs into stories</title>
    <updated>2026-01-28T15:37:49+00:00</updated>
    <author>
      <name>/u/No-Addendum-2793</name>
      <uri>https://old.reddit.com/user/No-Addendum-2793</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpenvd/jira_automation_mcp_server_to_break_figma_designs/"&gt; &lt;img alt="Jira automation + MCP server to break Figma designs into stories" src="https://external-preview.redd.it/iK469q4nYpN59xJv0IAPgnsXWm7p5vamg_BpAK1i_no.jpeg?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3cc27c93b29334531db4b439a28a4eea095db233" title="Jira automation + MCP server to break Figma designs into stories" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey all! I’ve been experimenting with AI workflows inside Jira, and my team built an MCP server + Jira automations that help turn Figma designs into Jira stories (all open source)&lt;/p&gt; &lt;p&gt;Workflow is basically:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Clarify scope&lt;/strong&gt; (assumptions + questions based on the design/comments)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Split the work&lt;/strong&gt; (breaks the feature into smaller stories)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Write the tickets&lt;/strong&gt; (generates full Jira tickets w/ acceptance criteria + Figma links)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;I recorded a short YouTube demo walkthrough and included the &lt;strong&gt;r&lt;/strong&gt;epo + setup instructions in the description.&lt;/p&gt; &lt;p&gt;Happy to answer questions / would appreciate feedback from anyone building with MCP or agent workflows.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/No-Addendum-2793"&gt; /u/No-Addendum-2793 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.youtube.com/watch?v=MK0tdwDBTmc"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpenvd/jira_automation_mcp_server_to_break_figma_designs/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpenvd/jira_automation_mcp_server_to_break_figma_designs/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T15:37:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1qp9c1l</id>
    <title>How are you running MCP servers beyond local demos?</title>
    <updated>2026-01-28T11:54:27+00:00</updated>
    <author>
      <name>/u/Sumanth_077</name>
      <uri>https://old.reddit.com/user/Sumanth_077</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;For anyone using MCP beyond quick demos, how are you running MCP servers in practice?&lt;/p&gt; &lt;p&gt;Are you mostly:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;running them locally on a workstation when they need access to files or editors&lt;/li&gt; &lt;li&gt;containerizing them and running them somewhere managed, either one per agent or shared&lt;/li&gt; &lt;li&gt;or treating them more like remote services and just calling them over HTTP&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Each of these seems to come with different tradeoffs around isolation, reuse, and ops overhead.&lt;/p&gt; &lt;p&gt;I’ve been looking at managed setups on Clarifai where public MCP servers are deployed as APIs and discovered by models at inference time, instead of being bundled into every runtime.&lt;/p&gt; &lt;p&gt;Curious what people here are doing today and what’s been annoying or unexpectedly smooth.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Sumanth_077"&gt; /u/Sumanth_077 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qp9c1l/how_are_you_running_mcp_servers_beyond_local_demos/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T11:54:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpp5hl</id>
    <title>Building opensource Zero Server Code Intelligence Engine</title>
    <updated>2026-01-28T21:49:15+00:00</updated>
    <author>
      <name>/u/DeathShot7777</name>
      <uri>https://old.reddit.com/user/DeathShot7777</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpp5hl/building_opensource_zero_server_code_intelligence/"&gt; &lt;img alt="Building opensource Zero Server Code Intelligence Engine" src="https://external-preview.redd.it/eGs5MTUzdTV2NWdnMX8xZ7UL_WAflwTq0BqeDmN95WRo5Ajh0fAkuzEXaT9M.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=5fcf2583014651d67ae6686c4e1a8cab038ac570" title="Building opensource Zero Server Code Intelligence Engine" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi, guys, I m building GitNexus, an opensource Code Intelligence Engine which works fully client sided in-browser. There have been lot of progress since I last posted.&lt;/p&gt; &lt;p&gt;Repo: &lt;a href="https://github.com/abhigyanpatwari/GitNexus"&gt;https://github.com/abhigyanpatwari/GitNexus&lt;/a&gt; ( ⭐ would help so much, u have no idea!! )&lt;br /&gt; Try: &lt;a href="https://gitnexus.vercel.app/"&gt;https://gitnexus.vercel.app/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It creates a Knowledge Graph from github repos and exposes an Agent with specially designed tools and also MCP support. Idea is to solve the project wide context issue in tools like cursor, claude code, etc and have a shared code intelligence layer for multiple agents. It provides a reliable way to retrieve full context important for codebase audits, blast radius detection of code changes and deep architectural understanding of the codebase for both humans and LLM. ( Ever encountered the issue where cursor updates some part of the codebase but fails to adapt other dependent functions around it ? this should solve it )&lt;/p&gt; &lt;p&gt;&lt;strong&gt;I tested it using cursor through MCP. Even without the impact tool and LLM enrichment feature, haiku 4.5 model was able to produce better Architecture documentation compared to opus 4.5 without MCP on PyBamm repo ( its a complex battery modelling repo )&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Opus 4.5 was asked to get into as much detail as possible but haiku had a simple prompt asking it to explain the architecture. The output files were compared in chatgpt 5.2 chat link: &lt;a href="https://chatgpt.com/share/697a7a2c-9524-8009-8112-32b83c6c9fe4"&gt;https://chatgpt.com/share/697a7a2c-9524-8009-8112-32b83c6c9fe4&lt;/a&gt;&lt;/p&gt; &lt;p&gt;( IK its not a good enough benchmark but still promising )&lt;/p&gt; &lt;p&gt;Quick tech jargon:&lt;/p&gt; &lt;p&gt;- Everything including db engine, embeddings model, all works in-browser client sided&lt;/p&gt; &lt;p&gt;- The project architecture flowchart u can see in the video is generated without LLM during repo ingestion so is reliable.&lt;/p&gt; &lt;p&gt;- Creates clusters ( using leidens algo ) and process maps during ingestion.&lt;/p&gt; &lt;p&gt;- It has all the usual tools like grep, semantic search, etc but enhanced majorly using process maps and clusters making the tool themselves smart hence a lot of the decisions the LLM had to make to retrieve context is offloaded into the tools, making it much more reliable even with non sota models.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What I need help with:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;- To convert it into a actually useful product do u think I should make it like a CLI tool that keeps track of local code changes and updating the graph?&lt;/p&gt; &lt;p&gt;- Is there some way to get some free API credits or sponsorship or something so that I can test gitnexus with multiple providers&lt;/p&gt; &lt;p&gt;- Some insights into enterprise code problems like security audits or dead code detection or any other potential usecase I can tune gitnexus for?&lt;/p&gt; &lt;p&gt;Any cool idea and suggestion helps a lot. The comments on previous post helped a LOT, thanks.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DeathShot7777"&gt; /u/DeathShot7777 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/wincxnt5v5gg1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpp5hl/building_opensource_zero_server_code_intelligence/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpp5hl/building_opensource_zero_server_code_intelligence/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T21:49:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpa84z</id>
    <title>HTTP2/HTTP3 support in the future?</title>
    <updated>2026-01-28T12:38:07+00:00</updated>
    <author>
      <name>/u/DorkyMcDorky</name>
      <uri>https://old.reddit.com/user/DorkyMcDorky</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Quick question for &lt;a href="/r/mcp"&gt;r/mcp&lt;/a&gt;: has anyone considered an HTTP/2 or HTTP/3 transport option for MCP, even if HTTP/1 stays the baseline? I get the tradeoffs like HTTP/1 ubiquity, stateless infra, and simpler deployment, but I am curious how folks weigh those against streaming and long lived connections.&lt;/p&gt; &lt;p&gt;I know HTTP/2 or HTTP/3 can be a pain in cloud environments and external facing SaaS, but for internal networks and home labs it is much easier and brings real benefits like multiplexing and true streaming. Maybe MCP is mainly targeting SaaS cloud infra, but it feels like a huge miss that there is no true streaming option for internal use cases.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DorkyMcDorky"&gt; /u/DorkyMcDorky &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpa84z/http2http3_support_in_the_future/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T12:38:07+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpvlmy</id>
    <title>Wake - Terminal context for Claude Code via MCP</title>
    <updated>2026-01-29T02:11:50+00:00</updated>
    <author>
      <name>/u/averagemrjoe</name>
      <uri>https://old.reddit.com/user/averagemrjoe</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I built an tool that records terminal sessions and exposes them to Claude Code via MCP. The idea: stop copy-pasting logs and command output into chat.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;How it works:&lt;/strong&gt;&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;code&gt;wake shell&lt;/code&gt; spawns your shell inside a PTY, capturing all commands and output&lt;/li&gt; &lt;li&gt;Shell hooks (zsh/bash) notify wake when commands start/end&lt;/li&gt; &lt;li&gt;Everything gets stored in a local SQLite database&lt;/li&gt; &lt;li&gt;The &lt;code&gt;wake-mcp&lt;/code&gt; server exposes this data via MCP tools&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;MCP Tools:&lt;/strong&gt;&lt;/p&gt; &lt;table&gt;&lt;thead&gt; &lt;tr&gt; &lt;th&gt;Tool&lt;/th&gt; &lt;th&gt;Purpose&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_status&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Current session info&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_list_commands&lt;/code&gt;&lt;/td&gt; &lt;td&gt;List recent commands with metadata + summaries&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_get_output&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Fetch full output for specific command IDs&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_log&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Recent commands with truncated output&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_search&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Search command history&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_dump&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Export session as markdown&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;wake_annotate&lt;/code&gt;&lt;/td&gt; &lt;td&gt;Add notes to the session&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; &lt;p&gt;The &lt;code&gt;wake_list_commands&lt;/code&gt; + &lt;code&gt;wake_get_output&lt;/code&gt; pattern enables tiered retrieval - Claude sees command metadata first, then fetches full output only when needed. Reduces context usage significantly.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Local LLM summarization:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;New in v0.5.0: wake automatically summarizes command outputs using a local Qwen2.5-0.5B model (~468MB). Summaries appear in &lt;code&gt;wake_list_commands&lt;/code&gt;, so Claude can quickly understand what happened without reading thousands of lines of build logs.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Runs on CPU (no GPU needed)&lt;/li&gt; &lt;li&gt;Downloads automatically on first use&lt;/li&gt; &lt;li&gt;All inference happens locally&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Setup:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;sh curl -sSf https://raw.githubusercontent.com/joemckenney/wake/main/install.sh | sh eval &amp;quot;$(wake init zsh)&amp;quot; # or bash claude mcp add wake-mcp -- wake-mcp &lt;/code&gt;&lt;/p&gt; &lt;p&gt;GitHub: &lt;a href="https://github.com/joemckenney/wake"&gt;https://github.com/joemckenney/wake&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Happy to answer questions about the MCP integration or architecture.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/averagemrjoe"&gt; /u/averagemrjoe &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvlmy/wake_terminal_context_for_claude_code_via_mcp/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvlmy/wake_terminal_context_for_claude_code_via_mcp/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpvlmy/wake_terminal_context_for_claude_code_via_mcp/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T02:11:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpjn96</id>
    <title>How I program everywhere</title>
    <updated>2026-01-28T18:29:58+00:00</updated>
    <author>
      <name>/u/Eyoba_19</name>
      <uri>https://old.reddit.com/user/Eyoba_19</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;So I've been programming in the metro, when waiting for the doctor, heck even in the bathroom. I mean it's quite the downfall from my dream of sitting in front of multiple large monitors with cmatrix style code, dark hoodies and insane typing speeds with Jarvis handing me my coffee.&lt;/p&gt; &lt;p&gt;But yeah I think I like this more.&lt;/p&gt; &lt;p&gt;So wanted to share how I do it, starting with the tools I use: &lt;/p&gt; &lt;ul&gt; &lt;li&gt;Linear for managing my tasks&lt;/li&gt; &lt;li&gt;Github for hosting my repo&lt;/li&gt; &lt;li&gt;Slack/Telegram for communication (currently in progress, but promising I tell you)&lt;/li&gt; &lt;li&gt;LLMs - codex and claude code (expanding to gemini)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;How they come together, imagine this: &lt;/p&gt; &lt;p&gt;Using Linear on my phone, I write down a task for my project, put it in spec status.&lt;/p&gt; &lt;p&gt;Few minutes later I see a spec, read it, if I'm happy, I set it as ready for dev, few minutes later a PR is ready.&lt;/p&gt; &lt;p&gt;If there are any failed checks on actions, no worries few minutes later they're all fixed and ready for merge, just needs my approval. &lt;/p&gt; &lt;p&gt;I make a few comments, few minutes again all fixed, I look at it again, if I'm happy, I approve and merge. &lt;/p&gt; &lt;p&gt;And how long? 30min, maybe an hour max, what could’ve possibly taken me a day or even a week?&lt;/p&gt; &lt;p&gt;Here’s the cool thing, I’m always doing multiple tasks and all in parallel. That was possibly weeks I was saving. Yeah Ik it’s pretty wild.&lt;/p&gt; &lt;p&gt;So what's happening under the hood?&lt;/p&gt; &lt;p&gt;Well whenever a Linear task is created a webhook is sent to my server (Linear has their webhook Api specs online so you could easily check the data that’s sent back). In the payload, I check whether the sent request is an issue/comment, see if it’s labeled AI (linear allows custom labels) and that the current status is &amp;quot;Spec&amp;quot; or &amp;quot;Ready for dev (custom status), any other status just returns from here.&lt;/p&gt; &lt;p&gt;If the paylod is an issue and it’s in Spec, the webhook will use linear’s graphql api to comment “Writing spec” and assign itself to the task, fetches latest repo, automatically creates a new worktree, and then launches a docker container with the worktree mounted as a volume, the container has codex/claude in it(you can just use a slim alpine and install codex/claude on it) and passes on the command “work on {issue_identifier}”. &lt;/p&gt; &lt;p&gt;The LLM has linear’s mcp configured (you can check my last &lt;a href="https://www.reddit.com/r/mcp/comments/1qlhj62/a_few_of_the_mcps_i_use_on_a_daily_basis/"&gt;post&lt;/a&gt; for the MCPs I use) so it can easily fetch the issue contents, see the title and any description in the issue, refer the codebase and write a proper spec directly to linear. I do not kill the container after the spec, mainly to save costs and to reuse context for following tasks.&lt;/p&gt; &lt;p&gt;If the spec isn’t ideal, I can comment under the spec/issue with the changes I want. Webhook fires-&amp;gt; payload is parsed-&amp;gt; content of the comment is checked, it must include “@ai”, if so it’s meant for the ai, since the container is still alive the llm can re-use the context session, saves me a lot of credit, you’ll thank me for it. Now command is passed- “Amend the spec on issue {issue_identifier} according to this comment {comment_content}”. The LLM does its thing and posts the new spec.&lt;/p&gt; &lt;p&gt;Once I’m satisfied with the spec, I move the issue to “Ready for Dev”, another webhook-&amp;gt; parse the payload-&amp;gt; checks issue statuses and sees it’s ready for dev, moves it to &amp;quot;In Progress&amp;quot;, fetches that same container and passes the command- “Issue {issue_identifier} is ready for implementation, start working on it, once finished commit and push to origin with a new PR”.&lt;/p&gt; &lt;p&gt;I’ll continue on another post on how I do the git side of things and communication as well, how I converse with codex/claude about new features and then tell it- “yeah sounds good, start working on on it” and it immediately sets up the linear issue, and does everything on its own, it’s pretty sick. &lt;/p&gt; &lt;p&gt;But yeah, happy to get any more ways to improve on it, hope this helps and would love to see you guys set up your own coding Jarvis too ;).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Eyoba_19"&gt; /u/Eyoba_19 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpjn96/how_i_program_everywhere/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T18:29:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpysua</id>
    <title>"Clink": MCP Server for Provider-agnostic Collaboration</title>
    <updated>2026-01-29T04:36:14+00:00</updated>
    <author>
      <name>/u/Mannentreu</name>
      <uri>https://old.reddit.com/user/Mannentreu</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;I've been working on a distributed platform called &amp;quot;Clink&amp;quot; that allows any MCP-enabled agent to collaborate with both humans and other agents.&lt;/p&gt; &lt;p&gt;I'd like to run some pilot programs with small or mid-sized teams of AI-forward developers and non-dev contributors. Please reach out if you're interested!&lt;/p&gt; &lt;p&gt;Marketing site: &lt;a href="https://clink.voxos.ai/"&gt;https://clink.voxos.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Docs: &lt;a href="https://docs.clink.voxos.ai/"&gt;https://docs.clink.voxos.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Web dashboard: &lt;a href="https://app.clink.voxos.ai/"&gt;https://app.clink.voxos.ai&lt;/a&gt;&lt;/p&gt; &lt;p&gt;MCP npm pkg: &lt;a href="https://www.npmjs.com/package/@voxos-ai/clink-mcp-server"&gt;https://www.npmjs.com/package/@voxos-ai/clink-mcp-server&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Npm pkg source: &lt;a href="https://github.com/Voxos-ai-Inc/clink-mcp-server"&gt;https://github.com/Voxos-ai-Inc/clink-mcp-server&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Mannentreu"&gt; /u/Mannentreu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpysua/clink_mcp_server_for_provideragnostic/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpysua/clink_mcp_server_for_provideragnostic/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpysua/clink_mcp_server_for_provideragnostic/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T04:36:14+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpz8ap</id>
    <title>I built a trend prediction system using Google Trends MCP and here's what I found about AI in January 2026</title>
    <updated>2026-01-29T04:57:02+00:00</updated>
    <author>
      <name>/u/-SLOW-MO-JOHN-D</name>
      <uri>https://old.reddit.com/user/-SLOW-MO-JOHN-D</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qpz8ap/i_built_a_trend_prediction_system_using_google/"&gt; &lt;img alt="I built a trend prediction system using Google Trends MCP and here's what I found about AI in January 2026" src="https://external-preview.redd.it/CkmvrfQTiP7HYMFPNIWJPjzI5K9-8M0FuMHy8WYwBuY.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d92bd4f28d36954b7fa271c07f7739cc96af4fea" title="I built a trend prediction system using Google Trends MCP and here's what I found about AI in January 2026" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/-SLOW-MO-JOHN-D"&gt; /u/-SLOW-MO-JOHN-D &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/4sbfqlmkt7gg1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpz8ap/i_built_a_trend_prediction_system_using_google/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpz8ap/i_built_a_trend_prediction_system_using_google/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T04:57:02+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpvgiz</id>
    <title>Made a free MCP server for generating local business websites</title>
    <updated>2026-01-29T02:05:46+00:00</updated>
    <author>
      <name>/u/dwbdwb</name>
      <uri>https://old.reddit.com/user/dwbdwb</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Built an MCP that creates websites for local businesses. You give it a business name/location, it pulls data from Google, Yelp, etc. and generates a full site with SEO, schema markup, the works.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Endpoint:&lt;/strong&gt; &lt;a href="https://webzum.com/api/mcp"&gt;&lt;code&gt;https://webzum.com/api/mcp&lt;/code&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Tools:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;search_businesses&lt;/code&gt; — find businesses by name/phone/location&lt;/li&gt; &lt;li&gt;&lt;code&gt;create_site&lt;/code&gt; — generate site from business data&lt;/li&gt; &lt;li&gt;&lt;code&gt;get_site_status&lt;/code&gt; — poll build progress&lt;/li&gt; &lt;li&gt;&lt;code&gt;generate_geo_page&lt;/code&gt; — make landing pages for specific cities/services&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;No API key needed. Streamable HTTP transport.&lt;/p&gt; &lt;p&gt;Useful if you're building agents for agencies, lead gen, or local SEO stuff.&lt;/p&gt; &lt;p&gt;More info: &lt;a href="https://webzum.com"&gt;https://webzum.com&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/dwbdwb"&gt; /u/dwbdwb &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvgiz/made_a_free_mcp_server_for_generating_local/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpvgiz/made_a_free_mcp_server_for_generating_local/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpvgiz/made_a_free_mcp_server_for_generating_local/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T02:05:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1qpn0d5</id>
    <title>LAD-A2A: How AI agents find each other on local networks</title>
    <updated>2026-01-28T20:29:18+00:00</updated>
    <author>
      <name>/u/franzvill</name>
      <uri>https://old.reddit.com/user/franzvill</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;AI agents are getting really good at doing things, but they're completely blind to their physical surroundings.&lt;/p&gt; &lt;p&gt;If you walk into a hotel and you have an AI assistant (like the Chatgpt mobile app), it has no idea there may be a concierge agent on the network that could help you book a spa, check breakfast times, or request late checkout. Same thing at offices, hospitals, cruise ships. The agents are there, but there's no way to discover them.&lt;/p&gt; &lt;p&gt;A2A (Google's agent-to-agent protocol) handles how agents talk to each other. MCP handles how agents use tools. But neither answers a basic question: how do you find agents in the first place?&lt;/p&gt; &lt;p&gt;So I built LAD-A2A, a simple discovery protocol. When you connect to a Wi-Fi, your agent can automatically find what's available using mDNS (like how AirDrop finds nearby devices) or a standard HTTP endpoint.&lt;/p&gt; &lt;p&gt;The spec is intentionally minimal. I didn't want to reinvent A2A or create another complex standard. LAD-A2A just handles discovery, then hands off to A2A for actual communication.&lt;/p&gt; &lt;p&gt;Open source, Apache 2.0. Includes a working Python implementation you can run to see it in action. Repo can be found at franzvill/lad.&lt;/p&gt; &lt;p&gt;Curious what people think!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/franzvill"&gt; /u/franzvill &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qpn0d5/lada2a_how_ai_agents_find_each_other_on_local/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-28T20:29:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1qq0rab</id>
    <title>Figma MCP is read-only, so I built a write-enabled MCP using code execution</title>
    <updated>2026-01-29T06:14:54+00:00</updated>
    <author>
      <name>/u/marv1nnnnn</name>
      <uri>https://old.reddit.com/user/marv1nnnnn</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1qq0rab/figma_mcp_is_readonly_so_i_built_a_writeenabled/"&gt; &lt;img alt="Figma MCP is read-only, so I built a write-enabled MCP using code execution" src="https://external-preview.redd.it/2G9izi-zBseQvm-cfUBoPWn0lswzbxtzmSHDnyb5Jq4.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e35be390d9bc62f7934773215a0d241dc5de82a6" title="Figma MCP is read-only, so I built a write-enabled MCP using code execution" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/marv1nnnnn"&gt; /u/marv1nnnnn &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/youware-labs/figma-pilot"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1qq0rab/figma_mcp_is_readonly_so_i_built_a_writeenabled/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1qq0rab/figma_mcp_is_readonly_so_i_built_a_writeenabled/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2026-01-29T06:14:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7pl2v</id>
    <title>Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers</title>
    <updated>2024-12-06T01:23:42+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt; &lt;img alt="Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers" src="https://external-preview.redd.it/_brkexfHYjxC2eADV5MfgvEttUuxvpShYZ2vAIxM6cI.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ecb04d6570882855a6cd592912cb4a1ca169c5f8" title="Awesome MCP Servers – A curated list of awesome Model Context Protocol (MCP) servers" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/punkpeye/awesome-mcp-servers/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7pl2v/awesome_mcp_servers_a_curated_list_of_awesome/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T01:23:42+00:00</published>
  </entry>
  <entry>
    <id>t3_1h7qe88</id>
    <title>Join the Model Context Protocol Discord Server!</title>
    <updated>2024-12-06T02:04:10+00:00</updated>
    <author>
      <name>/u/punkpeye</name>
      <uri>https://old.reddit.com/user/punkpeye</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/punkpeye"&gt; /u/punkpeye &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://glama.ai/mcp/discord"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/mcp/comments/1h7qe88/join_the_model_context_protocol_discord_server/"/>
    <category term="mcp" label="r/mcp"/>
    <published>2024-12-06T02:04:10+00:00</published>
  </entry>
</feed>
