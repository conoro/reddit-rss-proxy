<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-08-06T11:49:39+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss AI &amp; Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1midi67</id>
    <title>GPT-OSS today?</title>
    <updated>2025-08-05T16:14:54+00:00</updated>
    <author>
      <name>/u/jacek2023</name>
      <uri>https://old.reddit.com/user/jacek2023</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1midi67/gptoss_today/"&gt; &lt;img alt="GPT-OSS today?" src="https://preview.redd.it/2br9oi8178hf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=20cd517e2220fa7745b9e909a9f4bfcf589d5f03" title="GPT-OSS today?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;because this is almost merged &lt;a href="https://github.com/ggml-org/llama.cpp/pull/15091"&gt;https://github.com/ggml-org/llama.cpp/pull/15091&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jacek2023"&gt; /u/jacek2023 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/2br9oi8178hf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1midi67/gptoss_today/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1midi67/gptoss_today/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T16:14:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1mizhf1</id>
    <title>I mean honestly...what did you expect?</title>
    <updated>2025-08-06T08:53:44+00:00</updated>
    <author>
      <name>/u/agentcubed</name>
      <uri>https://old.reddit.com/user/agentcubed</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Did people forget it's OpenAI or what they're stance is? They even made a whole press tour saying they'll lobotomize it for safety. Their open source models are gonna be the most censored thing ever, not sure why you expect it to generate nsfw or even an ounce of lying.&lt;/p&gt; &lt;p&gt;People be jumping on the most expected things. Just wait until the abliterated model is out. Or not, it's not made for writing anyway.&lt;/p&gt; &lt;p&gt;I do agree that they didn't spend so much time building safety. Imagine how fast they can be throwing out smarter models, yet half the time is spent on making sure the AI doesn't write fanfics.&lt;/p&gt; &lt;p&gt;Edit: Someone pointed out a good point - It's clearly made for businesses. They have a safe baby that is sure to obey all laws and not get them sued. It's not gonna write smut anytime soon.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/agentcubed"&gt; /u/agentcubed &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mizhf1/i_mean_honestlywhat_did_you_expect/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mizhf1/i_mean_honestlywhat_did_you_expect/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mizhf1/i_mean_honestlywhat_did_you_expect/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T08:53:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1milkqp</id>
    <title>Run gpt-oss locally with Unsloth GGUFs + Fixes!</title>
    <updated>2025-08-05T21:13:26+00:00</updated>
    <author>
      <name>/u/danielhanchen</name>
      <uri>https://old.reddit.com/user/danielhanchen</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/"&gt; &lt;img alt="Run gpt-oss locally with Unsloth GGUFs + Fixes!" src="https://preview.redd.it/6s62jsx2o9hf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d4a03b38836e71df4373dc670859d4fca8398ff1" title="Run gpt-oss locally with Unsloth GGUFs + Fixes!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hey guys! You can now run OpenAI's gpt-oss-120b &amp;amp; 20b open models locally with our &lt;a href="https://github.com/unslothai/unsloth"&gt;Unsloth&lt;/a&gt; GGUFs! ü¶•&lt;/p&gt; &lt;p&gt;The uploads includes some of our chat template fixes including casing errors and other fixes. We also reuploaded the quants to facilitate OpenAI's recent change to their chat template and our new fixes.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;20b GGUF: &lt;a href="https://huggingface.co/unsloth/gpt-oss-20b-GGUF"&gt;https://huggingface.co/unsloth/gpt-oss-20b-GGUF&lt;/a&gt;&lt;/li&gt; &lt;li&gt;120b GGUF: &lt;a href="https://huggingface.co/unsloth/gpt-oss-120b-GGUF"&gt;https://huggingface.co/unsloth/gpt-oss-120b-GGUF&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can run both of the models in original precision with the GGUFs. The 120b model fits on 66GB RAM/unified mem &amp;amp; 20b model on 14GB RAM/unified mem. Both will run at &amp;gt;6 token/s. The original model were in f4 but we renamed it to bf16 for easier navigation.&lt;/p&gt; &lt;p&gt;Guide to run model: &lt;a href="https://docs.unsloth.ai/basics/gpt-oss"&gt;https://docs.unsloth.ai/basics/gpt-oss&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Instructions&lt;/strong&gt;: You must build llama.cpp from source. Update llama.cpp, Ollama, LM Studio etc. to run&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \ -hf unsloth/gpt-oss-20b-GGUF:F16 \ --jinja -ngl 99 --threads -1 --ctx-size 16384 \ --temp 0.6 --top-p 1.0 --top-k 0 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or Ollama:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;ollama run hf.co/unsloth/gpt-oss-20b-GGUF &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To run the &lt;strong&gt;120B model&lt;/strong&gt; via llama.cpp:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;./llama.cpp/llama-cli \ --model unsloth/gpt-oss-120b-GGUF/gpt-oss-120b-F16.gguf \ --threads -1 \ --ctx-size 16384 \ --n-gpu-layers 99 \ -ot &amp;quot;.ffn_.*_exps.=CPU&amp;quot; \ --temp 0.6 \ --min-p 0.0 \ --top-p 1.0 \ --top-k 0.0 \ &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Thanks for the support guys and happy running. ü•∞&lt;/p&gt; &lt;p&gt;Finetuning support coming soon (likely tomorrow)!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/danielhanchen"&gt; /u/danielhanchen &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/6s62jsx2o9hf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1milkqp/run_gptoss_locally_with_unsloth_ggufs_fixes/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T21:13:26+00:00</published>
  </entry>
  <entry>
    <id>t3_1milmrl</id>
    <title>OpenAI gpt-oss-120b &amp; 20b EQ-Bench &amp; creative writing results</title>
    <updated>2025-08-05T21:15:36+00:00</updated>
    <author>
      <name>/u/_sqrkl</name>
      <uri>https://old.reddit.com/user/_sqrkl</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/"&gt; &lt;img alt="OpenAI gpt-oss-120b &amp;amp; 20b EQ-Bench &amp;amp; creative writing results" src="https://b.thumbs.redditmedia.com/ddG4iHe_QohGbzMrf1QVWE9bWoVRavxmRobwbx0Do3Y.jpg" title="OpenAI gpt-oss-120b &amp;amp; 20b EQ-Bench &amp;amp; creative writing results" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://eqbench.com/"&gt;https://eqbench.com/&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;gpt-oss-120b:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Creative writing&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Longform writing:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-120b_longform_report.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;EQ-Bench:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-120b.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;gpt-oss-20b:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Creative writing&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html"&gt;https://eqbench.com/results/creative-writing-v3/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Longform writing:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html"&gt;https://eqbench.com/results/creative-writing-longform/openai__gpt-oss-20b_longform_report.html&lt;/a&gt;&lt;/p&gt; &lt;p&gt;EQ-Bench:&lt;/p&gt; &lt;p&gt;&lt;a href="https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html"&gt;https://eqbench.com/results/eqbench3_reports/openai__gpt-oss-20b.html&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/_sqrkl"&gt; /u/_sqrkl &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1milmrl"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1milmrl/openai_gptoss120b_20b_eqbench_creative_writing/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T21:15:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1miytb3</id>
    <title>Ok, we get a lobotobot. Great.</title>
    <updated>2025-08-06T08:09:18+00:00</updated>
    <author>
      <name>/u/Reno0vacio</name>
      <uri>https://old.reddit.com/user/Reno0vacio</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miytb3/ok_we_get_a_lobotobot_great/"&gt; &lt;img alt="Ok, we get a lobotobot. Great." src="https://preview.redd.it/81b7dbwexchf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3fd0e87382bebbd8aefaa35209dcc558bee3e45d" title="Ok, we get a lobotobot. Great." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;blockquote&gt; &lt;p&gt;Red pill is often considered part of the manosphere, which is a misogynistic ideology.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Hmm. Great views on manosphere üëå&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Reno0vacio"&gt; /u/Reno0vacio &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/81b7dbwexchf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miytb3/ok_we_get_a_lobotobot_great/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miytb3/ok_we_get_a_lobotobot_great/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T08:09:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1miotjk</id>
    <title>GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?</title>
    <updated>2025-08-05T23:25:41+00:00</updated>
    <author>
      <name>/u/Different_Fix_2217</name>
      <uri>https://old.reddit.com/user/Different_Fix_2217</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/"&gt; &lt;img alt="GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?" src="https://preview.redd.it/yu8x76wnbahf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c5a7c3a67a52ed6461fbbc4ed074a559a66c3df6" title="GPT-OSS 120B Simple-Bench is not looking great either. What is going on Openai?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Another one. &lt;a href="https://simple-bench.com/"&gt;https://simple-bench.com/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different_Fix_2217"&gt; /u/Different_Fix_2217 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/yu8x76wnbahf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miotjk/gptoss_120b_simplebench_is_not_looking_great/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T23:25:41+00:00</published>
  </entry>
  <entry>
    <id>t3_1mieqcb</id>
    <title>openai/gpt-oss-120b ¬∑ Hugging Face</title>
    <updated>2025-08-05T17:00:37+00:00</updated>
    <author>
      <name>/u/ShreckAndDonkey123</name>
      <uri>https://old.reddit.com/user/ShreckAndDonkey123</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/"&gt; &lt;img alt="openai/gpt-oss-120b ¬∑ Hugging Face" src="https://external-preview.redd.it/12ojQ9khZuJRm7jqdMaOtnKaFtBC6Yo7dfwq4qKZ3jA.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4ae7c659a21f868f6dba51b958c810a90c5bfe24" title="openai/gpt-oss-120b ¬∑ Hugging Face" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ShreckAndDonkey123"&gt; /u/ShreckAndDonkey123 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/openai/gpt-oss-120b"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mieqcb/openaigptoss120b_hugging_face/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T17:00:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1miv8y4</id>
    <title>WE CAN COMPLY</title>
    <updated>2025-08-06T04:32:04+00:00</updated>
    <author>
      <name>/u/Pro-editor-1105</name>
      <uri>https://old.reddit.com/user/Pro-editor-1105</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miv8y4/we_can_comply/"&gt; &lt;img alt="WE CAN COMPLY" src="https://preview.redd.it/uud2hotmubhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=83f0ba8ed65182bcac75f14c808ee28882456760" title="WE CAN COMPLY" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Pro-editor-1105"&gt; /u/Pro-editor-1105 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/uud2hotmubhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miv8y4/we_can_comply/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miv8y4/we_can_comply/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T04:32:04+00:00</published>
  </entry>
  <entry>
    <id>t3_1mj00g7</id>
    <title>Qwen3 vs. gpt-oss architecture: width matters</title>
    <updated>2025-08-06T09:27:51+00:00</updated>
    <author>
      <name>/u/entsnack</name>
      <uri>https://old.reddit.com/user/entsnack</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj00g7/qwen3_vs_gptoss_architecture_width_matters/"&gt; &lt;img alt="Qwen3 vs. gpt-oss architecture: width matters" src="https://preview.redd.it/vqgb87dfbdhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=6c2ff32aeda0494c869aa38d27852485afc947c7" title="Qwen3 vs. gpt-oss architecture: width matters" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Sebastian Raschka is at it again! This time he compares the Qwen 3 and gpt-oss architectures. I'm looking forward to his deep dive, his Qwen 3 series was phenomenal.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/entsnack"&gt; /u/entsnack &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/vqgb87dfbdhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj00g7/qwen3_vs_gptoss_architecture_width_matters/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mj00g7/qwen3_vs_gptoss_architecture_width_matters/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T09:27:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1minnrb</id>
    <title>Lol this is some next level brain fried from censorship.</title>
    <updated>2025-08-05T22:36:54+00:00</updated>
    <author>
      <name>/u/Different_Fix_2217</name>
      <uri>https://old.reddit.com/user/Different_Fix_2217</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/"&gt; &lt;img alt="Lol this is some next level brain fried from censorship." src="https://preview.redd.it/tcnuqjo63ahf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=043f9f18d071dc3ac979b1c42c6e3c2c762f2319" title="Lol this is some next level brain fried from censorship." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different_Fix_2217"&gt; /u/Different_Fix_2217 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/tcnuqjo63ahf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1minnrb/lol_this_is_some_next_level_brain_fried_from/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T22:36:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1mj011h</id>
    <title>It's amazing how OpenAI missed its window with the gpt-oss release. The models would have been perceived much better last week.</title>
    <updated>2025-08-06T09:28:54+00:00</updated>
    <author>
      <name>/u/DistanceSolar1449</name>
      <uri>https://old.reddit.com/user/DistanceSolar1449</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;This week, after the Qwen 2507 releases, the gpt-oss-120b and gpt-oss-20b models are just seen as a more censored &amp;quot;smaller but worse Qwen3-235b-Thinking-2057&amp;quot; and &amp;quot;smaller but worse Qwen3-30b-Thinking-2057&amp;quot; respectively. &lt;/p&gt; &lt;p&gt;This is &lt;a href="https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-nemotron-super-49b-v1-5-reasoning%2Ckimi-k2%2Cexaone-4-0-32b-reasoning%2Cglm-4.5%2Cqwen3-235b-a22b-instruct-2507-reasoning%2Cqwen3-30b-a3b-2507-reasoning&amp;amp;intelligence-tab=intelligence#artificial-analysis-intelligence-index"&gt;what the general perception is mostly following&lt;/a&gt; today: &lt;a href="https://i.imgur.com/wugi9sG.png"&gt;https://i.imgur.com/wugi9sG.png&lt;/a&gt;&lt;/p&gt; &lt;p&gt;But what if OpenAI released a week earlier? &lt;/p&gt; &lt;p&gt;They would have been seen as world beaters, at least for a few days. No Qwen 2507. No GLM-4.5. No Nvidia Nemotron 49b V1.5. No EXAONE 4.0 32b. &lt;/p&gt; &lt;p&gt;The field would have &lt;a href="https://artificialanalysis.ai/?models=gpt-oss-120b%2Co3-pro%2Cgpt-4-1%2Co4-mini%2Co3%2Cgpt-oss-20b%2Cllama-4-maverick%2Cgemini-2-5-pro%2Cclaude-4-sonnet-thinking%2Cdeepseek-r1%2Cgrok-4%2Cllama-3-1-nemotron-ultra-253b-v1-reasoning%2Ckimi-k2%2Cdeepseek-r1-0120%2Cqwen3-235b-a22b-instruct-reasoning%2Cqwen3-30b-a3b-instruct-reasoning&amp;amp;intelligence-tab=openWeights#artificial-analysis-intelligence-index-by-open-weights-vs-proprietary"&gt;looked like this&lt;/a&gt; last week: &lt;a href="https://i.imgur.com/rGKG8eZ.png"&gt;https://i.imgur.com/rGKG8eZ.png&lt;/a&gt;&lt;/p&gt; &lt;p&gt;That would be a very different set of competitors. The 2 gpt-oss models would have been seen as &lt;strong&gt;the&lt;/strong&gt; best models other than Deepseek R1 0528, and the 120b better than the original Deepseek R1. &lt;/p&gt; &lt;p&gt;There would have been no open source competitors in its league. Qwen3 235b would be significantly behind. Nvidia Nemotron Ultra 253b would have been significantly behind. &lt;/p&gt; &lt;p&gt;OpenAI would have &lt;strong&gt;set a narrative of &amp;quot;even our open source models stomps on others at the same size&amp;quot;, with others trying to catch up&lt;/strong&gt; but OpenAI failed to capitalize on that due to their delays. &lt;/p&gt; &lt;p&gt;It's possible that the open source models &lt;em&gt;were even better 1-2 weeks ago&lt;/em&gt;, but OpenAI decided to posttrain some more to dumb it down and make it safer since they felt like they had a comfortable lead...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/DistanceSolar1449"&gt; /u/DistanceSolar1449 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mj011h/its_amazing_how_openai_missed_its_window_with_the/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T09:28:54+00:00</published>
  </entry>
  <entry>
    <id>t3_1mizz4c</id>
    <title>I distilled Qwen3-Coder-480B into Qwen3-Coder-30b-A3B-Instruct</title>
    <updated>2025-08-06T09:25:31+00:00</updated>
    <author>
      <name>/u/Commercial-Celery769</name>
      <uri>https://old.reddit.com/user/Commercial-Celery769</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mizz4c/i_distilled_qwen3coder480b_into/"&gt; &lt;img alt="I distilled Qwen3-Coder-480B into Qwen3-Coder-30b-A3B-Instruct" src="https://b.thumbs.redditmedia.com/otdr2FbIcEHBACfeKNFLe7Iw0h8Ps5qbWOOlVN92PRY.jpg" title="I distilled Qwen3-Coder-480B into Qwen3-Coder-30b-A3B-Instruct" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;It seems to function better than stock Qwen-3-coder-30b-Instruct for UI/UX in my testing. I distilled it using SVD and applied the extracted Lora to the model. In the simulated OS things like the windows can fullscreen but cant minimize and the terminal is not functional. Still pretty good IMO considering its a 30b. All code was 1 or 2 shot. Currently only have a Q8_0 quant up but will have more up soon. If you would like to see the distillation scripts let me know and I can post them to github. &lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-Distill"&gt;https://huggingface.co/BasedBase/Qwen3-Coder-30B-A3B-Instruct-Distill&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Commercial-Celery769"&gt; /u/Commercial-Celery769 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.reddit.com/gallery/1mizz4c"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mizz4c/i_distilled_qwen3coder480b_into/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mizz4c/i_distilled_qwen3coder480b_into/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T09:25:31+00:00</published>
  </entry>
  <entry>
    <id>t3_1migl0k</id>
    <title>gpt-oss-120b is safetymaxxed (cw: explicit safety)</title>
    <updated>2025-08-05T18:07:05+00:00</updated>
    <author>
      <name>/u/TheLocalDrummer</name>
      <uri>https://old.reddit.com/user/TheLocalDrummer</uri>
    </author>
    <content type="html">&amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheLocalDrummer"&gt; /u/TheLocalDrummer &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/o893aealq8hf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1migl0k/gptoss120b_is_safetymaxxed_cw_explicit_safety/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1migl0k/gptoss120b_is_safetymaxxed_cw_explicit_safety/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T18:07:05+00:00</published>
  </entry>
  <entry>
    <id>t3_1miupht</id>
    <title>GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2</title>
    <updated>2025-08-06T04:02:50+00:00</updated>
    <author>
      <name>/u/mvp525</name>
      <uri>https://old.reddit.com/user/mvp525</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/"&gt; &lt;img alt="GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2" src="https://preview.redd.it/cbd2wyrfpbhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=994e72edd24558bb078da5397d66ecabc0d9a45a" title="GPT -OSS is heavily trained on benchmark. scored rank 34 on simplebench worse than grok 2" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mvp525"&gt; /u/mvp525 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/cbd2wyrfpbhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miupht/gpt_oss_is_heavily_trained_on_benchmark_scored/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T04:02:50+00:00</published>
  </entry>
  <entry>
    <id>t3_1migo6d</id>
    <title>I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!</title>
    <updated>2025-08-05T18:10:18+00:00</updated>
    <author>
      <name>/u/Different_Fix_2217</name>
      <uri>https://old.reddit.com/user/Different_Fix_2217</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/"&gt; &lt;img alt="I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!" src="https://preview.redd.it/7e3v67opr8hf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c78bd2d594d80d839e43d136cedfee6e05b2b464" title="I FEEL SO SAFE! THANK YOU SO MUCH OPENAI!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;It also lacks all general knowledge and is terrible at coding compared to the same sized GLM air, what is the use case here?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Different_Fix_2217"&gt; /u/Different_Fix_2217 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/7e3v67opr8hf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1migo6d/i_feel_so_safe_thank_you_so_much_openai/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T18:10:18+00:00</published>
  </entry>
  <entry>
    <id>t3_1miodyp</id>
    <title>GPT-OSS 120B and 20B feel kind of‚Ä¶ bad?</title>
    <updated>2025-08-05T23:07:10+00:00</updated>
    <author>
      <name>/u/SlackEight</name>
      <uri>https://old.reddit.com/user/SlackEight</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;After feeling horribly underwhelmed by these models, the more I look around, the more I‚Äôm noticing reports of excessive censorship, high hallucination rates, and lacklustre performance. &lt;/p&gt; &lt;p&gt;Our company builds character AI systems. After plugging both of these models into our workflows and running our eval sets against them, we are getting some of the worst performance we‚Äôve ever seen in the models we‚Äôve tested (120B performing marginally better than Qwen 3 32B, and both models getting demolished by Llama 4 Maverick, K2, DeepSeek V3, and even GPT 4.1 mini)&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/SlackEight"&gt; /u/SlackEight &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miodyp/gptoss_120b_and_20b_feel_kind_of_bad/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T23:07:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1mj00mr</id>
    <title>How did you enjoy the experience so far?</title>
    <updated>2025-08-06T09:28:11+00:00</updated>
    <author>
      <name>/u/Paradigmind</name>
      <uri>https://old.reddit.com/user/Paradigmind</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj00mr/how_did_you_enjoy_the_experience_so_far/"&gt; &lt;img alt="How did you enjoy the experience so far?" src="https://preview.redd.it/lj67oslhbdhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=3c80a51205f8e1a50045f6a608b9a5b683365337" title="How did you enjoy the experience so far?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;So aside from dishing out neural lobotomies in the name of safety, what else can this model actually provide? I heard someone is brave enough to try fixing it. But unless you‚Äôre in it for the masochistic fun, is it even worth it?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Paradigmind"&gt; /u/Paradigmind &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/lj67oslhbdhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj00mr/how_did_you_enjoy_the_experience_so_far/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mj00mr/how_did_you_enjoy_the_experience_so_far/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T09:28:11+00:00</published>
  </entry>
  <entry>
    <id>t3_1mivbuo</id>
    <title>in other words benchmaxxed</title>
    <updated>2025-08-06T04:36:37+00:00</updated>
    <author>
      <name>/u/mvp525</name>
      <uri>https://old.reddit.com/user/mvp525</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/"&gt; &lt;img alt="in other words benchmaxxed" src="https://preview.redd.it/i2vavxugvbhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d0659e158cc4f10d87cf14b124dccd590bed50dc" title="in other words benchmaxxed" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/mvp525"&gt; /u/mvp525 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/i2vavxugvbhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mivbuo/in_other_words_benchmaxxed/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T04:36:37+00:00</published>
  </entry>
  <entry>
    <id>t3_1mix2kg</id>
    <title>Safemaxxed for your safety!</title>
    <updated>2025-08-06T06:17:32+00:00</updated>
    <author>
      <name>/u/Caffdy</name>
      <uri>https://old.reddit.com/user/Caffdy</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/"&gt; &lt;img alt="Safemaxxed for your safety!" src="https://preview.redd.it/gaqdycledchf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=e5a2b32eb53633ee05256ff12a01a15e7ee6f844" title="Safemaxxed for your safety!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Caffdy"&gt; /u/Caffdy &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/gaqdycledchf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mix2kg/safemaxxed_for_your_safety/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T06:17:32+00:00</published>
  </entry>
  <entry>
    <id>t3_1miezct</id>
    <title>üöÄ OpenAI released their open-weight models!!!</title>
    <updated>2025-08-05T17:09:35+00:00</updated>
    <author>
      <name>/u/ResearchCrafty1804</name>
      <uri>https://old.reddit.com/user/ResearchCrafty1804</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/"&gt; &lt;img alt="üöÄ OpenAI released their open-weight models!!!" src="https://preview.redd.it/1yckal6wg8hf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=dc6b586f5d511d8c0e30969100e707e6e00a1815" title="üöÄ OpenAI released their open-weight models!!!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Welcome to the gpt-oss series, OpenAI‚Äôs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.&lt;/p&gt; &lt;p&gt;We‚Äôre releasing two flavors of the open models:&lt;/p&gt; &lt;p&gt;gpt-oss-120b ‚Äî for production, general purpose, high reasoning use cases that fits into a single H100 GPU (117B parameters with 5.1B active parameters)&lt;/p&gt; &lt;p&gt;gpt-oss-20b ‚Äî for lower latency, and local or specialized use cases (21B parameters with 3.6B active parameters)&lt;/p&gt; &lt;p&gt;Hugging Face: &lt;a href="https://huggingface.co/openai/gpt-oss-120b"&gt;https://huggingface.co/openai/gpt-oss-120b&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ResearchCrafty1804"&gt; /u/ResearchCrafty1804 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/1yckal6wg8hf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miezct/openai_released_their_openweight_models/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T17:09:35+00:00</published>
  </entry>
  <entry>
    <id>t3_1minpqr</id>
    <title>Finally, a model that's SAFE</title>
    <updated>2025-08-05T22:39:10+00:00</updated>
    <author>
      <name>/u/RandumbRedditor1000</name>
      <uri>https://old.reddit.com/user/RandumbRedditor1000</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"&gt; &lt;img alt="Finally, a model that's SAFE" src="https://a.thumbs.redditmedia.com/vPXQi6mxUBYl7zt9fZCD3LWOB6PaZGcjaDHZr2r1u18.jpg" title="Finally, a model that's SAFE" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81"&gt;https://preview.redd.it/elpfx70g3ahf1.png?width=996&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=09af507acfa40063fa0bed3df990bca01d097c81&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thanks openai, you're really contributing to the open-source LLM community&lt;/p&gt; &lt;p&gt;I haven't been this blown away by a model since Llama 4!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/RandumbRedditor1000"&gt; /u/RandumbRedditor1000 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1minpqr/finally_a_model_thats_safe/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-05T22:39:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1mj0snp</id>
    <title>Elon Musk says that xAI will make Grok 2 open source next week</title>
    <updated>2025-08-06T10:16:28+00:00</updated>
    <author>
      <name>/u/Nunki08</name>
      <uri>https://old.reddit.com/user/Nunki08</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj0snp/elon_musk_says_that_xai_will_make_grok_2_open/"&gt; &lt;img alt="Elon Musk says that xAI will make Grok 2 open source next week" src="https://preview.redd.it/htgw3mmvjdhf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=90be5e283724a3ec93ab02ddff87962c7ebd7661" title="Elon Musk says that xAI will make Grok 2 open source next week" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Elon Musk on ùïè: &lt;a href="https://x.com/elonmusk/status/1952988026617119075"&gt;https://x.com/elonmusk/status/1952988026617119075&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Nunki08"&gt; /u/Nunki08 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/htgw3mmvjdhf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1mj0snp/elon_musk_says_that_xai_will_make_grok_2_open/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1mj0snp/elon_musk_says_that_xai_will_make_grok_2_open/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T10:16:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1miyix4</id>
    <title>I'm sorry, but I can't provide that... patience - I already have none...</title>
    <updated>2025-08-06T07:49:59+00:00</updated>
    <author>
      <name>/u/Cool-Chemical-5629</name>
      <uri>https://old.reddit.com/user/Cool-Chemical-5629</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/"&gt; &lt;img alt="I'm sorry, but I can't provide that... patience - I already have none..." src="https://preview.redd.it/aufyauketchf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=88ae39d0f21635e24eb2be18f44662947077760e" title="I'm sorry, but I can't provide that... patience - I already have none..." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;That's it. I'm done with this useless piece of trash of a model...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cool-Chemical-5629"&gt; /u/Cool-Chemical-5629 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/aufyauketchf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miyix4/im_sorry_but_i_cant_provide_that_patience_i/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T07:49:59+00:00</published>
  </entry>
  <entry>
    <id>t3_1miwrli</id>
    <title>"What, you don't like your new SOTA model?"</title>
    <updated>2025-08-06T05:59:16+00:00</updated>
    <author>
      <name>/u/Friendly_Willingness</name>
      <uri>https://old.reddit.com/user/Friendly_Willingness</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/"&gt; &lt;img alt="&amp;quot;What, you don't like your new SOTA model?&amp;quot;" src="https://preview.redd.it/9yqb0l1n9chf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=726e03405370b5eb421009dfc38b1005ddf67ee0" title="&amp;quot;What, you don't like your new SOTA model?&amp;quot;" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Friendly_Willingness"&gt; /u/Friendly_Willingness &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/9yqb0l1n9chf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1miwrli/what_you_dont_like_your_new_sota_model/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T05:59:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1misyvc</id>
    <title>OpenAI, I don't feel SAFE ENOUGH</title>
    <updated>2025-08-06T02:35:22+00:00</updated>
    <author>
      <name>/u/Final_Wheel_7486</name>
      <uri>https://old.reddit.com/user/Final_Wheel_7486</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/"&gt; &lt;img alt="OpenAI, I don't feel SAFE ENOUGH" src="https://preview.redd.it/af6jm3nt9bhf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fb88d869e88cfd2f93a6e76c7ac3ddf342a2db09" title="OpenAI, I don't feel SAFE ENOUGH" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Good timing btw&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Final_Wheel_7486"&gt; /u/Final_Wheel_7486 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/af6jm3nt9bhf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1misyvc/openai_i_dont_feel_safe_enough/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-08-06T02:35:22+00:00</published>
  </entry>
</feed>
