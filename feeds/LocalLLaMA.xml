<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>/r/LocalLLaMA/.rss</id>
  <title>LocalLlama</title>
  <updated>2025-09-06T00:26:08+00:00</updated>
  <link href="https://old.reddit.com/r/LocalLLaMA/" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="1.0.0">python-feedgen</generator>
  <icon>https://www.redditstatic.com/icon.png/</icon>
  <subtitle>Subreddit to discuss AI &amp; Llama, the large language model created by Meta AI.</subtitle>
  <entry>
    <id>t3_1n91kiu</id>
    <title>Testing World Knowledge; and What Reasoning Does To It (regarding airliners, specifically)</title>
    <updated>2025-09-05T10:28:23+00:00</updated>
    <author>
      <name>/u/airbus_a360_when</name>
      <uri>https://old.reddit.com/user/airbus_a360_when</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n91kiu/testing_world_knowledge_and_what_reasoning_does/"&gt; &lt;img alt="Testing World Knowledge; and What Reasoning Does To It (regarding airliners, specifically)" src="https://preview.redd.it/6h652ykfpbnf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f741dacac81b4d1cd00ec2cbc6dfe4b990652691" title="Testing World Knowledge; and What Reasoning Does To It (regarding airliners, specifically)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;More info in top comment.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/airbus_a360_when"&gt; /u/airbus_a360_when &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/6h652ykfpbnf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n91kiu/testing_world_knowledge_and_what_reasoning_does/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n91kiu/testing_world_knowledge_and_what_reasoning_does/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T10:28:23+00:00</published>
  </entry>
  <entry>
    <id>t3_1n94n2x</id>
    <title>Succeeded to build full-level backend application with "qwen3-235b-a22b" in AutoBE</title>
    <updated>2025-09-05T13:00:38+00:00</updated>
    <author>
      <name>/u/jhnam88</name>
      <uri>https://old.reddit.com/user/jhnam88</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n94n2x/succeeded_to_build_fulllevel_backend_application/"&gt; &lt;img alt="Succeeded to build full-level backend application with &amp;quot;qwen3-235b-a22b&amp;quot; in AutoBE" src="https://preview.redd.it/bya05sjkgcnf1.png?width=320&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=cec55a8295cb6e75a23643f4026e5d53356c9c75" title="Succeeded to build full-level backend application with &amp;quot;qwen3-235b-a22b&amp;quot; in AutoBE" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/wrtnlabs/autobe-example-todo-qwen3-235b-a22b"&gt;https://github.com/wrtnlabs/autobe-example-todo-qwen3-235b-a22b&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Although what I've built with &lt;code&gt;qwen3-235b-a22b&lt;/code&gt; (2507) is just a simple backend application composed of 10 API functions and 37 DTO schemas, this marks the first time I've successfully generated a full-level backend application without any compilation errors.&lt;/p&gt; &lt;p&gt;I'm continuously testing larger backend applications while enhancing AutoBE (an open-source project for building full-level backend applications using AI-friendly compilers) system prompts and its AI-friendly compilers. I believe it may be possible to generate more complex backend applications like a Reddit-style community (with around 200 API functions) by next month.&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;I also tried the &lt;code&gt;qwen3-30b-a3b&lt;/code&gt; model, but it struggles with defining DTO types. However, one amazing thing is that its requirement analysis report and database design were quite professional. Since it's a smaller model, I won't invest much effort in it, but I was surprised by the quality of its requirements definition and DB design.&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;Currently, AutoBE requires about 150 million tokens using &lt;code&gt;gpt-4.1&lt;/code&gt; to create an Amazon like shopping mall-level backend application, which is very expensive (approximately $450). In addition to RAG tuning, using local LLM models like &lt;code&gt;qwen3-235b-a22b&lt;/code&gt; could be a viable alternative.&lt;/p&gt; &lt;p&gt;The results from &lt;code&gt;qwen3-235b-a22b&lt;/code&gt; were so interesting and promising that our AutoBE hackathon, originally planned to support only &lt;code&gt;gpt-4.1&lt;/code&gt; and &lt;code&gt;gpt-4.1-mini&lt;/code&gt;, urgently added the &lt;code&gt;qwen3-235b-a22b&lt;/code&gt; model to the contest. If you're interested in building full-level backend applications with AI and local LLMs like qwen3, we'd love to have you join our hackathon and share this exciting experience.&lt;/p&gt; &lt;p&gt;We will test as many local LLMs as possible with AutoBE and report our findings to this channel whenever we discover promising results. Furthermore, whenever we find a model that excels at backend coding, we will regularly host hackathons to share experiences and collect diverse case studies.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Hackathon Contest: &lt;a href="https://autobe.dev/docs/hackathon/"&gt;https://autobe.dev/docs/hackathon/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Github Repository: &lt;a href="https://github.com/wrtnlabs/autobe"&gt;https://github.com/wrtnlabs/autobe&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/jhnam88"&gt; /u/jhnam88 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/bya05sjkgcnf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n94n2x/succeeded_to_build_fulllevel_backend_application/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n94n2x/succeeded_to_build_fulllevel_backend_application/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T13:00:38+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9i0b8</id>
    <title>When LLMs Grow Hands and Feet, How to Design our Agentic RL Systems?</title>
    <updated>2025-09-05T21:45:16+00:00</updated>
    <author>
      <name>/u/Pleasant-Type2044</name>
      <uri>https://old.reddit.com/user/Pleasant-Type2044</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9i0b8/when_llms_grow_hands_and_feet_how_to_design_our/"&gt; &lt;img alt="When LLMs Grow Hands and Feet, How to Design our Agentic RL Systems?" src="https://b.thumbs.redditmedia.com/5pHY270DYUAVPyhXb9uE7hwmWHldZZ80A_4d6nBl2CA.jpg" title="When LLMs Grow Hands and Feet, How to Design our Agentic RL Systems?" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Lately I’ve been building AI agents for scientific research. In addition to build better agent scaffold, to make AI agents truly useful, LLMs need to do more than just think—they need to &lt;strong&gt;use tools, run code, and interact with complex environments&lt;/strong&gt;. That’s why we need &lt;strong&gt;Agentic RL&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;While working on this, I notice the underlying RL systems must evolve to support these new capabilities. So, I wrote a blog post to capture my thoughts and lessons learned.&lt;/p&gt; &lt;p&gt; &lt;strong&gt;“When LLMs Grow Hands and Feet, How to Design our Agentic RL Systems?”&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/abgto1kb2fnf1.png?width=1656&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cac5e0e3e7f51e94c0f6534bbb3741372bb6b82a"&gt;https://preview.redd.it/abgto1kb2fnf1.png?width=1656&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=cac5e0e3e7f51e94c0f6534bbb3741372bb6b82a&lt;/a&gt;&lt;/p&gt; &lt;p&gt;TL;DR:&lt;br /&gt; The frontier of AI is moving from simple-response generation to solving complex, multi-step problems through agents. Previous RL frameworks for LLMs aren’t built for this—they struggle with the heavy, heterogeneous resource demands that agents need, like isolated environments or tool interactions.&lt;/p&gt; &lt;p&gt;In the blog, I cover:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;How RL for LLM-based agents differs from traditional RL for LLM.&lt;/li&gt; &lt;li&gt;The critical system challenges when scaling agentic RL.&lt;/li&gt; &lt;li&gt;Emerging solutions top labs and companies are using &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you’re interested in agentic intelligence—LLMs that don’t just think but act—I go into the nuts and bolts of what it takes to make this work in practice.&lt;/p&gt; &lt;p&gt;&lt;a href="https://amberljc.github.io/blog/2025-09-05-agentic-rl-systems.html"&gt;https://amberljc.github.io/blog/2025-09-05-agentic-rl-systems.html&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Pleasant-Type2044"&gt; /u/Pleasant-Type2044 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9i0b8/when_llms_grow_hands_and_feet_how_to_design_our/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9i0b8/when_llms_grow_hands_and_feet_how_to_design_our/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9i0b8/when_llms_grow_hands_and_feet_how_to_design_our/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T21:45:16+00:00</published>
  </entry>
  <entry>
    <id>t3_1n8zn89</id>
    <title>VibeVoice RIP? Not with this Community!!!</title>
    <updated>2025-09-05T08:27:25+00:00</updated>
    <author>
      <name>/u/Cipher_Lock_20</name>
      <uri>https://old.reddit.com/user/Cipher_Lock_20</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8zn89/vibevoice_rip_not_with_this_community/"&gt; &lt;img alt="VibeVoice RIP? Not with this Community!!!" src="https://preview.redd.it/vnwua2k0zanf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=560d3e188bc6c42ff9082af9f34312ed7bbf964e" title="VibeVoice RIP? Not with this Community!!!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;strong&gt;VibeVoice Large is back!&lt;/strong&gt; No thanks to Microsoft though, still silence on their end.&lt;/p&gt; &lt;p&gt;This is in response to &lt;a href="/u/Fabix84"&gt;u/Fabix84&lt;/a&gt; post &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1n7zk45/vibevoice_rip_what_do_you_think/?utm_source=share&amp;amp;utm_medium=web3x&amp;amp;utm_name=web3xcss&amp;amp;utm_term=1&amp;amp;utm_content=share_button"&gt;here&lt;/a&gt;, who has done great work on providing VibeVoice support for ComfyUI.&lt;/p&gt; &lt;p&gt;In an odd series of events, Microsoft pulled the repo and any trace of the Large VibeVoice models on all platforms. No comments, nothing. The 1.5B is now part of the official HF Transformer library, but Large (7B) is only available through various mirrors provided by the community.&lt;/p&gt; &lt;p&gt;Oddly enough, I only see a marginal difference between the two with the 1.5B being incredibly good for single and multi-speaker models. I have my space back up and going here if interested. I'll run it on an L4 until I can move it over to Modal for inference. The 120 time limit for ZeroGPU makes a bit unusable on voices over 1-2 minutes. Generations do take a lot of time too, so you have to be patient.&lt;/p&gt; &lt;p&gt;Microsoft specifically states in the model card that they did not clean the training audio which is why you get music artifacts. This can be pretty cool, but I found it's so unpredictable that it can cause artifacts or noise to persist throughout the entire generation. I've found your better off just adding a sound effect after generation so that you can control it. This model is really meant for long form multi-speaker conversation which I think it does well at. I did test some other various voices with mixed results.&lt;/p&gt; &lt;p&gt;For the difference in quality I would personally just use the 1.5B. I use my space to generate &amp;quot;conferences&amp;quot; to test other STT models with transcription and captions. I am excited for the pending streaming model they have noted... though I won't keep hopes up too much.&lt;/p&gt; &lt;p&gt;For those interested in it or just need to reference the larger model here is my space, though there are many good ones still running.&lt;/p&gt; &lt;p&gt;&lt;a href="https://huggingface.co/spaces/ACloudCenter/Conference-Generator-VibeVoice"&gt;Conference Generator VibeVoice&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Cipher_Lock_20"&gt; /u/Cipher_Lock_20 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/vnwua2k0zanf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8zn89/vibevoice_rip_not_with_this_community/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n8zn89/vibevoice_rip_not_with_this_community/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T08:27:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9bck7</id>
    <title>Qwen 3 Max has no "thinking".</title>
    <updated>2025-09-05T17:23:21+00:00</updated>
    <author>
      <name>/u/Impressive_Half_2819</name>
      <uri>https://old.reddit.com/user/Impressive_Half_2819</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9bck7/qwen_3_max_has_no_thinking/"&gt; &lt;img alt="Qwen 3 Max has no &amp;quot;thinking&amp;quot;." src="https://preview.redd.it/50ybf3tlrdnf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9fadb19efc74d4c70ba689032d3c750efb640c4b" title="Qwen 3 Max has no &amp;quot;thinking&amp;quot;." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Qwen 3 max with no thinking.I wonder why?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Impressive_Half_2819"&gt; /u/Impressive_Half_2819 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/50ybf3tlrdnf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9bck7/qwen_3_max_has_no_thinking/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9bck7/qwen_3_max_has_no_thinking/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T17:23:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9d0k1</id>
    <title>I made local RAG, web search, and voice mode on iPhones completely open source, private, and free</title>
    <updated>2025-09-05T18:26:58+00:00</updated>
    <author>
      <name>/u/sskarz1016</name>
      <uri>https://old.reddit.com/user/sskarz1016</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9d0k1/i_made_local_rag_web_search_and_voice_mode_on/"&gt; &lt;img alt="I made local RAG, web search, and voice mode on iPhones completely open source, private, and free" src="https://external-preview.redd.it/MXVtZzNkdHcyZW5mMamXxO8Za-P_K6fyYmFJDRdRJp-EiUrWGPjDIQS2IH86.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=73db9e4b9f65aa1b59821bca9649878a5a8e0045" title="I made local RAG, web search, and voice mode on iPhones completely open source, private, and free" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Long time lurker here, I made an iOS app that uses on-device Apple Intelligence and enhances it with local RAG, web search, and voice mode, all on-device processed. There are 0 API connections, it's all free, private, and local.&lt;/p&gt; &lt;p&gt;This is in part with my CS Master's Thesis as I find ways to optimize on-device AI experiences on mobile hardware, so if you could try it and give me feedback I'd greatly appreciate it! I have no plans to monetize this application, use as freely as you like :)&lt;/p&gt; &lt;p&gt;Requirements: Apple Intelligence eligible device (iPhone, iPad, or Mac), and iOS 26 Public/Developer beta.&lt;/p&gt; &lt;p&gt;TestFlight: &lt;a href="https://testflight.apple.com/join/6gaB7S1R"&gt;https://testflight.apple.com/join/6gaB7S1R&lt;/a&gt;&lt;br /&gt; GitHub: &lt;a href="https://github.com/sskarz/Aeru"&gt;https://github.com/sskarz/Aeru&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Thank you!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/sskarz1016"&gt; /u/sskarz1016 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/kz5pwdtw2enf1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9d0k1/i_made_local_rag_web_search_and_voice_mode_on/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9d0k1/i_made_local_rag_web_search_and_voice_mode_on/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T18:26:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1n8wyla</id>
    <title>I've made some fun demos using the new kimi-k2-0905</title>
    <updated>2025-09-05T05:35:25+00:00</updated>
    <author>
      <name>/u/Dr_Karminski</name>
      <uri>https://old.reddit.com/user/Dr_Karminski</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8wyla/ive_made_some_fun_demos_using_the_new_kimik20905/"&gt; &lt;img alt="I've made some fun demos using the new kimi-k2-0905" src="https://external-preview.redd.it/aGZ4NjJ2a3o3YW5mMQ6wDUEz-v_Nzg5h_KpwfXxI3dQiiTxqUDt15pQk26OB.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=53a1c44fdc22349784a666c01c3f87736334da77" title="I've made some fun demos using the new kimi-k2-0905" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;They were all created with a single-pass, AI-generated prompt using both claude-code and kimi-k2-0905.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Dr_Karminski"&gt; /u/Dr_Karminski &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/wavkswkz7anf1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8wyla/ive_made_some_fun_demos_using_the_new_kimik20905/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n8wyla/ive_made_some_fun_demos_using_the_new_kimik20905/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T05:35:25+00:00</published>
  </entry>
  <entry>
    <id>t3_1n910t9</id>
    <title>Where is theBloke?</title>
    <updated>2025-09-05T09:55:49+00:00</updated>
    <author>
      <name>/u/holistic-engine</name>
      <uri>https://old.reddit.com/user/holistic-engine</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Haven’t seen any posts related to this legend in a while? Where is he, is he okay? &lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/holistic-engine"&gt; /u/holistic-engine &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n910t9/where_is_thebloke/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n910t9/where_is_thebloke/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n910t9/where_is_thebloke/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T09:55:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9ba1m</id>
    <title>Qwen3 30B A3B Q40 on 4 x Raspberry Pi 5 8GB 13.04 tok/s (Distributed Llama)</title>
    <updated>2025-09-05T17:20:43+00:00</updated>
    <author>
      <name>/u/thisislewekonto</name>
      <uri>https://old.reddit.com/user/thisislewekonto</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9ba1m/qwen3_30b_a3b_q40_on_4_x_raspberry_pi_5_8gb_1304/"&gt; &lt;img alt="Qwen3 30B A3B Q40 on 4 x Raspberry Pi 5 8GB 13.04 tok/s (Distributed Llama)" src="https://external-preview.redd.it/KUWKhlT5OZYpzmuPdkrY6FyowQ4PaYe23RiUvraDVrQ.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4733d277f6f6e759fe47794087d1da790f8d36b7" title="Qwen3 30B A3B Q40 on 4 x Raspberry Pi 5 8GB 13.04 tok/s (Distributed Llama)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/thisislewekonto"&gt; /u/thisislewekonto &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://github.com/b4rtaz/distributed-llama/discussions/255"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9ba1m/qwen3_30b_a3b_q40_on_4_x_raspberry_pi_5_8gb_1304/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9ba1m/qwen3_30b_a3b_q40_on_4_x_raspberry_pi_5_8gb_1304/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T17:20:43+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9b7mn</id>
    <title>Tenstorrent p150a tested against RTX5090, RTX3090, A100, H100 by Russian blogger</title>
    <updated>2025-09-05T17:18:10+00:00</updated>
    <author>
      <name>/u/No-Refrigerator-1672</name>
      <uri>https://old.reddit.com/user/No-Refrigerator-1672</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Tenstorrent is a startup that aims to create AI accelerators rivaling the GPU; their current best model, &lt;a href="https://tenstorrent.com/hardware/blackhole"&gt;p150a&lt;/a&gt;, featuring 32GB of GDDR6 memory, was tested against numerous GPUs by Russian blogger &lt;a href="https://www.youtube.com/@prohitec"&gt;Pro Hi-Tech&lt;/a&gt; in the following video:&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=pIS3Yery4I0"&gt;https://www.youtube.com/watch?v=pIS3Yery4I0&lt;/a&gt;&lt;/p&gt; &lt;p&gt;According to the video, the tests were launched by some kind of Python script on unquantized Llama 3 8B (timestamp 6:48), I assume inference via Transformers library. In such case, he found out the time to first token being slightly faster than 5090 and A100; however, the token generation speed is half of 5090 and on par with A30. Additionally, he disassembled the card and showed the PCB (2:02).&lt;/p&gt; &lt;p&gt;The charts featured in this video:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;7:39 - Time to first token, ms;&lt;/li&gt; &lt;li&gt;8:26 - Inter-token latency, ms;&lt;/li&gt; &lt;li&gt;8:38 - Generation speed, tok/s;&lt;/li&gt; &lt;li&gt;9:07 - Card TDP; it seems like the numbers are as specified by manufacturer, not measured;&lt;/li&gt; &lt;li&gt;9:26 - Performance per watt; I assume it's tok/s/W;&lt;/li&gt; &lt;li&gt;9:57 - Performance per dollar; prices are MSRP, not actual retail prices.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;He calls out numerous &lt;strong&gt;software problems&lt;/strong&gt; with p150a:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The default installation guide is outdated;&lt;/li&gt; &lt;li&gt;The manufacturer supplied model training containers failed to launch;&lt;/li&gt; &lt;li&gt;The telemetry app does not report any of the memory parameters (especially amount of memory utilized);&lt;/li&gt; &lt;li&gt;If telemetry app is launched while doing compute, it will hung up the system, requiring full PC reboot; as a result, it is impossible to measure the chip's temperature under load;&lt;/li&gt; &lt;li&gt;He failed to test any of 14B models he tried (11:01); although he cites OOM error, so I suspect the test script was simply reserving too much KV cache;&lt;/li&gt; &lt;li&gt;The p150a hung up and required full OS reboot after &amp;quot;long-term load&amp;quot;;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;It seems that while Tenstorrent offers decent performance for the price, it's software support is too lacking to use it in production.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/No-Refrigerator-1672"&gt; /u/No-Refrigerator-1672 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9b7mn/tenstorrent_p150a_tested_against_rtx5090_rtx3090/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9b7mn/tenstorrent_p150a_tested_against_rtx5090_rtx3090/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9b7mn/tenstorrent_p150a_tested_against_rtx5090_rtx3090/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T17:18:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9flux</id>
    <title>An Open-Source, Configurable Deepthink Reasoning System That Performs the Same as Gemini Deepthink (Gold Medal at IMO 2025)</title>
    <updated>2025-09-05T20:09:03+00:00</updated>
    <author>
      <name>/u/Ryoiki-Tokuiten</name>
      <uri>https://old.reddit.com/user/Ryoiki-Tokuiten</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9flux/an_opensource_configurable_deepthink_reasoning/"&gt; &lt;img alt="An Open-Source, Configurable Deepthink Reasoning System That Performs the Same as Gemini Deepthink (Gold Medal at IMO 2025)" src="https://external-preview.redd.it/ZzdnNGplb2prZW5mMQYvwHNGGuNUN8or0wrdAaTg9BfB31Jlu0HUBZSFT4Gi.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=bf73aae4d4084affa89860b6367ce25c59f84f8b" title="An Open-Source, Configurable Deepthink Reasoning System That Performs the Same as Gemini Deepthink (Gold Medal at IMO 2025)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Ryoiki-Tokuiten"&gt; /u/Ryoiki-Tokuiten &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://v.redd.it/jhjamaojkenf1"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9flux/an_opensource_configurable_deepthink_reasoning/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9flux/an_opensource_configurable_deepthink_reasoning/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T20:09:03+00:00</published>
  </entry>
  <entry>
    <id>t3_1n98c25</id>
    <title>Seems new model qwen 3 max preview is already available on qwen chat</title>
    <updated>2025-09-05T15:28:15+00:00</updated>
    <author>
      <name>/u/Independent-Wind4462</name>
      <uri>https://old.reddit.com/user/Independent-Wind4462</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n98c25/seems_new_model_qwen_3_max_preview_is_already/"&gt; &lt;img alt="Seems new model qwen 3 max preview is already available on qwen chat" src="https://preview.redd.it/nzfh1xg27dnf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=73f4d1143429da1ba0af0e95c543b1866fd87af5" title="Seems new model qwen 3 max preview is already available on qwen chat" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Independent-Wind4462"&gt; /u/Independent-Wind4462 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/nzfh1xg27dnf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n98c25/seems_new_model_qwen_3_max_preview_is_already/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n98c25/seems_new_model_qwen_3_max_preview_is_already/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T15:28:15+00:00</published>
  </entry>
  <entry>
    <id>t3_1n98t6m</id>
    <title>Qwen released API of Qwen3-Max-Preview (Instruct)</title>
    <updated>2025-09-05T15:46:51+00:00</updated>
    <author>
      <name>/u/ResearchCrafty1804</name>
      <uri>https://old.reddit.com/user/ResearchCrafty1804</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n98t6m/qwen_released_api_of_qwen3maxpreview_instruct/"&gt; &lt;img alt="Qwen released API of Qwen3-Max-Preview (Instruct)" src="https://preview.redd.it/zw8lhw7eadnf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=fb61f9c84a1df5f11a0a7762294f4a826dfa9e29" title="Qwen released API of Qwen3-Max-Preview (Instruct)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Big news: Introducing Qwen3-Max-Preview (Instruct) — our biggest model yet, with over 1 trillion parameters! 🚀&lt;/p&gt; &lt;p&gt;Now available via Qwen Chat &amp;amp; Alibaba Cloud API.&lt;/p&gt; &lt;p&gt;Benchmarks show it beats our previous best, Qwen3-235B-A22B-2507. Internal tests + early user feedback confirm: stronger performance, broader knowledge, better at conversations, agentic tasks &amp;amp; instruction following.&lt;/p&gt; &lt;p&gt;Scaling works — and the official release will surprise you even more. Stay tuned!&lt;/p&gt; &lt;p&gt;Qwen Chat: &lt;a href="https://chat.qwen.ai/"&gt;https://chat.qwen.ai/&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ResearchCrafty1804"&gt; /u/ResearchCrafty1804 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/zw8lhw7eadnf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n98t6m/qwen_released_api_of_qwen3maxpreview_instruct/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n98t6m/qwen_released_api_of_qwen3maxpreview_instruct/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T15:46:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1n981di</id>
    <title>Kwai-Klear/Klear-46B-A2.5B-Instruct: Sparse-MoE LLM (46B total / only 2.5B active)</title>
    <updated>2025-09-05T15:16:49+00:00</updated>
    <author>
      <name>/u/paf1138</name>
      <uri>https://old.reddit.com/user/paf1138</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n981di/kwaiklearklear46ba25binstruct_sparsemoe_llm_46b/"&gt; &lt;img alt="Kwai-Klear/Klear-46B-A2.5B-Instruct: Sparse-MoE LLM (46B total / only 2.5B active)" src="https://external-preview.redd.it/YCjYCLowWoUZPOtPjfRsNwF5BBEIscgMQg1iK3Ht-1Q.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b95159fb1ff226ff1812f1b78e632fd38eaf6fc9" title="Kwai-Klear/Klear-46B-A2.5B-Instruct: Sparse-MoE LLM (46B total / only 2.5B active)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/paf1138"&gt; /u/paf1138 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/Kwai-Klear/Klear-46B-A2.5B-Instruct"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n981di/kwaiklearklear46ba25binstruct_sparsemoe_llm_46b/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n981di/kwaiklearklear46ba25binstruct_sparsemoe_llm_46b/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T15:16:49+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9hduk</id>
    <title>VibeVoice came back. Though many may not like it.</title>
    <updated>2025-09-05T21:19:36+00:00</updated>
    <author>
      <name>/u/Fresh_Sun_1017</name>
      <uri>https://old.reddit.com/user/Fresh_Sun_1017</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://github.com/microsoft/VibeVoice"&gt;VibeVoice&lt;/a&gt; has returned(&lt;em&gt;not&lt;/em&gt; VibeVoice-large); however, Microsoft plans to implement censorship due to people's &amp;quot;misuse of research&amp;quot;. Here's the quote from the repo:&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;VibeVoice is an open-source research framework intended to advance collaboration in the speech synthesis community. &lt;strong&gt;After release, we discovered instances where the tool was used in ways inconsistent with the stated intent. Since responsible use of AI is one of Microsoft’s guiding principles, we have disabled this repo until we are confident that out-of-scope use is no longer possible.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt; &lt;p&gt;What types of censorship will be implemented? And couldn’t people just use or share older, unrestricted versions they've already downloaded? That's going to be interesting...&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Edit:&lt;/strong&gt; The VibeVoice-Large model is still available as of now, &lt;a href="https://www.modelscope.cn/models/microsoft/VibeVoice-Large/files"&gt;VibeVoice-Large · Models&lt;/a&gt; on Modelscope. It may be deleted soon.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Fresh_Sun_1017"&gt; /u/Fresh_Sun_1017 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9hduk/vibevoice_came_back_though_many_may_not_like_it/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9hduk/vibevoice_came_back_though_many_may_not_like_it/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9hduk/vibevoice_came_back_though_many_may_not_like_it/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T21:19:36+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9c0ef</id>
    <title>Bro is thinking about this for 5 minutes, what you mean by "maybe" man, decide it already</title>
    <updated>2025-09-05T17:48:45+00:00</updated>
    <author>
      <name>/u/trxhh36</name>
      <uri>https://old.reddit.com/user/trxhh36</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9c0ef/bro_is_thinking_about_this_for_5_minutes_what_you/"&gt; &lt;img alt="Bro is thinking about this for 5 minutes, what you mean by &amp;quot;maybe&amp;quot; man, decide it already" src="https://preview.redd.it/u6uf4z4kvdnf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=9d03e46b798490e8b7beb01b871ef039d65fc462" title="Bro is thinking about this for 5 minutes, what you mean by &amp;quot;maybe&amp;quot; man, decide it already" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;GLM 4.5 in Z AI&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/trxhh36"&gt; /u/trxhh36 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/u6uf4z4kvdnf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9c0ef/bro_is_thinking_about_this_for_5_minutes_what_you/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9c0ef/bro_is_thinking_about_this_for_5_minutes_what_you/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T17:48:45+00:00</published>
  </entry>
  <entry>
    <id>t3_1n8ues8</id>
    <title>Kimi-K2-Instruct-0905 Released!</title>
    <updated>2025-09-05T03:15:27+00:00</updated>
    <author>
      <name>/u/Dr_Karminski</name>
      <uri>https://old.reddit.com/user/Dr_Karminski</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8ues8/kimik2instruct0905_released/"&gt; &lt;img alt="Kimi-K2-Instruct-0905 Released!" src="https://preview.redd.it/6jq7r55ak9nf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=0a5eec08b8c7bedbb50e39a668de98e599c3a0b6" title="Kimi-K2-Instruct-0905 Released!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Dr_Karminski"&gt; /u/Dr_Karminski &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/6jq7r55ak9nf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8ues8/kimik2instruct0905_released/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n8ues8/kimik2instruct0905_released/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T03:15:27+00:00</published>
  </entry>
  <entry>
    <id>t3_1n95fl4</id>
    <title>Unsloth just released their GGUF of Kimi-K2-Instruct-0905!</title>
    <updated>2025-09-05T13:34:21+00:00</updated>
    <author>
      <name>/u/TheAndyGeorge</name>
      <uri>https://old.reddit.com/user/TheAndyGeorge</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n95fl4/unsloth_just_released_their_gguf_of/"&gt; &lt;img alt="Unsloth just released their GGUF of Kimi-K2-Instruct-0905!" src="https://external-preview.redd.it/u42y4pGiiWpLArGTxtLnpU7XIOrkkmzZ5xAid1ozch8.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=f7d4e7a1b9c3b96563747fc8517c620156b1d622" title="Unsloth just released their GGUF of Kimi-K2-Instruct-0905!" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/TheAndyGeorge"&gt; /u/TheAndyGeorge &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://huggingface.co/unsloth/Kimi-K2-Instruct-0905-GGUF"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n95fl4/unsloth_just_released_their_gguf_of/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n95fl4/unsloth_just_released_their_gguf_of/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T13:34:21+00:00</published>
  </entry>
  <entry>
    <id>t3_1n99gpq</id>
    <title>LongPage: 300 full novels with reasoning traces for training better writing LLMs</title>
    <updated>2025-09-05T16:11:47+00:00</updated>
    <author>
      <name>/u/Senior_Evidence_3793</name>
      <uri>https://old.reddit.com/user/Senior_Evidence_3793</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n99gpq/longpage_300_full_novels_with_reasoning_traces/"&gt; &lt;img alt="LongPage: 300 full novels with reasoning traces for training better writing LLMs" src="https://external-preview.redd.it/riwdF_EjDqIZtaMr2L8TnhS0xQM36fl9qJv4y9kVTdk.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=13dfc405c4b3fc698c8aad905dd57399f797231a" title="LongPage: 300 full novels with reasoning traces for training better writing LLMs" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;&lt;a href="https://preview.redd.it/5zaxpqdsednf1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c0018a54af853ad9c74b9e1e7bd1ac219af544b"&gt;https://preview.redd.it/5zaxpqdsednf1.png?width=1536&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8c0018a54af853ad9c74b9e1e7bd1ac219af544b&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Current LLMs struggle with long-form creative writing because they lack hierarchical planning. LongPage solves this by providing the reasoning scaffolds that were missing.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;What it is:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;300 complete books (Project Gutenberg classics) with full reasoning traces&lt;/li&gt; &lt;li&gt;40,000 to 600,000+ tokens per book&lt;/li&gt; &lt;li&gt;Multi-layered planning: character archetypes, story arcs, world rules, scene breakdowns&lt;/li&gt; &lt;li&gt;Rich structural metadata (dialogue density, pacing, narrative focus)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Why it matters:&lt;/strong&gt; This is the &amp;quot;Chain of Thought for creative writing&amp;quot; - explicit reasoning traces showing models how to plan character development, plot progression, and maintain thematic coherence across entire books.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Training applications:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Cold-start SFT → RL workflows with 3-component structure (prompt, thinking, book)&lt;/li&gt; &lt;li&gt;Inference-time scaffolding using reasoning traces as plans&lt;/li&gt; &lt;li&gt;Hierarchical training: book-level plans → chapter expansions → scene continuations&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Currently 300 books, scaling to 100K. All reasoning generated by Qwen3-32B with iterative agent validation across scene → chapter → book levels.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;HF Link:&lt;/strong&gt; &lt;a href="https://huggingface.co/datasets/Pageshift-Entertainment/LongPage"&gt;https://huggingface.co/datasets/Pageshift-Entertainment/LongPage&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Anyone working on long-form generation? Would love to hear what training approaches you're planning to try with this.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Senior_Evidence_3793"&gt; /u/Senior_Evidence_3793 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n99gpq/longpage_300_full_novels_with_reasoning_traces/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n99gpq/longpage_300_full_novels_with_reasoning_traces/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n99gpq/longpage_300_full_novels_with_reasoning_traces/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T16:11:47+00:00</published>
  </entry>
  <entry>
    <id>t3_1n92jy2</id>
    <title>List of open models released or updated this week on this sub, just in case you missed one.</title>
    <updated>2025-09-05T11:21:44+00:00</updated>
    <author>
      <name>/u/aifeed-fyi</name>
      <uri>https://old.reddit.com/user/aifeed-fyi</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A quick list of models updates and new releases mentioned in several posts during the week on LocalLLama. I wanted to include links to posts/models but it didn't go through. &lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Kimi K2-0905&lt;/strong&gt; – new release from Moonshot AI&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Wayfarer 2 12B &amp;amp; Nova 70B&lt;/strong&gt; – open-sourced narrative roleplay models from AI Dungeon&lt;/li&gt; &lt;li&gt;&lt;strong&gt;EmbeddingGemma (300M)&lt;/strong&gt; – Google’s compact multilingual embedding model&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Apertus&lt;/strong&gt; – new open multilingual LLM from ETH Zürich (40%+ non-English training data)&lt;/li&gt; &lt;li&gt;&lt;strong&gt;WEBGEN-4B&lt;/strong&gt; – web design generation model trained on 100k synthetic samples&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Lille (130M)&lt;/strong&gt; – a truly open-source small language model (trained fully from&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Hunyuan-MT-7B &amp;amp; Hunyuan-MT-Chimera-7B&lt;/strong&gt; – Tencent’s new translation &amp;amp; ensemble models&lt;/li&gt; &lt;li&gt;&lt;strong&gt;GPT-OSS-120B&lt;/strong&gt; – benchmarks updates&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Beens-MiniMax (103M MoE)&lt;/strong&gt; – scratch-built, SFT + LoRA experiments&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/aifeed-fyi"&gt; /u/aifeed-fyi &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n92jy2/list_of_open_models_released_or_updated_this_week/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n92jy2/list_of_open_models_released_or_updated_this_week/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n92jy2/list_of_open_models_released_or_updated_this_week/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T11:21:44+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9ap73</id>
    <title>Qwen 3 Max Official Pricing</title>
    <updated>2025-09-05T16:58:58+00:00</updated>
    <author>
      <name>/u/entsnack</name>
      <uri>https://old.reddit.com/user/entsnack</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9ap73/qwen_3_max_official_pricing/"&gt; &lt;img alt="Qwen 3 Max Official Pricing" src="https://preview.redd.it/tx801h07ndnf1.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=b87412ed2c1257b7012cf473923bdcbd7512d19e" title="Qwen 3 Max Official Pricing" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/entsnack"&gt; /u/entsnack &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/tx801h07ndnf1.png"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9ap73/qwen_3_max_official_pricing/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9ap73/qwen_3_max_official_pricing/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T16:58:58+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9kwwr</id>
    <title>New post flair: "local only"</title>
    <updated>2025-09-05T23:51:46+00:00</updated>
    <author>
      <name>/u/ttkciar</name>
      <uri>https://old.reddit.com/user/ttkciar</uri>
    </author>
    <content type="html">&lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;A new post flair has been created, &amp;quot;local only&amp;quot;.&lt;/p&gt; &lt;p&gt;Please use this flair on new posts to denote:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;Your post is about &lt;strong&gt;local&lt;/strong&gt; LLM technology,&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Comments should be focused primarily on &lt;strong&gt;local&lt;/strong&gt; LLM technology.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If your main interest in this subreddit is to read about / discuss local LLM technology, you can filter your view through the &amp;quot;local only&amp;quot; flair &lt;a href="https://www.reddit.com/r/LocalLLaMA/?f=flair_name%3A%22local%20only%22"&gt;like so,&lt;/a&gt; and all of the &amp;quot;noise&amp;quot; about closed models, API costs, etc will become hidden from view.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/ttkciar"&gt; /u/ttkciar &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9kwwr/new_post_flair_local_only/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9kwwr/new_post_flair_local_only/"&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9kwwr/new_post_flair_local_only/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T23:51:46+00:00</published>
  </entry>
  <entry>
    <id>t3_1n98vdp</id>
    <title>Qwen 3 Max Official Benchmarks (possibly open sourcing later..?)</title>
    <updated>2025-09-05T15:49:10+00:00</updated>
    <author>
      <name>/u/Trevor050</name>
      <uri>https://old.reddit.com/user/Trevor050</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n98vdp/qwen_3_max_official_benchmarks_possibly_open/"&gt; &lt;img alt="Qwen 3 Max Official Benchmarks (possibly open sourcing later..?)" src="https://preview.redd.it/eeekht6sadnf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=ff85bfdf6253ad3ba0a381c5514ad302898defd3" title="Qwen 3 Max Official Benchmarks (possibly open sourcing later..?)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/Trevor050"&gt; /u/Trevor050 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/eeekht6sadnf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n98vdp/qwen_3_max_official_benchmarks_possibly_open/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n98vdp/qwen_3_max_official_benchmarks_possibly_open/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T15:49:10+00:00</published>
  </entry>
  <entry>
    <id>t3_1n975er</id>
    <title>Qwen 3 max</title>
    <updated>2025-09-05T14:42:28+00:00</updated>
    <author>
      <name>/u/LeatherRub7248</name>
      <uri>https://old.reddit.com/user/LeatherRub7248</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n975er/qwen_3_max/"&gt; &lt;img alt="Qwen 3 max" src="https://external-preview.redd.it/9f9JRaQTq2uR5GC3copbxq5McLsZhYSzNHSbhHCgcmg.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=1f89b1589b444db5310feea66a3e0335c0591fac" title="Qwen 3 max" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;It's out&lt;/p&gt; &lt;p&gt;&lt;a href="https://openrouter.ai/qwen/qwen3-max"&gt;https://openrouter.ai/qwen/qwen3-max&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://chat.qwen.ai/"&gt;https://chat.qwen.ai/&lt;/a&gt; (qwen 3 max preview)&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/nb9wzcl9bdnf1.png?width=1254&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d22747e9fb863b0412d20782dd88e055fbb87a9f"&gt;https://preview.redd.it/nb9wzcl9bdnf1.png?width=1254&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d22747e9fb863b0412d20782dd88e055fbb87a9f&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/LeatherRub7248"&gt; /u/LeatherRub7248 &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n975er/qwen_3_max/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n975er/qwen_3_max/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n975er/qwen_3_max/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T14:42:28+00:00</published>
  </entry>
  <entry>
    <id>t3_1n9gfpt</id>
    <title>Anthropic to pay $1.5 billion to authors in landmark AI settlement</title>
    <updated>2025-09-05T20:41:52+00:00</updated>
    <author>
      <name>/u/cpldcpu</name>
      <uri>https://old.reddit.com/user/cpldcpu</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9gfpt/anthropic_to_pay_15_billion_to_authors_in/"&gt; &lt;img alt="Anthropic to pay $1.5 billion to authors in landmark AI settlement" src="https://external-preview.redd.it/2giFHQHB-5T6ma6XiIR2StAHVaV1z6nAKhfbARNarkE.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=d341db7b1d508270a9cf44051e58699980b97ccb" title="Anthropic to pay $1.5 billion to authors in landmark AI settlement" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/cpldcpu"&gt; /u/cpldcpu &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://www.theverge.com/anthropic/773087/anthropic-to-pay-1-5-billion-to-authors-in-landmark-ai-settlement"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n9gfpt/anthropic_to_pay_15_billion_to_authors_in/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n9gfpt/anthropic_to_pay_15_billion_to_authors_in/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-05T20:41:52+00:00</published>
  </entry>
  <entry>
    <id>t3_1n7j5z2</id>
    <title>Our 2nd AMA: Hugging Face Science Team, Creators of SmolLM, SmolVLM, and more! (Tomorrow, 8AM-11AM PST)</title>
    <updated>2025-09-03T16:14:51+00:00</updated>
    <author>
      <name>/u/XMasterrrr</name>
      <uri>https://old.reddit.com/user/XMasterrrr</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n7j5z2/our_2nd_ama_hugging_face_science_team_creators_of/"&gt; &lt;img alt="Our 2nd AMA: Hugging Face Science Team, Creators of SmolLM, SmolVLM, and more! (Tomorrow, 8AM-11AM PST)" src="https://preview.redd.it/wdx4ivdw3zmf1.jpeg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=876855c03867ead70389d15b60f24b91d478f835" title="Our 2nd AMA: Hugging Face Science Team, Creators of SmolLM, SmolVLM, and more! (Tomorrow, 8AM-11AM PST)" /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/XMasterrrr"&gt; /u/XMasterrrr &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://i.redd.it/wdx4ivdw3zmf1.jpeg"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n7j5z2/our_2nd_ama_hugging_face_science_team_creators_of/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n7j5z2/our_2nd_ama_hugging_face_science_team_creators_of/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-03T16:14:51+00:00</published>
  </entry>
  <entry>
    <id>t3_1n8c3l2</id>
    <title>AMA with Hugging Face Science, the team behind SmolLM, SmolVLM, Fineweb and more.</title>
    <updated>2025-09-04T14:43:01+00:00</updated>
    <author>
      <name>/u/eliebakk</name>
      <uri>https://old.reddit.com/user/eliebakk</uri>
    </author>
    <content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8c3l2/ama_with_hugging_face_science_the_team_behind/"&gt; &lt;img alt="AMA with Hugging Face Science, the team behind SmolLM, SmolVLM, Fineweb and more." src="https://external-preview.redd.it/y8IJElEOEd_2568MHNUZQsP7_aRTCAzyzXUKpDJwl1Y.png?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=4e377887ea8d7eae841499cc497b90b82aa97816" title="AMA with Hugging Face Science, the team behind SmolLM, SmolVLM, Fineweb and more." /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class="md"&gt;&lt;p&gt;Hi &lt;a href="https://www.reddit.com/r/LocalLLaMA/"&gt;r/LocalLLaMA&lt;/a&gt;&lt;/p&gt; &lt;p&gt;We're super excited to do this AMA. Come ask your questions to the researchers behind &lt;strong&gt;SmolLM, SmolVLM, FineWeb&lt;/strong&gt;, and more. You can learn more about our work at &lt;a href="http://hf.co/science"&gt;hf.co/science&lt;/a&gt; 🤗&lt;/p&gt; &lt;p&gt;If you want to get started in ML, a good place is &lt;a href="https://hf.co/learn"&gt;https://hf.co/learn&lt;/a&gt;&lt;/p&gt; &lt;p&gt;To celebrate the AMA, we release a new &lt;strong&gt;FineVision&lt;/strong&gt; dataset, check it out! &lt;a href="https://huggingface.co/datasets/HuggingFaceM4/FineVision"&gt;https://huggingface.co/datasets/HuggingFaceM4/FineVision&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Our participants:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://huggingface.co/eliebak"&gt;Elie Bakouch&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/eliebakk"&gt;u/eliebakk&lt;/a&gt; (SmolLM)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/loubnabnl"&gt;Loubna Ben Allal&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/loubnabnl"&gt;u/loubnabnl&lt;/a&gt; (SmolLM)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/nouamanetazi"&gt;Nouamane Tazi&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/Norlax"&gt;u/Norlax&lt;/a&gt;_42 (Nanotron/SmolLM)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/lvwerra"&gt;Leandro von Werra&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/lvwerra"&gt;u/lvwerra&lt;/a&gt; (Head of Research)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/edbeeching"&gt;Edward Beeching&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/edbeeching"&gt;u/edbeeching&lt;/a&gt; (Post Training)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/cmpatino"&gt;Carlos Miguel Patiño&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/cmpatino"&gt;u/cmpatino&lt;/a&gt;_ (Post Training)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/kashif"&gt;Kashif Rasul&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/krasul"&gt;u/krasul&lt;/a&gt; (Post Training)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/lewtun"&gt;Lewis Tunstall&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/lewtun"&gt;u/lewtun&lt;/a&gt; (Post Training)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/qgallouedec"&gt;Quentin Gallouédec&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/qgallouedec"&gt;u/qgallouedec&lt;/a&gt; (Post Training)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/clefourrier"&gt;Clémentine Fourrier&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/clefourrier"&gt;u/clefourrier&lt;/a&gt; (Eval)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/SaylorTwift"&gt;Nathan Habib&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/HauntingMoment"&gt;u/HauntingMoment&lt;/a&gt; (Eval)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/lusxvr"&gt;Luis Wiedmann&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/luswd"&gt;u/luswd&lt;/a&gt; (Multimodal)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/andito"&gt;Andres Marafioti&lt;/a&gt;, &lt;a href="/u/futterneid"&gt;u/futterneid&lt;/a&gt; (Multimodal)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/guipenedo"&gt;Guilherme Penedo&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/PhilipsNostrum"&gt;u/PhilipsNostrum&lt;/a&gt; (Data)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/hynky"&gt;Hynek Kydlíček&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/Other"&gt;u/Other&lt;/a&gt;_Housing8453 (Data)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/reach-vb"&gt;Vaibhav Srivastav,&lt;/a&gt; &lt;a href="/u/vaibhavs10"&gt;u/vaibhavs10&lt;/a&gt; (Head of Developer Experience and Community)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/BrigitteTousi"&gt;Brigitte Tousignant&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/BriggieSmalls1992"&gt;u/BriggieSmalls1992&lt;/a&gt; (Comms)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/Xenova"&gt;Xenova&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/xenovatech"&gt;u/xenovatech&lt;/a&gt; (Transformers.js)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/craffel"&gt;Colin Raffel&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/craffel"&gt;u/craffel&lt;/a&gt; (Research)&lt;/li&gt; &lt;li&gt;&lt;a href="https://huggingface.co/ngxson"&gt;Xuan Son Nguyen&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href="/u/MediocreProgrammer99"&gt;u/MediocreProgrammer99&lt;/a&gt; (llama.cpp)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you are passionate about open source and open science like us, apply at &lt;a href="https://hf.co/jobs"&gt;https://hf.co/jobs&lt;/a&gt; &lt;/p&gt; &lt;p&gt;&lt;strong&gt;The AMA will run from 8 AM – 11 AM PST, with the Hugging Face team continuing to follow up on questions over the next 24 hours.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://preview.redd.it/o6moshv0u5nf1.png?width=2013&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ee6a9392c3da8651e8a1425264ed855a51b69135"&gt;https://preview.redd.it/o6moshv0u5nf1.png?width=2013&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ee6a9392c3da8651e8a1425264ed855a51b69135&lt;/a&gt;&lt;/p&gt; &lt;blockquote&gt; &lt;p&gt;Thanks everyone for joining our AMA. The live part has ended but we will still answer question async for the next 24h. Follow our &lt;a href="https://hf.co/science"&gt;Hugging Face Science Org&lt;/a&gt; to be aware of our latest release! 🤗&lt;/p&gt; &lt;/blockquote&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href="https://old.reddit.com/user/eliebakk"&gt; /u/eliebakk &lt;/a&gt; &lt;br /&gt; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8c3l2/ama_with_hugging_face_science_the_team_behind/"&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href="https://old.reddit.com/r/LocalLLaMA/comments/1n8c3l2/ama_with_hugging_face_science_the_team_behind/"&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content>
    <link href="https://old.reddit.com/r/LocalLLaMA/comments/1n8c3l2/ama_with_hugging_face_science_the_team_behind/"/>
    <category term="LocalLLaMA" label="r/LocalLLaMA"/>
    <published>2025-09-04T14:43:01+00:00</published>
  </entry>
</feed>
